"""
Ollama Gateway - èª¿åº¦å™¨å’Œåå‘ä»£ç†
çµ±ä¸€ç¶²é—œï¼Œè² è²¬å°‡LLMè«‹æ±‚è½‰ç™¼åˆ°å¤šå€‹Ollamaç¯€é»
"""
import os
import asyncio
import time
import json
import re
from typing import List, Optional, Dict, Set, Tuple
from fastapi import FastAPI, Request, HTTPException, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, HTMLResponse
import httpx
from dotenv import load_dotenv
import uvicorn
from prometheus_client import Counter, Gauge, Histogram, generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response as MetricsResponse

# åŠ è¼‰ç’°å¢ƒè®Šé‡
load_dotenv()

# åŠ è¼‰ç¯€é»é…ç½®
CONFIG_FILE = os.getenv("NODE_CONFIG_FILE", "node_config.json")
node_config = {}
model_patterns = {}
model_name_mapping = {}
default_model_size = 7

try:
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        config_data = json.load(f)
        node_config = {node["name"]: node for node in config_data.get("nodes", [])}
        model_patterns = config_data.get("model_name_patterns", {})
        model_name_mapping = config_data.get("model_name_mapping", {})
        default_model_size = config_data.get("default_model_size_b", 7)
    print(f"Loaded node configuration from {CONFIG_FILE}")
except FileNotFoundError:
    print(f"Warning: Config file {CONFIG_FILE} not found, using default configuration")
except Exception as e:
    print(f"Error loading config file: {e}")

app = FastAPI(title="Ollama Gateway", version="1.0.0")

# CORSæ”¯æŒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Prometheus metrics
request_count = Counter(
    "gateway_requests_total",
    "Total number of requests processed",
    ["method", "endpoint", "node", "status"]
)

request_duration = Histogram(
    "gateway_request_duration_seconds",
    "Request duration in seconds",
    ["method", "endpoint", "node"]
)

active_connections = Gauge(
    "gateway_active_connections",
    "Number of active connections per node",
    ["node"]
)

node_health = Gauge(
    "gateway_node_health",
    "Health status of each node (1=healthy, 0=unhealthy)",
    ["node"]
)

# ç¯€é»é…ç½®
NODES = [
    {
        "name": "node1",
        "hosts": ["192.168.50.158", "m3max", "m3max.local", "m3max-128gb.local"],
        "port": 11434,
        "weight": 1.0,  # è² è¼‰å‡è¡¡æ¬Šé‡
        "enabled": True,
    },
    {
        "name": "node2",
        "hosts": ["192.168.50.31", "m1max", "m1max.local", "m1max-64gb.local"],
        "port": 11434,
        "weight": 1.0,
        "enabled": True,
    },
    {
        "name": "node3",
        "hosts": ["192.168.50.94", "m1", "m1.local", "m1-16gb.local"],
        "port": 11434,
        "weight": 1.0,
        "enabled": True,
    },
    {
        "name": "node4",
        "hosts": ["192.168.50.155", "i7", "i74080.local", "i7g13-4080-32gb.local"],
        "port": 11434,
        "weight": 1.0,
        "enabled": True,
    },
]

# èª¿åº¦ç­–ç•¥é¡å‹
SCHEDULING_STRATEGY = os.getenv("SCHEDULING_STRATEGY", "round_robin")  # round_robin, least_connections, weighted_round_robin

# ç¯€é»ç‹€æ…‹è¿½è¹¤
node_stats: Dict[str, Dict] = {}
node_models: Dict[str, Set[str]] = {}  # æ¯å€‹ç¯€é»ä¸Šå·²ä¸‹è¼‰çš„æ¨¡å‹åˆ—è¡¨
for node in NODES:
    node_stats[node["name"]] = {
        "active_connections": 0,
        "total_requests": 0,
        "failed_requests": 0,
        "last_health_check": None,
        "is_healthy": True,
        "current_weight": node["weight"],
        "effective_weight": node["weight"],
        "last_model_sync": None,
    }
    node_models[node["name"]] = set()

# è¼ªè©¢ç´¢å¼•
round_robin_index = 0

# HTTPå®¢æˆ¶ç«¯ï¼ˆæ”¯æŒé€£æ¥æ± å’Œè¶…æ™‚ï¼‰
timeout = httpx.Timeout(300.0, connect=10.0)  # 5åˆ†é˜ç¸½è¶…æ™‚ï¼Œ10ç§’é€£æ¥è¶…æ™‚
client = httpx.AsyncClient(timeout=timeout, follow_redirects=True)


class NodeSelector:
    """ç¯€é»é¸æ“‡å™¨ - å¯¦ç¾ä¸åŒçš„èª¿åº¦ç­–ç•¥"""
    
    @staticmethod
    def round_robin(nodes: List[Dict]) -> Optional[Dict]:
        """è¼ªè©¢èª¿åº¦"""
        global round_robin_index
        enabled_nodes = [n for n in nodes if n.get("enabled", True) and node_stats[n["name"]]["is_healthy"]]
        if not enabled_nodes:
            return None
        node = enabled_nodes[round_robin_index % len(enabled_nodes)]
        round_robin_index += 1
        return node
    
    @staticmethod
    def least_connections(nodes: List[Dict]) -> Optional[Dict]:
        """æœ€å°‘é€£æ¥æ•¸èª¿åº¦"""
        enabled_nodes = [
            n for n in nodes 
            if n.get("enabled", True) and node_stats[n["name"]]["is_healthy"]
        ]
        if not enabled_nodes:
            return None
        return min(enabled_nodes, key=lambda n: node_stats[n["name"]]["active_connections"])
    
    @staticmethod
    def weighted_round_robin(nodes: List[Dict]) -> Optional[Dict]:
        """åŠ æ¬Šè¼ªè©¢èª¿åº¦"""
        enabled_nodes = [
            n for n in nodes 
            if n.get("enabled", True) and node_stats[n["name"]]["is_healthy"]
        ]
        if not enabled_nodes:
            return None
        
        # æ‰¾åˆ°ç•¶å‰æ¬Šé‡æœ€å¤§çš„ç¯€é»
        max_node = max(enabled_nodes, key=lambda n: node_stats[n["name"]]["current_weight"])
        
        # æ›´æ–°æ¬Šé‡ï¼šé¸ä¸­ç¯€é»æ¸›å»ç¸½æ¬Šé‡ï¼Œæ‰€æœ‰ç¯€é»åŠ ä¸ŠåŸå§‹æ¬Šé‡
        total_weight = sum(n["weight"] for n in enabled_nodes)
        for node in enabled_nodes:
            if node["name"] == max_node["name"]:
                node_stats[node["name"]]["current_weight"] -= total_weight
            node_stats[node["name"]]["current_weight"] += node["weight"]
        
        return max_node


def extract_model_name_from_request(request: Request, path: str) -> Optional[str]:
    """å¾è«‹æ±‚ä¸­æå–æ¨¡å‹åç¨±"""
    try:
        # å¾è·¯å¾‘ä¸­æå–ï¼ˆä¾‹å¦‚ /api/generateï¼‰
        if path.startswith("/api/"):
            # å°æ–¼ POST è«‹æ±‚ï¼Œå¾è«‹æ±‚é«”ä¸­æå–
            if request.method == "POST":
                # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘éœ€è¦ç•°æ­¥è®€å–bodyï¼Œä½†ç‚ºäº†ä¸é˜»å¡ï¼Œæˆ‘å€‘å…ˆå˜—è©¦å¾URLåƒæ•¸ç²å–
                pass
        
        # å¾æŸ¥è©¢åƒæ•¸ä¸­ç²å–
        model = request.query_params.get("model")
        if model:
            # ç§»é™¤ç‰ˆæœ¬æ¨™ç±¤
            if ":" in model:
                model = model.split(":")[0]
            return model
        
        # å¾è·¯å¾‘ä¸­æå–ï¼ˆä¾‹å¦‚ /api/generate/model_nameï¼‰
        path_parts = path.strip("/").split("/")
        if len(path_parts) >= 3 and path_parts[0] == "api":
            # å¯èƒ½æ˜¯ /api/generate æˆ– /api/chat ç­‰ï¼Œæ¨¡å‹ååœ¨bodyä¸­
            pass
            
    except Exception as e:
        print(f"Error extracting model name: {e}")
    return None


async def extract_model_name_from_body(body: bytes) -> Tuple[Optional[str], Optional[str]]:
    """å¾è«‹æ±‚é«”ä¸­æå–æ¨¡å‹åç¨±
    
    Returns:
        (model_name, full_model_name): æ¨¡å‹åç¨±ï¼ˆä¸å«tagï¼‰å’Œå®Œæ•´æ¨¡å‹åç¨±ï¼ˆå«tagï¼‰
    """
    try:
        if body:
            data = json.loads(body.decode('utf-8'))
            full_model = data.get("model")
            if full_model:
                # ä¿ç•™å®Œæ•´åç¨±ï¼ŒåŒæ™‚è¿”å›ä¸å«tagçš„ç‰ˆæœ¬
                model_name = full_model.split(":")[0] if ":" in full_model else full_model
                return model_name, full_model
    except Exception:
        pass
    return None, None


def get_model_size_b(model_name: str, full_model_name: Optional[str] = None) -> int:
    """å¾æ¨¡å‹åç¨±ä¸­æå–åƒæ•¸æ•¸é‡ï¼ˆBç‚ºå–®ä½ï¼‰
    
    Ollama çš„æ¨¡å‹é€šå¸¸æ ¼å¼ç‚ºï¼šmodel-name:tagï¼Œå…¶ä¸­ tag ç¶“å¸¸åŒ…å«åƒæ•¸æ•¸é‡ï¼ˆå¦‚ :30b, :70b-instructï¼‰
    
    Args:
        model_name: æ¨¡å‹åç¨±ï¼ˆå¯èƒ½å·²ç§»é™¤tagï¼‰
        full_model_name: å®Œæ•´çš„æ¨¡å‹åç¨±ï¼ˆåŒ…å«tagï¼Œå¦‚ qwen3-coder:30bï¼‰
    """
    if not model_name:
        return default_model_size
    
    # å„ªå…ˆæª¢æŸ¥å®Œæ•´æ¨¡å‹åç¨±ï¼ˆå¦‚æœæä¾›ï¼‰ï¼Œå› ç‚º Ollama çš„ tag ä¸­é€šå¸¸åŒ…å«åƒæ•¸æ•¸é‡
    if full_model_name:
        full_name_lower = full_model_name.lower()
        
        # å¾å®Œæ•´åç¨±ä¸­æå–åƒæ•¸æ•¸é‡ï¼ˆå¯èƒ½åœ¨tagä¸­ï¼‰
        # æ”¯æŒå¤šç¨®æ ¼å¼ï¼š:30b, :30B, :30-b, :30b-instruct, :30b:latest ç­‰
        # å„ªå…ˆåŒ¹é… tag éƒ¨åˆ†ï¼ˆå†’è™Ÿå¾Œé¢çš„å…§å®¹ï¼‰
        if ":" in full_model_name:
            tag_part = full_model_name.split(":")[-1].lower()  # å–æœ€å¾Œä¸€å€‹å†’è™Ÿå¾Œçš„éƒ¨åˆ†
            # åŒ¹é… tag ä¸­çš„åƒæ•¸æ•¸é‡ï¼ˆå¦‚ 30b, 30-b, 30b-instruct ç­‰ï¼‰
            match = re.search(r'(\d+)\s*[-_]?\s*b\b', tag_part)
            if match:
                return int(match.group(1))
        
        # å¦‚æœ tag ä¸­æ²’æœ‰æ‰¾åˆ°ï¼Œåœ¨æ•´å€‹å®Œæ•´åç¨±ä¸­æœç´¢
        match = re.search(r'(\d+)\s*[-_]?\s*b\b', full_name_lower)
        if match:
            return int(match.group(1))
    
    # æª¢æŸ¥æ¨¡å‹åç¨±æ˜ å°„è¡¨ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰
    if model_name in model_name_mapping:
        return model_name_mapping[model_name]
    
    # æª¢æŸ¥å®Œæ•´åç¨±çš„æ˜ å°„ï¼ˆå¦‚æœæä¾›ï¼‰
    if full_model_name and full_model_name in model_name_mapping:
        return model_name_mapping[full_model_name]
    
    model_name_lower = model_name.lower()
    
    # æŒ‰ç…§æ¨¡å¼åŒ¹é…ï¼Œå„ªå…ˆåŒ¹é…æ›´å¤§çš„æ•¸å­—
    sorted_patterns = sorted(model_patterns.items(), key=lambda x: x[1], reverse=True)
    for pattern, size in sorted_patterns:
        if pattern.lower() in model_name_lower:
            return size
    
    # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°ï¼Œå˜—è©¦ç”¨æ­£å‰‡è¡¨é”å¼æå–æ•¸å­—
    # åŒ¹é…é¡ä¼¼ "70b", "120b", "7b", "30-b" ç­‰
    match = re.search(r'(\d+)\s*[-_]?\s*b\b', model_name_lower)
    if match:
        return int(match.group(1))
    
    # é»˜èªè¿”å›é…ç½®çš„é»˜èªå€¼
    return default_model_size


def is_node_suitable_for_model(node_name: str, model_size_b: int) -> bool:
    """æª¢æŸ¥ç¯€é»æ˜¯å¦é©åˆé‹è¡ŒæŒ‡å®šå¤§å°çš„æ¨¡å‹"""
    if node_name not in node_config:
        # å¦‚æœç¯€é»ä¸åœ¨é…ç½®ä¸­ï¼Œå…è¨±ä½¿ç”¨ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        return True
    
    node_cfg = node_config[node_name]
    supported_ranges = node_cfg.get("supported_model_ranges", [])
    
    if not supported_ranges:
        return True  # æ²’æœ‰é…ç½®ç¯„åœï¼Œå…è¨±ä½¿ç”¨
    
    for range_cfg in supported_ranges:
        min_params = range_cfg.get("min_params_b", 0)
        max_params = range_cfg.get("max_params_b")
        
        if max_params is None:
            # ç„¡ä¸Šé™
            if model_size_b >= min_params:
                return True
        else:
            if min_params <= model_size_b <= max_params:
                return True
    
    return False


def filter_nodes_by_model(nodes: List[Dict], model_name: Optional[str], model_size_b: int) -> List[Dict]:
    """æ ¹æ“šæ¨¡å‹åç¨±å’Œå¤§å°éæ¿¾ç¯€é»"""
    if not model_name:
        # å¦‚æœæ²’æœ‰æ¨¡å‹åç¨±ï¼Œè¿”å›æ‰€æœ‰ç¯€é»
        return nodes
    
    filtered = []
    for node in nodes:
        node_name = node["name"]
        
        # ç¬¬ä¸€æ­¥ï¼šæª¢æŸ¥ç¯€é»æ˜¯å¦æœ‰è©²æ¨¡å‹
        has_model = model_name in node_models.get(node_name, set())
        if not has_model:
            continue
        
        # ç¬¬äºŒæ­¥ï¼šæª¢æŸ¥ç¯€é»ç¡¬ä»¶æ˜¯å¦é©åˆè©²æ¨¡å‹å¤§å°
        if not is_node_suitable_for_model(node_name, model_size_b):
            continue
        
        # ç¬¬ä¸‰æ­¥ï¼šæª¢æŸ¥ç¯€é»æ˜¯å¦å•Ÿç”¨ä¸”å¥åº·
        if not node.get("enabled", True):
            continue
        if not node_stats[node_name]["is_healthy"]:
            continue
        
        filtered.append(node)
    
    return filtered


def select_node(model_name: Optional[str] = None, model_size_b: Optional[int] = None) -> Optional[Dict]:
    """æ ¹æ“šèª¿åº¦ç­–ç•¥é¸æ“‡ç¯€é»ï¼Œæ”¯æŒæ¨¡å‹æ„ŸçŸ¥çš„ç¯€é»é¸æ“‡"""
    # å¦‚æœæä¾›äº†æ¨¡å‹ä¿¡æ¯ï¼Œå…ˆéæ¿¾ç¯€é»
    candidate_nodes = NODES
    if model_name and model_size_b is not None:
        candidate_nodes = filter_nodes_by_model(NODES, model_name, model_size_b)
        # å¦‚æœéæ¿¾å¾Œæ²’æœ‰ç¯€é»ï¼Œå›é€€åˆ°æ‰€æœ‰ç¯€é»ï¼ˆå…è¨±æ¨¡å‹ä¸‹è¼‰ï¼‰
        if not candidate_nodes:
            print(f"Warning: No suitable nodes found for model {model_name} ({model_size_b}B), falling back to all nodes")
            candidate_nodes = [n for n in NODES if n.get("enabled", True) and node_stats[n["name"]]["is_healthy"]]
    
    # æ ¹æ“šèª¿åº¦ç­–ç•¥é¸æ“‡
    if SCHEDULING_STRATEGY == "least_connections":
        return NodeSelector.least_connections(candidate_nodes)
    elif SCHEDULING_STRATEGY == "weighted_round_robin":
        return NodeSelector.weighted_round_robin(candidate_nodes)
    else:  # é»˜èªä½¿ç”¨ round_robin
        return NodeSelector.round_robin(candidate_nodes)


def get_node_url(node: Dict) -> str:
    """ç²å–ç¯€é»çš„å®Œæ•´URLï¼ˆä½¿ç”¨ç¬¬ä¸€å€‹hostï¼‰"""
    return f"http://{node['hosts'][0]}:{node['port']}"


async def get_node_models(node: Dict) -> Set[str]:
    """ç²å–ç¯€é»ä¸Šå·²ä¸‹è¼‰çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        url = f"{get_node_url(node)}/api/tags"
        async with httpx.AsyncClient(timeout=httpx.Timeout(5.0)) as client:
            response = await client.get(url)
            if response.status_code == 200:
                data = response.json()
                models = set()
                for model_info in data.get("models", []):
                    model_name = model_info.get("name", "")
                    # ç§»é™¤ç‰ˆæœ¬æ¨™ç±¤ï¼Œåªä¿ç•™æ¨¡å‹å
                    if ":" in model_name:
                        model_name = model_name.split(":")[0]
                    models.add(model_name)
                return models
    except Exception as e:
        print(f"Failed to get models from {node['name']}: {e}")
    return set()


async def health_check_node(node: Dict) -> bool:
    """å¥åº·æª¢æŸ¥ç¯€é»ä¸¦åŒæ­¥æ¨¡å‹åˆ—è¡¨"""
    try:
        url = f"{get_node_url(node)}/api/tags"
        async with httpx.AsyncClient(timeout=httpx.Timeout(5.0)) as client:
            response = await client.get(url)
            is_healthy = response.status_code == 200
            node_stats[node["name"]]["is_healthy"] = is_healthy
            node_stats[node["name"]]["last_health_check"] = time.time()
            node_health.labels(node=node["name"]).set(1 if is_healthy else 0)
            
            # åŒæ­¥æ¨¡å‹åˆ—è¡¨
            if is_healthy:
                models = await get_node_models(node)
                node_models[node["name"]] = models
                node_stats[node["name"]]["last_model_sync"] = time.time()
            
            return is_healthy
    except Exception as e:
        print(f"Health check failed for {node['name']}: {e}")
        node_stats[node["name"]]["is_healthy"] = False
        node_stats[node["name"]]["last_health_check"] = time.time()
        node_health.labels(node=node["name"]).set(0)
        return False


async def periodic_health_check():
    """å®šæœŸå¥åº·æª¢æŸ¥æ‰€æœ‰ç¯€é»"""
    while True:
        for node in NODES:
            if node.get("enabled", True):
                await health_check_node(node)
        await asyncio.sleep(30)  # æ¯30ç§’æª¢æŸ¥ä¸€æ¬¡


@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚åˆå§‹åŒ–"""
    # åˆå§‹åŒ–metrics
    for node in NODES:
        active_connections.labels(node=node["name"]).set(0)
        node_health.labels(node=node["name"]).set(0)
    
    # å•Ÿå‹•å¥åº·æª¢æŸ¥ä»»å‹™
    asyncio.create_task(periodic_health_check())
    
    # ç«‹å³åŸ·è¡Œä¸€æ¬¡å¥åº·æª¢æŸ¥
    for node in NODES:
        if node.get("enabled", True):
            await health_check_node(node)


@app.on_event("shutdown")
async def shutdown_event():
    """é—œé–‰æ™‚æ¸…ç†è³‡æº"""
    await client.aclose()


async def proxy_request(request: Request, path: str):
    """ä»£ç†è«‹æ±‚åˆ°é¸å®šçš„ç¯€é»"""
    # å…ˆè®€å–è«‹æ±‚é«”ï¼ˆç”¨æ–¼æå–æ¨¡å‹ä¿¡æ¯ï¼‰
    body_bytes = b""
    if request.method == "POST":
        try:
            body_bytes = await request.body()
        except Exception:
            pass
    
    # æå–æ¨¡å‹ä¿¡æ¯
    model_name = None
    full_model_name = None
    model_size_b = None
    
    # å…ˆå¾æŸ¥è©¢åƒæ•¸ç²å–
    full_model_name = request.query_params.get("model")
    if full_model_name:
        model_name = full_model_name.split(":")[0] if ":" in full_model_name else full_model_name
    
    # å¦‚æœæ²’æœ‰ï¼Œå¾è«‹æ±‚é«”ç²å–
    if not model_name and body_bytes:
        model_name, full_model_name = await extract_model_name_from_body(body_bytes)
    
    # è¨ˆç®—æ¨¡å‹å¤§å°ï¼ˆå‚³å…¥å®Œæ•´åç¨±ä»¥ä¾¿å¾tagä¸­æå–åƒæ•¸æ•¸é‡ï¼‰
    if model_name:
        model_size_b = get_model_size_b(model_name, full_model_name)
        display_name = full_model_name if full_model_name else model_name
        print(f"Request for model: {display_name} ({model_size_b}B)")
    
    # é¸æ“‡ç¯€é»ï¼ˆåŸºæ–¼æ¨¡å‹ä¿¡æ¯ï¼‰
    node = select_node(model_name, model_size_b)
    if not node:
        raise HTTPException(status_code=503, detail="No healthy nodes available")
    
    node_name = node["name"]
    node_url = get_node_url(node)
    target_url = f"{node_url}{path}"
    
    # æ›´æ–°é€£æ¥æ•¸
    node_stats[node_name]["active_connections"] += 1
    active_connections.labels(node=node_name).set(node_stats[node_name]["active_connections"])
    
    start_time = time.time()
    status_code = 500
    method = request.method  # åœ¨tryå¡Šå¤–å®šç¾©ï¼Œç¢ºä¿ç•°å¸¸è™•ç†ä¸­å¯ç”¨
    
    try:
        # æº–å‚™è«‹æ±‚
        headers = dict(request.headers)
        # ç§»é™¤å¯èƒ½å°è‡´å•é¡Œçš„headers
        headers.pop("host", None)
        headers.pop("content-length", None)
        
        # ä½¿ç”¨ä¹‹å‰è®€å–çš„body
        body = body_bytes
        
        # è½‰ç™¼è«‹æ±‚
        params = dict(request.query_params)
        
        response = await client.request(
            method=method,
            url=target_url,
            headers=headers,
            content=body,
            params=params,
        )
        
        status_code = response.status_code
        node_stats[node_name]["total_requests"] += 1
        
        # æ›´æ–°metrics
        request_count.labels(
            method=method,
            endpoint=path,
            node=node_name,
            status=status_code
        ).inc()
        
        duration = time.time() - start_time
        request_duration.labels(
            method=method,
            endpoint=path,
            node=node_name
        ).observe(duration)
        
        # å¦‚æœæ˜¯æµå¼éŸ¿æ‡‰
        if "text/event-stream" in response.headers.get("content-type", ""):
            async def generate():
                try:
                    async for chunk in response.aiter_bytes():
                        yield chunk
                finally:
                    node_stats[node_name]["active_connections"] -= 1
                    active_connections.labels(node=node_name).set(node_stats[node_name]["active_connections"])
            
            return StreamingResponse(
                generate(),
                status_code=status_code,
                headers=dict(response.headers),
                media_type=response.headers.get("content-type", "text/event-stream")
            )
        else:
            # æ™®é€šéŸ¿æ‡‰
            content = await response.aread()
            node_stats[node_name]["active_connections"] -= 1
            active_connections.labels(node=node_name).set(node_stats[node_name]["active_connections"])
            
            return Response(
                content=content,
                status_code=status_code,
                headers=dict(response.headers),
                media_type=response.headers.get("content-type", "application/json")
            )
    
    except httpx.TimeoutException:
        node_stats[node_name]["failed_requests"] += 1
        node_stats[node_name]["active_connections"] -= 1
        active_connections.labels(node=node_name).set(node_stats[node_name]["active_connections"])
        
        request_count.labels(
            method=method,
            endpoint=path,
            node=node_name,
            status="timeout"
        ).inc()
        
        raise HTTPException(status_code=504, detail=f"Request to {node_name} timed out")
    
    except Exception as e:
        node_stats[node_name]["failed_requests"] += 1
        node_stats[node_name]["active_connections"] -= 1
        active_connections.labels(node=node_name).set(node_stats[node_name]["active_connections"])
        
        request_count.labels(
            method=method,
            endpoint=path,
            node=node_name,
            status="error"
        ).inc()
        
        print(f"Error proxying to {node_name}: {e}")
        raise HTTPException(status_code=502, detail=f"Error proxying to {node_name}: {str(e)}")


# æ ¹è·¯å¾‘é‡å®šå‘åˆ°æ‹“æ’²é é¢ï¼ˆå¿…é ˆåœ¨é€šé…ç¬¦è·¯ç”±ä¹‹å‰ï¼‰
@app.get("/", response_class=HTMLResponse)
async def root():
    """æ ¹è·¯å¾‘ï¼Œé‡å®šå‘åˆ°æ‹“æ’²å¯è¦–åŒ–æˆ–é¡¯ç¤ºæ­¡è¿é é¢"""
    try:
        # å˜—è©¦è¿”å›æ‹“æ’²é é¢
        return await topology_viewer()
    except Exception:
        # å¦‚æœå¤±æ•—ï¼Œè¿”å›ç°¡å–®çš„æ­¡è¿é é¢
        welcome_html = """
        <!DOCTYPE html>
        <html lang="zh-TW">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Ollama Gateway</title>
            <style>
                body {
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
                    max-width: 800px;
                    margin: 50px auto;
                    padding: 20px;
                    background: #f5f7fa;
                }
                h1 { color: #2563eb; }
                .endpoint {
                    background: white;
                    padding: 15px;
                    margin: 10px 0;
                    border-radius: 8px;
                    border-left: 4px solid #2563eb;
                }
                a {
                    color: #2563eb;
                    text-decoration: none;
                    font-weight: 600;
                }
                a:hover { text-decoration: underline; }
                code {
                    background: #f1f5f9;
                    padding: 2px 6px;
                    border-radius: 4px;
                    font-family: 'Monaco', 'Courier New', monospace;
                }
            </style>
        </head>
        <body>
            <h1>ğŸš€ Ollama Gateway</h1>
            <p>çµ±ä¸€çš„ Ollama ç¶²é—œæœå‹™ï¼Œæä¾›è² è¼‰å‡è¡¡å’Œæ™ºèƒ½ç¯€é»é¸æ“‡ã€‚</p>
            
            <div class="endpoint">
                <h3>ğŸ“Š <a href="/topology">3D ç¶²çµ¡æ‹“æ’²å¯è¦–åŒ–</a></h3>
                <p>å¯¦æ™‚æŸ¥çœ‹é›†ç¾¤ç¶²çµ¡æ‹“æ’²å’Œç¯€é»ç‹€æ…‹</p>
            </div>
            
            <div class="endpoint">
                <h3>ğŸ” <a href="/health">å¥åº·æª¢æŸ¥</a></h3>
                <p>æŸ¥çœ‹ç¶²é—œå’Œç¯€é»çš„å¥åº·ç‹€æ…‹</p>
                <code>GET /health</code>
            </div>
            
            <div class="endpoint">
                <h3>ğŸ“¡ <a href="/nodes">ç¯€é»ç‹€æ…‹</a></h3>
                <p>æŸ¥çœ‹æ‰€æœ‰ç¯€é»çš„è©³ç´°ä¿¡æ¯å’Œå·²ä¸‹è¼‰çš„æ¨¡å‹åˆ—è¡¨</p>
                <code>GET /nodes</code>
            </div>
            
            <div class="endpoint">
                <h3>ğŸ“ˆ <a href="/metrics">Prometheus Metrics</a></h3>
                <p>Prometheus ç›£æ§æŒ‡æ¨™</p>
                <code>GET /metrics</code>
            </div>
            
            <div class="endpoint">
                <h3>ğŸ¤– Ollama API</h3>
                <p>æ‰€æœ‰ Ollama API è«‹æ±‚æœƒè‡ªå‹•ä»£ç†åˆ°åˆé©çš„ç¯€é»</p>
                <code>POST /api/generate</code><br>
                <code>GET /api/tags</code><br>
                <code>POST /api/chat</code>
            </div>
        </body>
        </html>
        """
        return HTMLResponse(content=welcome_html)


# æ‹“æ’²å¯è¦–åŒ–é é¢ï¼ˆå¿…é ˆåœ¨é€šé…ç¬¦è·¯ç”±ä¹‹å‰ï¼‰
@app.get("/topology", response_class=HTMLResponse)
async def topology_viewer():
    """3D ç¶²çµ¡æ‹“æ’²å¯è¦–åŒ–é é¢"""
    try:
        html_file = os.path.join(os.path.dirname(__file__), "topology-3d.html")
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        return HTMLResponse(content=html_content)
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>éŒ¯èª¤</h1><p>æ‰¾ä¸åˆ° topology-3d.html æ–‡ä»¶</p>",
            status_code=404
        )
    except Exception as e:
        return HTMLResponse(
            content=f"<h1>éŒ¯èª¤</h1><p>è®€å–æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}</p>",
            status_code=500
        )


# å¥åº·æª¢æŸ¥ç«¯é»
@app.get("/health")
async def health():
    """ç¶²é—œå¥åº·æª¢æŸ¥"""
    healthy_nodes = sum(1 for node in NODES if node_stats[node["name"]]["is_healthy"])
    return {
        "status": "healthy" if healthy_nodes > 0 else "degraded",
        "healthy_nodes": healthy_nodes,
        "total_nodes": len(NODES),
        "nodes": {
            node["name"]: {
                "healthy": node_stats[node["name"]]["is_healthy"],
                "active_connections": node_stats[node["name"]]["active_connections"],
                "total_requests": node_stats[node["name"]]["total_requests"],
                "failed_requests": node_stats[node["name"]]["failed_requests"],
            }
            for node in NODES
        }
    }


# ç¯€é»ç‹€æ…‹ç«¯é»
@app.get("/nodes")
async def get_nodes():
    """ç²å–æ‰€æœ‰ç¯€é»ç‹€æ…‹"""
    return {
        "scheduling_strategy": SCHEDULING_STRATEGY,
        "nodes": [
            {
                "name": node["name"],
                "hosts": node["hosts"],
                "port": node["port"],
                "weight": node["weight"],
                "enabled": node.get("enabled", True),
                "stats": node_stats[node["name"]],
                "models": list(node_models.get(node["name"], set())),
                "config": node_config.get(node["name"], {}),
            }
            for node in NODES
        ]
    }


# Prometheus metricsç«¯é»
@app.get("/metrics")
async def metrics():
    """Prometheus metrics"""
    return MetricsResponse(generate_latest(), media_type=CONTENT_TYPE_LATEST)


# ä»£ç†æ‰€æœ‰Ollama APIè«‹æ±‚ï¼ˆå¿…é ˆæ”¾åœ¨æœ€å¾Œï¼Œä½œç‚ºé€šé…ç¬¦è·¯ç”±ï¼‰
@app.api_route("/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"])
async def proxy_all(request: Request, path: str):
    """ä»£ç†æ‰€æœ‰è«‹æ±‚åˆ°Ollamaç¯€é»"""
    return await proxy_request(request, f"/{path}")


if __name__ == "__main__":
    gateway_port = int(os.getenv("GATEWAY_PORT", "11435"))
    uvicorn.run(app, host="0.0.0.0", port=gateway_port)

