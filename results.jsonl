{"task_id": "HumanEval/0", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 35.306241035461426, "exec_time_s": 0.03598523139953613, "stdout": "", "stderr": "", "error": null, "eval_count": 369, "prompt_eval_count": 265, "eval_tokens_per_sec": 43.902849757618675, "prompt_tokens_per_sec": 30.106074634554982, "eval_duration_ns": 8404921367, "prompt_eval_duration_ns": 8802210292, "code": "from typing import List\n\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\n    \"\"\"Check if any two numbers in the list are closer than the given threshold.\n\n    Args:\n        numbers: List of numeric values.\n        threshold: Positive distance threshold.\n\n    Returns:\n        True if there exists at least one pair (i, j) with i != j such that\n        abs(numbers[i] - numbers[j]) < threshold, otherwise False.\n\n    Examples:\n        >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n        False\n        >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n        True\n    \"\"\"\n    if len(numbers) < 2:\n        return False\n\n    # Sort to bring closest values next to each other\n    sorted_nums = sorted(numbers)\n    for a, b in zip(sorted_nums, sorted_nums[1:]):\n        if b - a < threshold:\n            return True\n    return False", "response_raw": "from typing import List\n\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\n    \"\"\"Check if any two numbers in the list are closer than the given threshold.\n\n    Args:\n        numbers: List of numeric values.\n        threshold: Positive distance threshold.\n\n    Returns:\n        True if there exists at least one pair (i, j) with i != j such that\n        abs(numbers[i] - numbers[j]) < threshold, otherwise False.\n\n    Examples:\n        >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n        False\n        >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n        True\n    \"\"\"\n    if len(numbers) < 2:\n        return False\n\n    # Sort to bring closest values next to each other\n    sorted_nums = sorted(numbers)\n    for a, b in zip(sorted_nums, sorted_nums[1:]):\n        if b - a < threshold:\n            return True\n    return False"}
{"task_id": "HumanEval/1", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.462346076965332, "exec_time_s": 0.03316926956176758, "stdout": "", "stderr": "", "error": null, "eval_count": 344, "prompt_eval_count": 255, "eval_tokens_per_sec": 44.277356819324346, "prompt_tokens_per_sec": 639.8070370077713, "eval_duration_ns": 7769208117, "prompt_eval_duration_ns": 398557667, "code": "from typing import List\n\ndef separate_paren_groups(paren_string: str) -> List[str]:\n    groups: List[str] = []\n    current = []\n    depth = 0\n    for ch in paren_string:\n        if ch == ' ':\n            continue\n        if ch == '(':\n            if depth == 0:\n                current = []\n            depth += 1\n            current.append(ch)\n        elif ch == ')':\n            current.append(ch)\n            depth -= 1\n            if depth == 0:\n                groups.append(''.join(current))\n        else:\n            # ignore any other characters (though spec implies only parentheses and spaces)\n            continue\n    return groups", "response_raw": "from typing import List\n\ndef separate_paren_groups(paren_string: str) -> List[str]:\n    groups: List[str] = []\n    current = []\n    depth = 0\n    for ch in paren_string:\n        if ch == ' ':\n            continue\n        if ch == '(':\n            if depth == 0:\n                current = []\n            depth += 1\n            current.append(ch)\n        elif ch == ')':\n            current.append(ch)\n            depth -= 1\n            if depth == 0:\n                groups.append(''.join(current))\n        else:\n            # ignore any other characters (though spec implies only parentheses and spaces)\n            continue\n    return groups"}
{"task_id": "HumanEval/2", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.00366473197937, "exec_time_s": 0.023769140243530273, "stdout": "", "stderr": "", "error": null, "eval_count": 199, "prompt_eval_count": 225, "eval_tokens_per_sec": 44.7818145226059, "prompt_tokens_per_sec": 613.6675362735676, "eval_duration_ns": 4443768126, "prompt_eval_duration_ns": 366648041, "code": "def truncate_number(number: float) -> float:\n    \"\"\"Return the decimal part of a positive floating point number.\n\n    The decimal part is the fractional component after removing the integer part.\n    \"\"\"\n    if number < 0:\n        raise ValueError(\"Number must be non-negative\")\n    return number - int(number)", "response_raw": "def truncate_number(number: float) -> float:\n    \"\"\"Return the decimal part of a positive floating point number.\n\n    The decimal part is the fractional component after removing the integer part.\n    \"\"\"\n    if number < 0:\n        raise ValueError(\"Number must be non-negative\")\n    return number - int(number)"}
{"task_id": "HumanEval/3", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.736151218414307, "exec_time_s": 0.0187380313873291, "stdout": "", "stderr": "", "error": null, "eval_count": 224, "prompt_eval_count": 258, "eval_tokens_per_sec": 43.93588981502724, "prompt_tokens_per_sec": 590.8316327363091, "eval_duration_ns": 5098337622, "prompt_eval_duration_ns": 436672625, "code": "from typing import List\n\ndef below_zero(operations: List[int]) -> bool:\n    \"\"\"You're given a list of deposit and withdrawal operations on a bank account that starts with\n    zero balance. Your task is to detect if at any point the balance of account falls below zero,\n    and at that point function should return True. Otherwise it should return False.\n\n    >>> below_zero([1, 2, 3])\n    False\n    >>> below_zero([1, 2, -4, 5])\n    True\n    \"\"\"\n    balance = 0\n    for op in operations:\n        balance += op\n        if balance < 0:\n            return True\n    return False", "response_raw": "from typing import List\n\ndef below_zero(operations: List[int]) -> bool:\n    \"\"\"You're given a list of deposit and withdrawal operations on a bank account that starts with\n    zero balance. Your task is to detect if at any point the balance of account falls below zero,\n    and at that point function should return True. Otherwise it should return False.\n\n    >>> below_zero([1, 2, 3])\n    False\n    >>> below_zero([1, 2, -4, 5])\n    True\n    \"\"\"\n    balance = 0\n    for op in operations:\n        balance += op\n        if balance < 0:\n            return True\n    return False"}
{"task_id": "HumanEval/4", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 4.899513244628906, "exec_time_s": 0.0317080020904541, "stdout": "", "stderr": "", "error": null, "eval_count": 194, "prompt_eval_count": 258, "eval_tokens_per_sec": 45.414533739340825, "prompt_tokens_per_sec": 616.3622681175866, "eval_duration_ns": 4271760250, "prompt_eval_duration_ns": 418585000, "code": "from typing import List\n\ndef mean_absolute_deviation(numbers: List[float]) -> float:\n    \"\"\"Calculate the Mean Absolute Deviation (MAD) around the mean of the dataset.\n\n    Args:\n        numbers: A list of numeric values.\n\n    Returns:\n        The MAD as a float. Returns 0.0 for an empty list.\n    \"\"\"\n    if not numbers:\n        return 0.0\n    mean_val = sum(numbers) / len(numbers)\n    mad = sum(abs(x - mean_val) for x in numbers) / len(numbers)\n    return mad", "response_raw": "from typing import List\n\ndef mean_absolute_deviation(numbers: List[float]) -> float:\n    \"\"\"Calculate the Mean Absolute Deviation (MAD) around the mean of the dataset.\n\n    Args:\n        numbers: A list of numeric values.\n\n    Returns:\n        The MAD as a float. Returns 0.0 for an empty list.\n    \"\"\"\n    if not numbers:\n        return 0.0\n    mean_val = sum(numbers) / len(numbers)\n    mad = sum(abs(x - mean_val) for x in numbers) / len(numbers)\n    return mad"}
{"task_id": "HumanEval/5", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.107301235198975, "exec_time_s": 0.03002333641052246, "stdout": "", "stderr": "", "error": null, "eval_count": 253, "prompt_eval_count": 238, "eval_tokens_per_sec": 45.73334030936089, "prompt_tokens_per_sec": 661.4582241759351, "eval_duration_ns": 5532069127, "prompt_eval_duration_ns": 359811083, "code": "from typing import List\n\ndef intersperse(numbers: List[int], delimeter: int) -> List[int]:\n    \"\"\"Insert a number 'delimeter' between every two consecutive elements of input list `numbers'.\n\n    >>> intersperse([], 4)\n    []\n    >>> intersperse([1, 2, 3], 4)\n    [1, 4, 2, 4, 3]\n    \"\"\"\n    if not numbers:\n        return []\n    result: List[int] = []\n    for i, num in enumerate(numbers):\n        result.append(num)\n        if i < len(numbers) - 1:\n            result.append(delimeter)\n    return result", "response_raw": "from typing import List\n\ndef intersperse(numbers: List[int], delimeter: int) -> List[int]:\n    \"\"\"Insert a number 'delimeter' between every two consecutive elements of input list `numbers'.\n\n    >>> intersperse([], 4)\n    []\n    >>> intersperse([1, 2, 3], 4)\n    [1, 4, 2, 4, 3]\n    \"\"\"\n    if not numbers:\n        return []\n    result: List[int] = []\n    for i, num in enumerate(numbers):\n        result.append(num)\n        if i < len(numbers) - 1:\n            result.append(delimeter)\n    return result"}
{"task_id": "HumanEval/6", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.164201974868774, "exec_time_s": 0.020228862762451172, "stdout": "", "stderr": "", "error": null, "eval_count": 209, "prompt_eval_count": 250, "eval_tokens_per_sec": 45.586581803488656, "prompt_tokens_per_sec": 640.6794966784971, "eval_duration_ns": 4584682416, "prompt_eval_duration_ns": 390210708, "code": "from typing import List\n\ndef parse_nested_parens(paren_string: str) -> List[int]:\n    if not paren_string:\n        return []\n    results = []\n    for group in paren_string.split():\n        max_depth = 0\n        current = 0\n        for ch in group:\n            if ch == '(':\n                current += 1\n                if current > max_depth:\n                    max_depth = current\n            elif ch == ')':\n                current -= 1\n        results.append(max_depth)\n    return results", "response_raw": "from typing import List\n\ndef parse_nested_parens(paren_string: str) -> List[int]:\n    if not paren_string:\n        return []\n    results = []\n    for group in paren_string.split():\n        max_depth = 0\n        current = 0\n        for ch in group:\n            if ch == '(':\n                current += 1\n                if current > max_depth:\n                    max_depth = current\n            elif ch == ')':\n                current -= 1\n        results.append(max_depth)\n    return results"}
{"task_id": "HumanEval/7", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.603321075439453, "exec_time_s": 0.02101922035217285, "stdout": "", "stderr": "", "error": null, "eval_count": 222, "prompt_eval_count": 233, "eval_tokens_per_sec": 44.04667144990239, "prompt_tokens_per_sec": 677.7766949834497, "eval_duration_ns": 5040108428, "prompt_eval_duration_ns": 343771041, "code": "from typing import List\n\ndef filter_by_substring(strings: List[str], substring: str) -> List[str]:\n    \"\"\" Filter an input list of strings only for ones that contain given substring\n    >>> filter_by_substring([], 'a')\n    []\n    >>> filter_by_substring(['abc', 'bacd', 'cde', 'array'], 'a')\n    ['abc', 'bacd', 'array']\n    \"\"\"\n    return [s for s in strings if substring in s]", "response_raw": "from typing import List\n\ndef filter_by_substring(strings: List[str], substring: str) -> List[str]:\n    \"\"\" Filter an input list of strings only for ones that contain given substring\n    >>> filter_by_substring([], 'a')\n    []\n    >>> filter_by_substring(['abc', 'bacd', 'cde', 'array'], 'a')\n    ['abc', 'bacd', 'array']\n    \"\"\"\n    return [s for s in strings if substring in s]"}
{"task_id": "HumanEval/8", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.678106784820557, "exec_time_s": 0.027348995208740234, "stdout": "", "stderr": "", "error": null, "eval_count": 196, "prompt_eval_count": 250, "eval_tokens_per_sec": 38.77299591942329, "prompt_tokens_per_sec": 632.2502635105293, "eval_duration_ns": 5055064623, "prompt_eval_duration_ns": 395413042, "code": "from typing import List, Tuple\nimport operator\nimport functools\n\ndef sum_product(numbers: List[int]) -> Tuple[int, int]:\n    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n    Empty sum should be equal to 0 and empty product should be equal to 1.\n    >>> sum_product([])\n    (0, 1)\n    >>> sum_product([1, 2, 3, 4])\n    (10, 24)\n    \"\"\"\n    total_sum = sum(numbers)\n    total_product = functools.reduce(operator.mul, numbers, 1)\n    return total_sum, total_product", "response_raw": "from typing import List, Tuple\nimport operator\nimport functools\n\ndef sum_product(numbers: List[int]) -> Tuple[int, int]:\n    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n    Empty sum should be equal to 0 and empty product should be equal to 1.\n    >>> sum_product([])\n    (0, 1)\n    >>> sum_product([1, 2, 3, 4])\n    (10, 24)\n    \"\"\"\n    total_sum = sum(numbers)\n    total_product = functools.reduce(operator.mul, numbers, 1)\n    return total_sum, total_product"}
{"task_id": "HumanEval/9", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 3.420090675354004, "exec_time_s": 0.029293060302734375, "stdout": "", "stderr": "", "error": null, "eval_count": 110, "prompt_eval_count": 240, "eval_tokens_per_sec": 39.29375950053671, "prompt_tokens_per_sec": 523.4816026774897, "eval_duration_ns": 2799426713, "prompt_eval_duration_ns": 458468834, "code": "from typing import List\n\ndef rolling_max(numbers: List[int]) -> List[int]:\n    result = []\n    current_max = None\n    for num in numbers:\n        if current_max is None or num > current_max:\n            current_max = num\n        result.append(current_max)\n    return result", "response_raw": "from typing import List\n\ndef rolling_max(numbers: List[int]) -> List[int]:\n    result = []\n    current_max = None\n    for num in numbers:\n        if current_max is None or num > current_max:\n            current_max = num\n        result.append(current_max)\n    return result"}
{"task_id": "HumanEval/10", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.647077798843384, "exec_time_s": 0.01943182945251465, "stdout": "", "stderr": "", "error": null, "eval_count": 556, "prompt_eval_count": 281, "eval_tokens_per_sec": 37.64547930269748, "prompt_tokens_per_sec": 517.3389480773741, "eval_duration_ns": 14769369664, "prompt_eval_duration_ns": 543164208, "code": "def make_palindrome(string: str) -> str:\n    \"\"\"Find the shortest palindrome that begins with a supplied string.\n\n    The algorithm:\n    - Find the longest suffix of the supplied string that is a palindrome.\n    - Append to the end of the string the reverse of the prefix that precedes this suffix.\n\n    Examples:\n    >>> make_palindrome('')\n    ''\n    >>> make_palindrome('cat')\n    'catac'\n    >>> make_palindrome('cata')\n    'catac'\n    \"\"\"\n    n = len(string)\n    if n == 0:\n        return \"\"\n    # Find the earliest index i such that string[i:] is a palindrome\n    for i in range(n):\n        if is_palindrome(string[i:]):\n            prefix = string[:i]\n            return string + prefix[::-1]\n    # Fallback (should never be reached because the last character is always a palindrome)\n    return string + string[:-1][::-1]", "response_raw": "def is_palindrome(string: str) -> bool:\n    \"\"\"Test if given string is a palindrome.\"\"\"\n    return string == string[::-1]\n\n\ndef make_palindrome(string: str) -> str:\n    \"\"\"Find the shortest palindrome that begins with a supplied string.\n\n    The algorithm:\n    - Find the longest suffix of the supplied string that is a palindrome.\n    - Append to the end of the string the reverse of the prefix that precedes this suffix.\n\n    Examples:\n    >>> make_palindrome('')\n    ''\n    >>> make_palindrome('cat')\n    'catac'\n    >>> make_palindrome('cata')\n    'catac'\n    \"\"\"\n    n = len(string)\n    if n == 0:\n        return \"\"\n    # Find the earliest index i such that string[i:] is a palindrome\n    for i in range(n):\n        if is_palindrome(string[i:]):\n            prefix = string[:i]\n            return string + prefix[::-1]\n    # Fallback (should never be reached because the last character is always a palindrome)\n    return string + string[:-1][::-1]"}
{"task_id": "HumanEval/11", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.744459867477417, "exec_time_s": 0.016707181930541992, "stdout": "", "stderr": "", "error": null, "eval_count": 186, "prompt_eval_count": 218, "eval_tokens_per_sec": 37.19427018548366, "prompt_tokens_per_sec": 393.0284618645989, "eval_duration_ns": 5000770255, "prompt_eval_duration_ns": 554667209, "code": "def string_xor(a: str, b: str) -> str:\n    \"\"\"Input are two strings a and b consisting only of 1s and 0s.\n    Perform binary XOR on these inputs and return result also as a string.\n    >>> string_xor('010', '110')\n    '100'\n    \"\"\"\n    if len(a) != len(b):\n        raise ValueError(\"Input strings must have the same length\")\n    return ''.join('1' if x != y else '0' for x, y in zip(a, b))", "response_raw": "def string_xor(a: str, b: str) -> str:\n    \"\"\"Input are two strings a and b consisting only of 1s and 0s.\n    Perform binary XOR on these inputs and return result also as a string.\n    >>> string_xor('010', '110')\n    '100'\n    \"\"\"\n    if len(a) != len(b):\n        raise ValueError(\"Input strings must have the same length\")\n    return ''.join('1' if x != y else '0' for x, y in zip(a, b))"}
{"task_id": "HumanEval/12", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.289007902145386, "exec_time_s": 0.03093695640563965, "stdout": "", "stderr": "", "error": null, "eval_count": 374, "prompt_eval_count": 242, "eval_tokens_per_sec": 32.418315643318124, "prompt_tokens_per_sec": 498.86030004797925, "eval_duration_ns": 11536688214, "prompt_eval_duration_ns": 485105750, "code": "from typing import List, Optional\n\ndef longest(strings: List[str]) -> Optional[str]:\n    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\n    strings of the same length. Return None in case the input list is empty.\n    >>> longest([])\n\n    >>> longest(['a', 'b', 'c'])\n    'a'\n    >>> longest(['a', 'bb', 'ccc'])\n    'ccc'\n    \"\"\"\n    if not strings:\n        return None\n    longest_str = strings[0]\n    max_len = len(strings[0])\n    for s in strings[1:]:\n        l = len(s)\n        if l > max_len:\n            longest_str = s\n            max_len = l\n    return longest_str", "response_raw": "from typing import List, Optional\n\ndef longest(strings: List[str]) -> Optional[str]:\n    \"\"\" Out of list of strings, return the longest one. Return the first one in case of multiple\n    strings of the same length. Return None in case the input list is empty.\n    >>> longest([])\n\n    >>> longest(['a', 'b', 'c'])\n    'a'\n    >>> longest(['a', 'bb', 'ccc'])\n    'ccc'\n    \"\"\"\n    if not strings:\n        return None\n    longest_str = strings[0]\n    max_len = len(strings[0])\n    for s in strings[1:]:\n        l = len(s)\n        if l > max_len:\n            longest_str = s\n            max_len = l\n    return longest_str"}
{"task_id": "HumanEval/13", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.408728122711182, "exec_time_s": 0.028254985809326172, "stdout": "", "stderr": "", "error": null, "eval_count": 294, "prompt_eval_count": 211, "eval_tokens_per_sec": 27.48339751630089, "prompt_tokens_per_sec": 435.56175984497304, "eval_duration_ns": 10697367377, "prompt_eval_duration_ns": 484431875, "code": "def greatest_common_divisor(a: int, b: int) -> int:\n    \"\"\" Return a greatest common divisor of two integers a and b\n    >>> greatest_common_divisor(3, 5)\n    1\n    >>> greatest_common_divisor(25, 15)\n    5\n    \"\"\"\n    a, b = abs(a), abs(b)\n    while b:\n        a, b = b, a % b\n    return a", "response_raw": "def greatest_common_divisor(a: int, b: int) -> int:\n    \"\"\" Return a greatest common divisor of two integers a and b\n    >>> greatest_common_divisor(3, 5)\n    1\n    >>> greatest_common_divisor(25, 15)\n    5\n    \"\"\"\n    a, b = abs(a), abs(b)\n    while b:\n        a, b = b, a % b\n    return a"}
{"task_id": "HumanEval/14", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.924347162246704, "exec_time_s": 0.0402979850769043, "stdout": "", "stderr": "", "error": null, "eval_count": 243, "prompt_eval_count": 199, "eval_tokens_per_sec": 22.20085520555695, "prompt_tokens_per_sec": 268.94738845375645, "eval_duration_ns": 10945524294, "prompt_eval_duration_ns": 739921667, "code": "from typing import List\n\ndef all_prefixes(string: str) -> List[str]:\n    \"\"\"Return list of all prefixes from shortest to longest of the input string.\n    >>> all_prefixes('abc')\n    ['a', 'ab', 'abc']\n    \"\"\"\n    return [string[:i] for i in range(1, len(string) + 1)]", "response_raw": "from typing import List\n\ndef all_prefixes(string: str) -> List[str]:\n    \"\"\"Return list of all prefixes from shortest to longest of the input string.\n    >>> all_prefixes('abc')\n    ['a', 'ab', 'abc']\n    \"\"\"\n    return [string[:i] for i in range(1, len(string) + 1)]"}
{"task_id": "HumanEval/15", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 20.18920397758484, "exec_time_s": 0.041152000427246094, "stdout": "", "stderr": "", "error": null, "eval_count": 252, "prompt_eval_count": 209, "eval_tokens_per_sec": 13.549150732737083, "prompt_tokens_per_sec": 195.94912682514249, "eval_duration_ns": 18598951696, "prompt_eval_duration_ns": 1066603375, "code": "def string_sequence(n: int) -> str:\n    \"\"\"Return a string containing space-delimited numbers starting from 0 up to n inclusive.\n\n    Args:\n        n (int): The upper bound of the sequence (must be non‑negative).\n\n    Returns:\n        str: Space‑separated numbers from 0 to n.\n\n    Examples:\n        >>> string_sequence(0)\n        '0'\n        >>> string_sequence(5)\n        '0 1 2 3 4 5'\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    return \" \".join(str(i) for i in range(n + 1))", "response_raw": "def string_sequence(n: int) -> str:\n    \"\"\"Return a string containing space-delimited numbers starting from 0 up to n inclusive.\n\n    Args:\n        n (int): The upper bound of the sequence (must be non‑negative).\n\n    Returns:\n        str: Space‑separated numbers from 0 to n.\n\n    Examples:\n        >>> string_sequence(0)\n        '0'\n        >>> string_sequence(5)\n        '0 1 2 3 4 5'\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    return \" \".join(str(i) for i in range(n + 1))"}
{"task_id": "HumanEval/16", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.027053117752075, "exec_time_s": 0.04655790328979492, "stdout": "", "stderr": "", "error": null, "eval_count": 190, "prompt_eval_count": 214, "eval_tokens_per_sec": 14.313098136277622, "prompt_tokens_per_sec": 153.05015911362736, "eval_duration_ns": 13274554411, "prompt_eval_duration_ns": 1398234417, "code": "def count_distinct_characters(string: str) -> int:\n    \"\"\"Given a string, find out how many distinct characters (regardless of case) it consists of.\"\"\"\n    return len({ch.lower() for ch in string})", "response_raw": "def count_distinct_characters(string: str) -> int:\n    \"\"\"Given a string, find out how many distinct characters (regardless of case) it consists of.\"\"\"\n    return len({ch.lower() for ch in string})"}
{"task_id": "HumanEval/17", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 19.685282945632935, "exec_time_s": 0.06333208084106445, "stdout": "", "stderr": "", "error": null, "eval_count": 218, "prompt_eval_count": 310, "eval_tokens_per_sec": 12.662422498701403, "prompt_tokens_per_sec": 168.10888581293733, "eval_duration_ns": 17216294909, "prompt_eval_duration_ns": 1844042916, "code": "from typing import List\n\ndef parse_music(music_string: str) -> List[int]:\n    token_to_beats = {\n        'o': 4,\n        'o|': 2,\n        '.|': 1,\n    }\n    if not music_string:\n        return []\n    return [token_to_beats.get(token, 0) for token in music_string.split()]", "response_raw": "from typing import List\n\ndef parse_music(music_string: str) -> List[int]:\n    token_to_beats = {\n        'o': 4,\n        'o|': 2,\n        '.|': 1,\n    }\n    if not music_string:\n        return []\n    return [token_to_beats.get(token, 0) for token in music_string.split()]"}
{"task_id": "HumanEval/18", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 17.408491134643555, "exec_time_s": 0.027945280075073242, "stdout": "", "stderr": "", "error": null, "eval_count": 229, "prompt_eval_count": 229, "eval_tokens_per_sec": 14.649333189252983, "prompt_tokens_per_sec": 168.60167980003442, "eval_duration_ns": 15632110830, "prompt_eval_duration_ns": 1358230833, "code": "def how_many_times(string: str, substring: str) -> int:\n    \"\"\"Find how many times a given substring can be found in the original string, counting overlapping cases.\"\"\"\n    if not substring:\n        return 0\n    count = 0\n    sub_len = len(substring)\n    for i in range(len(string) - sub_len + 1):\n        if string[i:i + sub_len] == substring:\n            count += 1\n    return count", "response_raw": "def how_many_times(string: str, substring: str) -> int:\n    \"\"\"Find how many times a given substring can be found in the original string, counting overlapping cases.\"\"\"\n    if not substring:\n        return 0\n    count = 0\n    sub_len = len(substring)\n    for i in range(len(string) - sub_len + 1):\n        if string[i:i + sub_len] == substring:\n            count += 1\n    return count"}
{"task_id": "HumanEval/19", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 18.58465003967285, "exec_time_s": 0.031330108642578125, "stdout": "", "stderr": "", "error": null, "eval_count": 307, "prompt_eval_count": 245, "eval_tokens_per_sec": 18.35408086705558, "prompt_tokens_per_sec": 165.9751225118777, "eval_duration_ns": 16726525410, "prompt_eval_duration_ns": 1476124833, "code": "from typing import List\n\ndef sort_numbers(numbers: str) -> str:\n    \"\"\" Input is a space-delimited string of numberals from 'zero' to 'nine'.\n    Valid choices are 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight' and 'nine'.\n    Return the string with numbers sorted from smallest to largest\n    >>> sort_numbers('three one five')\n    'one three five'\n    \"\"\"\n    order = {\n        'zero': 0,\n        'one': 1,\n        'two': 2,\n        'three': 3,\n        'four': 4,\n        'five': 5,\n        'six': 6,\n        'seven': 7,\n        'eight': 8,\n        'nine': 9\n    }\n    if not numbers.strip():\n        return ''\n    words = numbers.split()\n    sorted_words = sorted(words, key=lambda w: order[w])\n    return ' '.join(sorted_words)", "response_raw": "from typing import List\n\ndef sort_numbers(numbers: str) -> str:\n    \"\"\" Input is a space-delimited string of numberals from 'zero' to 'nine'.\n    Valid choices are 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight' and 'nine'.\n    Return the string with numbers sorted from smallest to largest\n    >>> sort_numbers('three one five')\n    'one three five'\n    \"\"\"\n    order = {\n        'zero': 0,\n        'one': 1,\n        'two': 2,\n        'three': 3,\n        'four': 4,\n        'five': 5,\n        'six': 6,\n        'seven': 7,\n        'eight': 8,\n        'nine': 9\n    }\n    if not numbers.strip():\n        return ''\n    words = numbers.split()\n    sorted_words = sorted(words, key=lambda w: order[w])\n    return ' '.join(sorted_words)"}
{"task_id": "HumanEval/20", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 19.160084009170532, "exec_time_s": 0.02022719383239746, "stdout": "", "stderr": "", "error": null, "eval_count": 395, "prompt_eval_count": 308, "eval_tokens_per_sec": 22.296040026803862, "prompt_tokens_per_sec": 262.59562912201284, "eval_duration_ns": 17716150470, "prompt_eval_duration_ns": 1172906042, "code": "from typing import List, Tuple\n\ndef find_closest_elements(numbers: List[float]) -> Tuple[float, float]:\n    if len(numbers) < 2:\n        raise ValueError(\"At least two numbers are required\")\n    sorted_nums = sorted(numbers)\n    min_diff = float('inf')\n    result = (sorted_nums[0], sorted_nums[1])\n    for i in range(len(sorted_nums) - 1):\n        a, b = sorted_nums[i], sorted_nums[i + 1]\n        diff = b - a\n        if diff < min_diff:\n            min_diff = diff\n            result = (a, b)\n            if min_diff == 0:\n                break\n    return result", "response_raw": "from typing import List, Tuple\n\ndef find_closest_elements(numbers: List[float]) -> Tuple[float, float]:\n    if len(numbers) < 2:\n        raise ValueError(\"At least two numbers are required\")\n    sorted_nums = sorted(numbers)\n    min_diff = float('inf')\n    result = (sorted_nums[0], sorted_nums[1])\n    for i in range(len(sorted_nums) - 1):\n        a, b = sorted_nums[i], sorted_nums[i + 1]\n        diff = b - a\n        if diff < min_diff:\n            min_diff = diff\n            result = (a, b)\n            if min_diff == 0:\n                break\n    return result"}
{"task_id": "HumanEval/21", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 16.72689414024353, "exec_time_s": 0.023685216903686523, "stdout": "", "stderr": "", "error": null, "eval_count": 384, "prompt_eval_count": 265, "eval_tokens_per_sec": 24.611897544943762, "prompt_tokens_per_sec": 308.9463126143634, "eval_duration_ns": 15602210244, "prompt_eval_duration_ns": 857754209, "code": "from typing import List\n\ndef rescale_to_unit(numbers: List[float]) -> List[float]:\n    \"\"\"Given list of numbers (of at least two elements), apply a linear transform to that list,\n    such that the smallest number will become 0 and the largest will become 1.\n    Example:\n    >>> rescale_to_unit([1.0, 2.0, 3.0, 4.0, 5.0])\n    [0.0, 0.25, 0.5, 0.75, 1.0]\n    \"\"\"\n    if not numbers:\n        raise ValueError(\"Input list must contain at least one element\")\n    min_val = min(numbers)\n    max_val = max(numbers)\n    if max_val == min_val:\n        return [0.0 for _ in numbers]\n    scale = max_val - min_val\n    return [(x - min_val) / scale for x in numbers]", "response_raw": "from typing import List\n\ndef rescale_to_unit(numbers: List[float]) -> List[float]:\n    \"\"\"Given list of numbers (of at least two elements), apply a linear transform to that list,\n    such that the smallest number will become 0 and the largest will become 1.\n    Example:\n    >>> rescale_to_unit([1.0, 2.0, 3.0, 4.0, 5.0])\n    [0.0, 0.25, 0.5, 0.75, 1.0]\n    \"\"\"\n    if not numbers:\n        raise ValueError(\"Input list must contain at least one element\")\n    min_val = min(numbers)\n    max_val = max(numbers)\n    if max_val == min_val:\n        return [0.0 for _ in numbers]\n    scale = max_val - min_val\n    return [(x - min_val) / scale for x in numbers]"}
{"task_id": "HumanEval/22", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 13.50342583656311, "exec_time_s": 0.029848098754882812, "stdout": "", "stderr": "", "error": null, "eval_count": 305, "prompt_eval_count": 234, "eval_tokens_per_sec": 24.5986163640903, "prompt_tokens_per_sec": 294.20380780193295, "eval_duration_ns": 12399071374, "prompt_eval_duration_ns": 795367000, "code": "from typing import List, Any\n\ndef filter_integers(values: List[Any]) -> List[int]:\n    \"\"\" Filter given list of any python values only for integers\n    >>> filter_integers(['a', 3.14, 5])\n    [5]\n    >>> filter_integers([1, 2, 3, 'abc', {}, []])\n    [1, 2, 3]\n    \"\"\"\n    return [v for v in values if isinstance(v, int) and not isinstance(v, bool)]", "response_raw": "from typing import List, Any\n\ndef filter_integers(values: List[Any]) -> List[int]:\n    \"\"\" Filter given list of any python values only for integers\n    >>> filter_integers(['a', 3.14, 5])\n    [5]\n    >>> filter_integers([1, 2, 3, 'abc', {}, []])\n    [1, 2, 3]\n    \"\"\"\n    return [v for v in values if isinstance(v, int) and not isinstance(v, bool)]"}
{"task_id": "HumanEval/23", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.480774879455566, "exec_time_s": 0.028673887252807617, "stdout": "", "stderr": "", "error": null, "eval_count": 218, "prompt_eval_count": 184, "eval_tokens_per_sec": 22.607341089190978, "prompt_tokens_per_sec": 361.88825028506074, "eval_duration_ns": 9642885430, "prompt_eval_duration_ns": 508444250, "code": "def strlen(string: str) -> int:\n    \"\"\" Return length of given string\n    >>> strlen('')\n    0\n    >>> strlen('abc')\n    3\n    \"\"\"\n    return len(string)", "response_raw": "def strlen(string: str) -> int:\n    \"\"\" Return length of given string\n    >>> strlen('')\n    0\n    >>> strlen('abc')\n    3\n    \"\"\"\n    return len(string)"}
{"task_id": "HumanEval/24", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 20.338310956954956, "exec_time_s": 0.02370595932006836, "stdout": "", "stderr": "", "error": null, "eval_count": 467, "prompt_eval_count": 193, "eval_tokens_per_sec": 24.207121833813666, "prompt_tokens_per_sec": 301.81407051629606, "eval_duration_ns": 19291843252, "prompt_eval_duration_ns": 639466542, "code": "def largest_divisor(n: int) -> int:\n    \"\"\"Return the largest divisor of n that is smaller than n.\"\"\"\n    if n <= 1:\n        return 0\n    limit = int(n ** 0.5)\n    for i in range(2, limit + 1):\n        if n % i == 0:\n            return n // i\n    return 1", "response_raw": "def largest_divisor(n: int) -> int:\n    \"\"\"Return the largest divisor of n that is smaller than n.\"\"\"\n    if n <= 1:\n        return 0\n    limit = int(n ** 0.5)\n    for i in range(2, limit + 1):\n        if n % i == 0:\n            return n // i\n    return 1"}
{"task_id": "HumanEval/25", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.537138938903809, "exec_time_s": 0.023416757583618164, "stdout": "", "stderr": "", "error": null, "eval_count": 269, "prompt_eval_count": 266, "eval_tokens_per_sec": 25.856019965224288, "prompt_tokens_per_sec": 313.981918668952, "eval_duration_ns": 10403766719, "prompt_eval_duration_ns": 847182542, "code": "from typing import List\nimport math\n\ndef factorize(n: int) -> List[int]:\n    \"\"\"Return list of prime factors of given integer in ascending order with multiplicities.\"\"\"\n    if n < 2:\n        return []\n    factors: List[int] = []\n    # handle factor 2 separately for efficiency\n    while n % 2 == 0:\n        factors.append(2)\n        n //= 2\n    # check odd factors up to sqrt(n)\n    limit = int(math.isqrt(n)) + 1\n    f = 3\n    while f <= limit and n > 1:\n        while n % f == 0:\n            factors.append(f)\n            n //= f\n            limit = int(math.isqrt(n)) + 1\n        f += 2\n    if n > 1:\n        factors.append(n)\n    return factors", "response_raw": "from typing import List\nimport math\n\ndef factorize(n: int) -> List[int]:\n    \"\"\"Return list of prime factors of given integer in ascending order with multiplicities.\"\"\"\n    if n < 2:\n        return []\n    factors: List[int] = []\n    # handle factor 2 separately for efficiency\n    while n % 2 == 0:\n        factors.append(2)\n        n //= 2\n    # check odd factors up to sqrt(n)\n    limit = int(math.isqrt(n)) + 1\n    f = 3\n    while f <= limit and n > 1:\n        while n % f == 0:\n            factors.append(f)\n            n //= f\n            limit = int(math.isqrt(n)) + 1\n        f += 2\n    if n > 1:\n        factors.append(n)\n    return factors"}
{"task_id": "HumanEval/26", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.039121150970459, "exec_time_s": 0.023691892623901367, "stdout": "", "stderr": "", "error": null, "eval_count": 201, "prompt_eval_count": 224, "eval_tokens_per_sec": 24.89558330678117, "prompt_tokens_per_sec": 309.09619032045964, "eval_duration_ns": 8073721251, "prompt_eval_duration_ns": 724693500, "code": "from typing import List\nfrom collections import Counter\n\ndef remove_duplicates(numbers: List[int]) -> List[int]:\n    \"\"\"From a list of integers, remove all elements that occur more than once.\n    Keep order of elements left the same as in the input.\n    >>> remove_duplicates([1, 2, 3, 2, 4])\n    [1, 3, 4]\n    \"\"\"\n    counts = Counter(numbers)\n    return [num for num in numbers if counts[num] == 1]", "response_raw": "from typing import List\nfrom collections import Counter\n\ndef remove_duplicates(numbers: List[int]) -> List[int]:\n    \"\"\"From a list of integers, remove all elements that occur more than once.\n    Keep order of elements left the same as in the input.\n    >>> remove_duplicates([1, 2, 3, 2, 4])\n    [1, 3, 4]\n    \"\"\"\n    counts = Counter(numbers)\n    return [num for num in numbers if counts[num] == 1]"}
{"task_id": "HumanEval/27", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.016376256942749, "exec_time_s": 0.03307318687438965, "stdout": "", "stderr": "", "error": null, "eval_count": 191, "prompt_eval_count": 189, "eval_tokens_per_sec": 26.30932434327577, "prompt_tokens_per_sec": 374.7659883835869, "eval_duration_ns": 7259783547, "prompt_eval_duration_ns": 504314708, "code": "def flip_case(string: str) -> str:\n    \"\"\"For a given string, flip lowercase characters to uppercase and uppercase to lowercase.\n\n    >>> flip_case('Hello')\n    'hELLO'\n    \"\"\"\n    return string.swapcase()", "response_raw": "def flip_case(string: str) -> str:\n    \"\"\"For a given string, flip lowercase characters to uppercase and uppercase to lowercase.\n\n    >>> flip_case('Hello')\n    'hELLO'\n    \"\"\"\n    return string.swapcase()"}
{"task_id": "HumanEval/28", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.165982007980347, "exec_time_s": 0.018357038497924805, "stdout": "", "stderr": "", "error": null, "eval_count": 115, "prompt_eval_count": 197, "eval_tokens_per_sec": 27.656550745411828, "prompt_tokens_per_sec": 441.32200241556365, "eval_duration_ns": 4158146873, "prompt_eval_duration_ns": 446386083, "code": "from typing import List\n\ndef concatenate(strings: List[str]) -> str:\n    \"\"\"Concatenate list of strings into a single string.\n\n    >>> concatenate([])\n    ''\n    >>> concatenate(['a', 'b', 'c'])\n    'abc'\n    \"\"\"\n    return ''.join(strings)", "response_raw": "from typing import List\n\ndef concatenate(strings: List[str]) -> str:\n    \"\"\"Concatenate list of strings into a single string.\n\n    >>> concatenate([])\n    ''\n    >>> concatenate(['a', 'b', 'c'])\n    'abc'\n    \"\"\"\n    return ''.join(strings)"}
{"task_id": "HumanEval/29", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.175554037094116, "exec_time_s": 0.0305478572845459, "stdout": "", "stderr": "", "error": null, "eval_count": 163, "prompt_eval_count": 228, "eval_tokens_per_sec": 29.507648120625632, "prompt_tokens_per_sec": 511.4814587331858, "eval_duration_ns": 5523991588, "prompt_eval_duration_ns": 445763959, "code": "from typing import List\n\ndef filter_by_prefix(strings: List[str], prefix: str) -> List[str]:\n    \"\"\" Filter an input list of strings only for ones that start with a given prefix.\n    >>> filter_by_prefix([], 'a')\n    []\n    >>> filter_by_prefix(['abc', 'bcd', 'cde', 'array'], 'a')\n    ['abc', 'array']\n    \"\"\"\n    return [s for s in strings if s.startswith(prefix)]", "response_raw": "from typing import List\n\ndef filter_by_prefix(strings: List[str], prefix: str) -> List[str]:\n    \"\"\" Filter an input list of strings only for ones that start with a given prefix.\n    >>> filter_by_prefix([], 'a')\n    []\n    >>> filter_by_prefix(['abc', 'bcd', 'cde', 'array'], 'a')\n    ['abc', 'array']\n    \"\"\"\n    return [s for s in strings if s.startswith(prefix)]"}
{"task_id": "HumanEval/30", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.042630910873413, "exec_time_s": 0.025003910064697266, "stdout": "", "stderr": "", "error": null, "eval_count": 205, "prompt_eval_count": 254, "eval_tokens_per_sec": 28.74382055863675, "prompt_tokens_per_sec": 418.64554978956465, "eval_duration_ns": 7131967707, "prompt_eval_duration_ns": 606718500, "code": "def get_positive(l: list):\n    \"\"\"Return only positive numbers in the list.\n    >>> get_positive([-1, 2, -4, 5, 6])\n    [2, 5, 6]\n    >>> get_positive([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n    [5, 3, 2, 3, 9, 123, 1]\n    \"\"\"\n    return [x for x in l if x > 0]", "response_raw": "def get_positive(l: list):\n    \"\"\"Return only positive numbers in the list.\n    >>> get_positive([-1, 2, -4, 5, 6])\n    [2, 5, 6]\n    >>> get_positive([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n    [5, 3, 2, 3, 9, 123, 1]\n    \"\"\"\n    return [x for x in l if x > 0]"}
{"task_id": "HumanEval/31", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.341214179992676, "exec_time_s": 0.024168968200683594, "stdout": "", "stderr": "", "error": null, "eval_count": 328, "prompt_eval_count": 240, "eval_tokens_per_sec": 31.377341529627465, "prompt_tokens_per_sec": 372.8130240440447, "eval_duration_ns": 10453403125, "prompt_eval_duration_ns": 643754334, "code": "def is_prime(n):\n    \"\"\"Return true if a given number is prime, and false otherwise.\n    >>> is_prime(6)\n    False\n    >>> is_prime(101)\n    True\n    >>> is_prime(11)\n    True\n    >>> is_prime(13441)\n    True\n    >>> is_prime(61)\n    True\n    >>> is_prime(4)\n    False\n    >>> is_prime(1)\n    False\n    \"\"\"\n    if n <= 1:\n        return False\n    if n <= 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    i = 5\n    w = 2\n    while i * i <= n:\n        if n % i == 0:\n            return False\n        i += w\n        w = 6 - w\n    return True", "response_raw": "def is_prime(n):\n    \"\"\"Return true if a given number is prime, and false otherwise.\n    >>> is_prime(6)\n    False\n    >>> is_prime(101)\n    True\n    >>> is_prime(11)\n    True\n    >>> is_prime(13441)\n    True\n    >>> is_prime(61)\n    True\n    >>> is_prime(4)\n    False\n    >>> is_prime(1)\n    False\n    \"\"\"\n    if n <= 1:\n        return False\n    if n <= 3:\n        return True\n    if n % 2 == 0 or n % 3 == 0:\n        return False\n    i = 5\n    w = 2\n    while i * i <= n:\n        if n % i == 0:\n            return False\n        i += w\n        w = 6 - w\n    return True"}
{"task_id": "HumanEval/32", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 33.72203207015991, "exec_time_s": 0.033203125, "stdout": "", "stderr": "", "error": null, "eval_count": 935, "prompt_eval_count": 400, "eval_tokens_per_sec": 29.07065661223465, "prompt_tokens_per_sec": 404.41603750256684, "eval_duration_ns": 32163016215, "prompt_eval_duration_ns": 989080459, "code": "def find_zero(xs: list):\n    \"\"\"\n    xs are coefficients of a polynomial.\n    find_zero find x such that poly(x) = 0.\n    find_zero returns only only zero point, even if there are many.\n    Moreover, find_zero only takes list xs having even number of coefficients\n    and largest non zero coefficient as it guarantees a solution.\n    \"\"\"\n    # Helper to evaluate polynomial\n    def f(val):\n        return poly(xs, val)\n\n    # Start with an interval around zero\n    left, right = -1.0, 1.0\n    f_left, f_right = f(left), f(right)\n\n    # Expand interval exponentially until a sign change is found\n    while f_left * f_right > 0:\n        left *= 2.0\n        right *= 2.0\n        f_left, f_right = f(left), f(right)\n        # Safety break to avoid infinite loop (should not happen for odd-degree polynomials)\n        if abs(left) > 1e12:\n            break\n\n    # Bisection method for root refinement\n    for _ in range(100):\n        mid = (left + right) / 2.0\n        f_mid = f(mid)\n\n        if f_mid == 0:\n            return mid\n\n        if f_left * f_mid <= 0:\n            right = mid\n            f_right = f_mid\n        else:\n            left = mid\n            f_left = f_mid\n\n    return (left + right) / 2.0", "response_raw": "import math\n\ndef poly(xs: list, x: float):\n    \"\"\"\n    Evaluates polynomial with coefficients xs at point x.\n    return xs[0] + xs[1] * x + xs[1] * x^2 + .... xs[n] * x^n\n    \"\"\"\n    return sum(coeff * math.pow(x, i) for i, coeff in enumerate(xs))\n\ndef find_zero(xs: list):\n    \"\"\"\n    xs are coefficients of a polynomial.\n    find_zero find x such that poly(x) = 0.\n    find_zero returns only only zero point, even if there are many.\n    Moreover, find_zero only takes list xs having even number of coefficients\n    and largest non zero coefficient as it guarantees a solution.\n    \"\"\"\n    # Helper to evaluate polynomial\n    def f(val):\n        return poly(xs, val)\n\n    # Start with an interval around zero\n    left, right = -1.0, 1.0\n    f_left, f_right = f(left), f(right)\n\n    # Expand interval exponentially until a sign change is found\n    while f_left * f_right > 0:\n        left *= 2.0\n        right *= 2.0\n        f_left, f_right = f(left), f(right)\n        # Safety break to avoid infinite loop (should not happen for odd-degree polynomials)\n        if abs(left) > 1e12:\n            break\n\n    # Bisection method for root refinement\n    for _ in range(100):\n        mid = (left + right) / 2.0\n        f_mid = f(mid)\n\n        if f_mid == 0:\n            return mid\n\n        if f_left * f_mid <= 0:\n            right = mid\n            f_right = f_mid\n        else:\n            left = mid\n            f_left = f_mid\n\n    return (left + right) / 2.0"}
{"task_id": "HumanEval/33", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 18.739202976226807, "exec_time_s": 0.0266420841217041, "stdout": "", "stderr": "", "error": null, "eval_count": 535, "prompt_eval_count": 294, "eval_tokens_per_sec": 30.357388309597116, "prompt_tokens_per_sec": 393.7155061275169, "eval_duration_ns": 17623386918, "prompt_eval_duration_ns": 746732083, "code": "def sort_third(l: list) -> list:\n    \"\"\"Return a list where elements at indices divisible by 3 are sorted,\n    while other elements remain in their original positions.\n\n    >>> sort_third([1, 2, 3])\n    [1, 2, 3]\n    >>> sort_third([5, 6, 3, 4, 8, 9, 2])\n    [2, 6, 3, 4, 8, 9, 5]\n    \"\"\"\n    if not l:\n        return []\n    # Indices that are multiples of 3 (including 0)\n    idx = [i for i in range(len(l)) if i % 3 == 0]\n    # Extract and sort the corresponding values\n    sorted_vals = sorted(l[i] for i in idx)\n    # Build the result list\n    result = list(l)\n    for i, val in zip(idx, sorted_vals):\n        result[i] = val\n    return result", "response_raw": "def sort_third(l: list) -> list:\n    \"\"\"Return a list where elements at indices divisible by 3 are sorted,\n    while other elements remain in their original positions.\n\n    >>> sort_third([1, 2, 3])\n    [1, 2, 3]\n    >>> sort_third([5, 6, 3, 4, 8, 9, 2])\n    [2, 6, 3, 4, 8, 9, 5]\n    \"\"\"\n    if not l:\n        return []\n    # Indices that are multiples of 3 (including 0)\n    idx = [i for i in range(len(l)) if i % 3 == 0]\n    # Extract and sort the corresponding values\n    sorted_vals = sorted(l[i] for i in idx)\n    # Build the result list\n    result = list(l)\n    for i, val in zip(idx, sorted_vals):\n        result[i] = val\n    return result"}
{"task_id": "HumanEval/34", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.302184104919434, "exec_time_s": 0.017691850662231445, "stdout": "", "stderr": "", "error": null, "eval_count": 144, "prompt_eval_count": 214, "eval_tokens_per_sec": 30.775558539713288, "prompt_tokens_per_sec": 486.8504414394665, "eval_duration_ns": 4679037744, "prompt_eval_duration_ns": 439560041, "code": "def unique(l: list):\n    \"\"\"Return sorted unique elements in a list\n    >>> unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n    [0, 2, 3, 5, 9, 123]\n    \"\"\"\n    return sorted(set(l))", "response_raw": "def unique(l: list):\n    \"\"\"Return sorted unique elements in a list\n    >>> unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n    [0, 2, 3, 5, 9, 123]\n    \"\"\"\n    return sorted(set(l))"}
{"task_id": "HumanEval/35", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.345413208007812, "exec_time_s": 0.026524782180786133, "stdout": "", "stderr": "", "error": null, "eval_count": 307, "prompt_eval_count": 223, "eval_tokens_per_sec": 32.16069873233308, "prompt_tokens_per_sec": 404.20997705577287, "eval_duration_ns": 9545812501, "prompt_eval_duration_ns": 551693458, "code": "def max_element(l: list):\n    \"\"\"Return maximum element in the list.\n    >>> max_element([1, 2, 3])\n    3\n    >>> max_element([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n    123\n    \"\"\"\n    if not l:\n        raise ValueError(\"max_element() arg is an empty sequence\")\n    max_val = l[0]\n    for item in l[1:]:\n        if item > max_val:\n            max_val = item\n    return max_val", "response_raw": "def max_element(l: list):\n    \"\"\"Return maximum element in the list.\n    >>> max_element([1, 2, 3])\n    3\n    >>> max_element([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n    123\n    \"\"\"\n    if not l:\n        raise ValueError(\"max_element() arg is an empty sequence\")\n    max_val = l[0]\n    for item in l[1:]:\n        if item > max_val:\n            max_val = item\n    return max_val"}
{"task_id": "HumanEval/36", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 25.436378002166748, "exec_time_s": 8.005305051803589, "stdout": "", "stderr": "", "error": "timeout", "eval_count": 732, "prompt_eval_count": 220, "eval_tokens_per_sec": 30.029747153694977, "prompt_tokens_per_sec": 360.99957500504576, "eval_duration_ns": 24375829615, "prompt_eval_duration_ns": 609419000, "code": "def solve() -> None:\n    import sys\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    n = int(data[0])\n    result = fizz_buzz(n)\n    sys.stdout.write(str(result))\n\n\nif __name__ == \"__main__\":\n    solve()", "response_raw": "def fizz_buzz(n: int) -> int:\n    \"\"\"Return the number of times the digit 7 appears in integers less than n\n    which are divisible by 11 or 13.\n    \"\"\"\n    count = 0\n    for i in range(1, n):\n        if i % 11 == 0 or i % 13 == 0:\n            count += str(i).count('7')\n    return count\n\n\ndef solve() -> None:\n    import sys\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    n = int(data[0])\n    result = fizz_buzz(n)\n    sys.stdout.write(str(result))\n\n\nif __name__ == \"__main__\":\n    solve()\n"}
{"task_id": "HumanEval/37", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 16.48480796813965, "exec_time_s": 0.030692100524902344, "stdout": "", "stderr": "", "error": null, "eval_count": 462, "prompt_eval_count": 264, "eval_tokens_per_sec": 32.322058861620796, "prompt_tokens_per_sec": 144.38220600310302, "eval_duration_ns": 14293643916, "prompt_eval_duration_ns": 1828480166, "code": "def sort_even(l: list):\n    \"\"\"Return a list where elements at odd indices stay the same,\n    and elements at even indices are sorted among themselves.\n    \"\"\"\n    # Extract values at even indices\n    even_vals = [l[i] for i in range(0, len(l), 2)]\n    # Sort them\n    even_vals.sort()\n    # Build result list\n    result = l[:]  # copy original list\n    even_idx = 0\n    for i in range(0, len(l), 2):\n        result[i] = even_vals[even_idx]\n        even_idx += 1\n    return result", "response_raw": "def sort_even(l: list):\n    \"\"\"Return a list where elements at odd indices stay the same,\n    and elements at even indices are sorted among themselves.\n    \"\"\"\n    # Extract values at even indices\n    even_vals = [l[i] for i in range(0, len(l), 2)]\n    # Sort them\n    even_vals.sort()\n    # Build result list\n    result = l[:]  # copy original list\n    even_idx = 0\n    for i in range(0, len(l), 2):\n        result[i] = even_vals[even_idx]\n        even_idx += 1\n    return result"}
{"task_id": "HumanEval/38", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 16.198679208755493, "exec_time_s": 0.03196597099304199, "stdout": "", "stderr": "", "error": null, "eval_count": 499, "prompt_eval_count": 300, "eval_tokens_per_sec": 32.73253837762523, "prompt_tokens_per_sec": 484.9223827091885, "eval_duration_ns": 15244769417, "prompt_eval_duration_ns": 618655708, "code": "def decode_cyclic(s: str) -> str:\n    \"\"\"\n    Decode a string that was encoded with encode_cyclic, rotating each full group of three characters to the right.\n    \"\"\"\n    groups = [s[i:i+3] for i in range(0, len(s), 3)]\n    decoded_groups = [(g[-1] + g[:-1]) if len(g) == 3 else g for g in groups]\n    return \"\".join(decoded_groups)", "response_raw": "def encode_cyclic(s: str) -> str:\n    \"\"\"\n    Encode a string by rotating each full group of three characters to the left.\n    \"\"\"\n    groups = [s[i:i+3] for i in range(0, len(s), 3)]\n    encoded_groups = [(g[1:] + g[0]) if len(g) == 3 else g for g in groups]\n    return \"\".join(encoded_groups)\n\n\ndef decode_cyclic(s: str) -> str:\n    \"\"\"\n    Decode a string that was encoded with encode_cyclic, rotating each full group of three characters to the right.\n    \"\"\"\n    groups = [s[i:i+3] for i in range(0, len(s), 3)]\n    decoded_groups = [(g[-1] + g[:-1]) if len(g) == 3 else g for g in groups]\n    return \"\".join(decoded_groups)"}
{"task_id": "HumanEval/39", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 21.654541969299316, "exec_time_s": 0.02409815788269043, "stdout": "", "stderr": "", "error": null, "eval_count": 680, "prompt_eval_count": 237, "eval_tokens_per_sec": 32.98168912945467, "prompt_tokens_per_sec": 391.6162178778408, "eval_duration_ns": 20617500739, "prompt_eval_duration_ns": 605184334, "code": "def prime_fib(n: int):\n    \"\"\"\n    prime_fib returns n-th number that is a Fibonacci number and it's also prime.\n    >>> prime_fib(1)\n    2\n    >>> prime_fib(2)\n    3\n    >>> prime_fib(3)\n    5\n    >>> prime_fib(4)\n    13\n    >>> prime_fib(5)\n    89\n    \"\"\"\n    if n <= 0:\n        raise ValueError(\"n must be a positive integer\")\n    count = 0\n    a, b = 0, 1\n    while True:\n        a, b = b, a + b  # generate next Fibonacci number\n        if is_prime(a):\n            count += 1\n            if count == n:\n                return a", "response_raw": "def is_prime(n: int) -> bool:\n    if n < 2:\n        return False\n    # small primes\n    small_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n    for p in small_primes:\n        if n % p == 0:\n            return n == p\n    # Miller-Rabin deterministic for 64-bit integers\n    d = n - 1\n    s = 0\n    while d % 2 == 0:\n        d //= 2\n        s += 1\n    # bases sufficient for n < 2^64\n    for a in [2, 325, 9375, 28178, 450775, 9780504, 1795265022]:\n        if a % n == 0:\n            continue\n        x = pow(a, d, n)\n        if x == 1 or x == n - 1:\n            continue\n        for _ in range(s - 1):\n            x = (x * x) % n\n            if x == n - 1:\n                break\n        else:\n            return False\n    return True\n\ndef prime_fib(n: int):\n    \"\"\"\n    prime_fib returns n-th number that is a Fibonacci number and it's also prime.\n    >>> prime_fib(1)\n    2\n    >>> prime_fib(2)\n    3\n    >>> prime_fib(3)\n    5\n    >>> prime_fib(4)\n    13\n    >>> prime_fib(5)\n    89\n    \"\"\"\n    if n <= 0:\n        raise ValueError(\"n must be a positive integer\")\n    count = 0\n    a, b = 0, 1\n    while True:\n        a, b = b, a + b  # generate next Fibonacci number\n        if is_prime(a):\n            count += 1\n            if count == n:\n                return a"}
{"task_id": "HumanEval/40", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 17.66495680809021, "exec_time_s": 0.02411818504333496, "stdout": "", "stderr": "", "error": null, "eval_count": 560, "prompt_eval_count": 300, "eval_tokens_per_sec": 33.6372879279864, "prompt_tokens_per_sec": 454.2377256922725, "eval_duration_ns": 16648191174, "prompt_eval_duration_ns": 660447125, "code": "def triples_sum_to_zero(l: list) -> bool:\n    \"\"\"\n    triples_sum_to_zero takes a list of integers as an input.\n    it returns True if there are three distinct elements in the list that\n    sum to zero, and False otherwise.\n\n    >>> triples_sum_to_zero([1, 3, 5, 0])\n    False\n    >>> triples_sum_to_zero([1, 3, -2, 1])\n    True\n    >>> triples_sum_to_zero([1, 2, 3, 7])\n    False\n    >>> triples_sum_to_zero([2, 4, -5, 3, 9, 7])\n    True\n    >>> triples_sum_to_zero([1])\n    False\n    \"\"\"\n    n = len(l)\n    if n < 3:\n        return False\n    nums = sorted(l)\n    for i in range(n - 2):\n        left, right = i + 1, n - 1\n        while left < right:\n            s = nums[i] + nums[left] + nums[right]\n            if s == 0:\n                return True\n            if s < 0:\n                left += 1\n            else:\n                right -= 1\n    return False", "response_raw": "def triples_sum_to_zero(l: list) -> bool:\n    \"\"\"\n    triples_sum_to_zero takes a list of integers as an input.\n    it returns True if there are three distinct elements in the list that\n    sum to zero, and False otherwise.\n\n    >>> triples_sum_to_zero([1, 3, 5, 0])\n    False\n    >>> triples_sum_to_zero([1, 3, -2, 1])\n    True\n    >>> triples_sum_to_zero([1, 2, 3, 7])\n    False\n    >>> triples_sum_to_zero([2, 4, -5, 3, 9, 7])\n    True\n    >>> triples_sum_to_zero([1])\n    False\n    \"\"\"\n    n = len(l)\n    if n < 3:\n        return False\n    nums = sorted(l)\n    for i in range(n - 2):\n        left, right = i + 1, n - 1\n        while left < right:\n            s = nums[i] + nums[left] + nums[right]\n            if s == 0:\n                return True\n            if s < 0:\n                left += 1\n            else:\n                right -= 1\n    return False"}
{"task_id": "HumanEval/41", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 8.886558771133423, "exec_time_s": 8.00328803062439, "stdout": "", "stderr": "", "error": "timeout", "eval_count": 282, "prompt_eval_count": 290, "eval_tokens_per_sec": 35.51404882639029, "prompt_tokens_per_sec": 404.50840857487304, "eval_duration_ns": 7940519578, "prompt_eval_duration_ns": 716919584, "code": "import sys\n\ndef solve() -> None:\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    n = int(data[0])\n    print(n * n)\n\nif __name__ == \"__main__\":\n    solve()", "response_raw": "import sys\n\ndef solve() -> None:\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    n = int(data[0])\n    print(n * n)\n\nif __name__ == \"__main__\":\n    solve()\n"}
{"task_id": "HumanEval/42", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.141386270523071, "exec_time_s": 0.026926279067993164, "stdout": "", "stderr": "", "error": null, "eval_count": 174, "prompt_eval_count": 250, "eval_tokens_per_sec": 33.5907714614103, "prompt_tokens_per_sec": 144.65357845486275, "eval_duration_ns": 5179994160, "prompt_eval_duration_ns": 1728266958, "code": "def incr_list(l: list):\n    \"\"\"Return list with elements incremented by 1.\n    >>> incr_list([1, 2, 3])\n    [2, 3, 4]\n    >>> incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123])\n    [6, 4, 6, 3, 4, 4, 10, 1, 124]\n    \"\"\"\n    return [x + 1 for x in l]", "response_raw": "def incr_list(l: list):\n    \"\"\"Return list with elements incremented by 1.\n    >>> incr_list([1, 2, 3])\n    [2, 3, 4]\n    >>> incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123])\n    [6, 4, 6, 3, 4, 4, 10, 1, 124]\n    \"\"\"\n    return [x + 1 for x in l]"}
{"task_id": "HumanEval/43", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.996005773544312, "exec_time_s": 0.024760007858276367, "stdout": "", "stderr": "", "error": null, "eval_count": 407, "prompt_eval_count": 298, "eval_tokens_per_sec": 33.880544159375525, "prompt_tokens_per_sec": 449.88624497972427, "eval_duration_ns": 12012794071, "prompt_eval_duration_ns": 662389667, "code": "def pairs_sum_to_zero(l):\n    \"\"\"\n    pairs_sum_to_zero takes a list of integers as an input.\n    it returns True if there are two distinct elements in the list that\n    sum to zero, and False otherwise.\n    >>> pairs_sum_to_zero([1, 3, 5, 0])\n    False\n    >>> pairs_sum_to_zero([1, 3, -2, 1])\n    False\n    >>> pairs_sum_to_zero([1, 2, 3, 7])\n    False\n    >>> pairs_sum_to_zero([2, 4, -5, 3, 5, 7])\n    True\n    >>> pairs_sum_to_zero([1])\n    False\n    \"\"\"\n    seen = set()\n    for num in l:\n        if -num in seen:\n            return True\n        if num == 0 and 0 in seen:\n            return True\n        seen.add(num)\n    return False", "response_raw": "def pairs_sum_to_zero(l):\n    \"\"\"\n    pairs_sum_to_zero takes a list of integers as an input.\n    it returns True if there are two distinct elements in the list that\n    sum to zero, and False otherwise.\n    >>> pairs_sum_to_zero([1, 3, 5, 0])\n    False\n    >>> pairs_sum_to_zero([1, 3, -2, 1])\n    False\n    >>> pairs_sum_to_zero([1, 2, 3, 7])\n    False\n    >>> pairs_sum_to_zero([2, 4, -5, 3, 5, 7])\n    True\n    >>> pairs_sum_to_zero([1])\n    False\n    \"\"\"\n    seen = set()\n    for num in l:\n        if -num in seen:\n            return True\n        if num == 0 and 0 in seen:\n            return True\n        seen.add(num)\n    return False"}
{"task_id": "HumanEval/44", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.643639087677002, "exec_time_s": 0.025901079177856445, "stdout": "", "stderr": "", "error": null, "eval_count": 285, "prompt_eval_count": 232, "eval_tokens_per_sec": 36.09863779961265, "prompt_tokens_per_sec": 447.1313371673869, "eval_duration_ns": 7895034754, "prompt_eval_duration_ns": 518863208, "code": "def change_base(x: int, base: int) -> str:\n    \"\"\"Change numerical base of input number x to base.\n    return string representation after the conversion.\n    base numbers are less than 10.\n    >>> change_base(8, 3)\n    '22'\n    >>> change_base(8, 2)\n    '1000'\n    >>> change_base(7, 2)\n    '111'\n    \"\"\"\n    if base < 2 or base > 9:\n        raise ValueError(\"Base must be between 2 and 9 inclusive.\")\n    if x == 0:\n        return \"0\"\n    if x < 0:\n        sign = \"-\"\n        x = -x\n    else:\n        sign = \"\"\n    digits = []\n    while x > 0:\n        digits.append(str(x % base))\n        x //= base\n    return sign + \"\".join(reversed(digits))", "response_raw": "def change_base(x: int, base: int) -> str:\n    \"\"\"Change numerical base of input number x to base.\n    return string representation after the conversion.\n    base numbers are less than 10.\n    >>> change_base(8, 3)\n    '22'\n    >>> change_base(8, 2)\n    '1000'\n    >>> change_base(7, 2)\n    '111'\n    \"\"\"\n    if base < 2 or base > 9:\n        raise ValueError(\"Base must be between 2 and 9 inclusive.\")\n    if x == 0:\n        return \"0\"\n    if x < 0:\n        sign = \"-\"\n        x = -x\n    else:\n        sign = \"\"\n    digits = []\n    while x > 0:\n        digits.append(str(x % base))\n        x //= base\n    return sign + \"\".join(reversed(digits))"}
{"task_id": "HumanEval/45", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.30313515663147, "exec_time_s": 0.020535707473754883, "stdout": "", "stderr": "", "error": null, "eval_count": 268, "prompt_eval_count": 187, "eval_tokens_per_sec": 35.00061376841226, "prompt_tokens_per_sec": 436.98169851944664, "eval_duration_ns": 7657008582, "prompt_eval_duration_ns": 427935542, "code": "def triangle_area(a, h):\n    \"\"\"Given length of a side and high return area for a triangle.\n    >>> triangle_area(5, 3)\n    7.5\n    \"\"\"\n    return 0.5 * a * h", "response_raw": "def triangle_area(a, h):\n    \"\"\"Given length of a side and high return area for a triangle.\n    >>> triangle_area(5, 3)\n    7.5\n    \"\"\"\n    return 0.5 * a * h"}
{"task_id": "HumanEval/46", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 19.30731701850891, "exec_time_s": 0.023235082626342773, "stdout": "", "stderr": "Traceback (most recent call last):\n  File \"/var/folders/15/tzdxphxd5tb0cxb8mbs0hn900000gn/T/tmp02a1k2u9/main.py\", line 9, in <module>\n    main()\n  File \"/var/folders/15/tzdxphxd5tb0cxb8mbs0hn900000gn/T/tmp02a1k2u9/main.py\", line 2, in main\n    data = sys.stdin.read().strip().split()\nNameError: name 'sys' is not defined\n", "error": null, "eval_count": 647, "prompt_eval_count": 311, "eval_tokens_per_sec": 35.52734752641942, "prompt_tokens_per_sec": 436.7234319268591, "eval_duration_ns": 18211322968, "prompt_eval_duration_ns": 712121167, "code": "def main():\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    results = [str(fib4(int(x))) for x in data]\n    sys.stdout.write(\"\\n\".join(results))\n\nif __name__ == \"__main__\":\n    main()", "response_raw": "import sys\n\ndef fib4(n: int) -> int:\n    if n == 0 or n == 1 or n == 3:\n        return 0\n    if n == 2:\n        return 2\n    a0, a1, a2, a3 = 0, 0, 2, 0  # fib4(0), fib4(1), fib4(2), fib4(3)\n    for _ in range(4, n + 1):\n        nxt = a0 + a1 + a2 + a3\n        a0, a1, a2, a3 = a1, a2, a3, nxt\n    return a3\n\ndef main():\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    results = [str(fib4(int(x))) for x in data]\n    sys.stdout.write(\"\\n\".join(results))\n\nif __name__ == \"__main__\":\n    main()\n"}
{"task_id": "HumanEval/47", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 22.58343005180359, "exec_time_s": 0.0305330753326416, "stdout": "", "stderr": "", "error": null, "eval_count": 774, "prompt_eval_count": 216, "eval_tokens_per_sec": 35.56330704219018, "prompt_tokens_per_sec": 541.6271372888936, "eval_duration_ns": 21764005217, "prompt_eval_duration_ns": 398798334, "code": "def median(l: list):\n    \"\"\"Return median of elements in the list l.\n    >>> median([3, 1, 2, 4, 5])\n    3\n    >>> median([-10, 4, 6, 1000, 10, 20])\n    15.0\n    \"\"\"\n    if not l:\n        raise ValueError(\"median() arg is an empty sequence\")\n    sorted_l = sorted(l)\n    n = len(sorted_l)\n    mid = n // 2\n    if n % 2 == 1:\n        return sorted_l[mid]\n    else:\n        return (sorted_l[mid - 1] + sorted_l[mid]) / 2.0", "response_raw": "def median(l: list):\n    \"\"\"Return median of elements in the list l.\n    >>> median([3, 1, 2, 4, 5])\n    3\n    >>> median([-10, 4, 6, 1000, 10, 20])\n    15.0\n    \"\"\"\n    if not l:\n        raise ValueError(\"median() arg is an empty sequence\")\n    sorted_l = sorted(l)\n    n = len(sorted_l)\n    mid = n // 2\n    if n % 2 == 1:\n        return sorted_l[mid]\n    else:\n        return (sorted_l[mid - 1] + sorted_l[mid]) / 2.0"}
{"task_id": "HumanEval/48", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.445210218429565, "exec_time_s": 0.02182292938232422, "stdout": "", "stderr": "", "error": null, "eval_count": 169, "prompt_eval_count": 212, "eval_tokens_per_sec": 34.64894535517575, "prompt_tokens_per_sec": 570.3587644065192, "eval_duration_ns": 4877493334, "prompt_eval_duration_ns": 371695875, "code": "def is_palindrome(text: str) -> bool:\n    \"\"\"\n    Checks if given string is a palindrome\n    >>> is_palindrome('')\n    True\n    >>> is_palindrome('aba')\n    True\n    >>> is_palindrome('aaaaa')\n    True\n    >>> is_palindrome('zbcd')\n    False\n    \"\"\"\n    return text == text[::-1]", "response_raw": "def is_palindrome(text: str) -> bool:\n    \"\"\"\n    Checks if given string is a palindrome\n    >>> is_palindrome('')\n    True\n    >>> is_palindrome('aba')\n    True\n    >>> is_palindrome('aaaaa')\n    True\n    >>> is_palindrome('zbcd')\n    False\n    \"\"\"\n    return text == text[::-1]"}
{"task_id": "HumanEval/49", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.329287767410278, "exec_time_s": 0.02435302734375, "stdout": "", "stderr": "", "error": null, "eval_count": 314, "prompt_eval_count": 247, "eval_tokens_per_sec": 36.65246676643565, "prompt_tokens_per_sec": 471.2899511251332, "eval_duration_ns": 8566954088, "prompt_eval_duration_ns": 524093500, "code": "def modp(n: int, p: int) -> int:\n    \"\"\"Return 2^n modulo p (be aware of numerics).\n    >>> modp(3, 5)\n    3\n    >>> modp(1101, 101)\n    2\n    >>> modp(0, 101)\n    1\n    >>> modp(3, 11)\n    8\n    >>> modp(100, 101)\n    1\n    \"\"\"\n    if p == 0:\n        raise ValueError(\"Modulo p must be non-zero\")\n    return pow(2, n, p)", "response_raw": "def modp(n: int, p: int) -> int:\n    \"\"\"Return 2^n modulo p (be aware of numerics).\n    >>> modp(3, 5)\n    3\n    >>> modp(1101, 101)\n    2\n    >>> modp(0, 101)\n    1\n    >>> modp(3, 11)\n    8\n    >>> modp(100, 101)\n    1\n    \"\"\"\n    if p == 0:\n        raise ValueError(\"Modulo p must be non-zero\")\n    return pow(2, n, p)"}
{"task_id": "HumanEval/50", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 13.327579736709595, "exec_time_s": 0.02019190788269043, "stdout": "", "stderr": "", "error": null, "eval_count": 442, "prompt_eval_count": 231, "eval_tokens_per_sec": 35.48269105561676, "prompt_tokens_per_sec": 406.4890432726063, "eval_duration_ns": 12456777850, "prompt_eval_duration_ns": 568281000, "code": "def decode_shift(s: str):\n    \"\"\"\n    takes as input string encoded with encode_shift function. Returns decoded string.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])", "response_raw": "def encode_shift(s: str):\n    \"\"\"\n    returns encoded string by shifting every character by 5 in the alphabet.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) + 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\ndef decode_shift(s: str):\n    \"\"\"\n    takes as input string encoded with encode_shift function. Returns decoded string.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])"}
{"task_id": "HumanEval/51", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.708916902542114, "exec_time_s": 0.0254518985748291, "stdout": "", "stderr": "", "error": null, "eval_count": 372, "prompt_eval_count": 256, "eval_tokens_per_sec": 37.34872104977855, "prompt_tokens_per_sec": 521.0334603434483, "eval_duration_ns": 9960180417, "prompt_eval_duration_ns": 491331209, "code": "def remove_vowels(text):\n    \"\"\"\n    remove_vowels is a function that takes string and returns string without vowels.\n    >>> remove_vowels('')\n    ''\n    >>> remove_vowels(\"abcdef\\nghijklm\")\n    'bcdf\\nghjklm'\n    >>> remove_vowels('abcdef')\n    'bcdf'\n    >>> remove_vowels('aaaaa')\n    ''\n    >>> remove_vowels('aaBAA')\n    'B'\n    >>> remove_vowels('zbcd')\n    'zbcd'\n    \"\"\"\n    vowels = set('aeiouAEIOU')\n    return ''.join(ch for ch in text if ch not in vowels)", "response_raw": "def remove_vowels(text):\n    \"\"\"\n    remove_vowels is a function that takes string and returns string without vowels.\n    >>> remove_vowels('')\n    ''\n    >>> remove_vowels(\"abcdef\\nghijklm\")\n    'bcdf\\nghjklm'\n    >>> remove_vowels('abcdef')\n    'bcdf'\n    >>> remove_vowels('aaaaa')\n    ''\n    >>> remove_vowels('aaBAA')\n    'B'\n    >>> remove_vowels('zbcd')\n    'zbcd'\n    \"\"\"\n    vowels = set('aeiouAEIOU')\n    return ''.join(ch for ch in text if ch not in vowels)"}
{"task_id": "HumanEval/52", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.719379901885986, "exec_time_s": 0.025458097457885742, "stdout": "", "stderr": "", "error": null, "eval_count": 233, "prompt_eval_count": 220, "eval_tokens_per_sec": 38.25815487049231, "prompt_tokens_per_sec": 506.25595323921783, "eval_duration_ns": 6090204841, "prompt_eval_duration_ns": 434562791, "code": "def below_threshold(l: list, t: int) -> bool:\n    \"\"\"Return True if all numbers in the list l are below threshold t.\n    >>> below_threshold([1, 2, 4, 10], 100)\n    True\n    >>> below_threshold([1, 20, 4, 10], 5)\n    False\n    \"\"\"\n    return all(x < t for x in l)", "response_raw": "def below_threshold(l: list, t: int) -> bool:\n    \"\"\"Return True if all numbers in the list l are below threshold t.\n    >>> below_threshold([1, 2, 4, 10], 100)\n    True\n    >>> below_threshold([1, 20, 4, 10], 5)\n    False\n    \"\"\"\n    return all(x < t for x in l)"}
{"task_id": "HumanEval/53", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.32748007774353, "exec_time_s": 0.036312103271484375, "stdout": "", "stderr": "", "error": null, "eval_count": 229, "prompt_eval_count": 194, "eval_tokens_per_sec": 29.985652722840353, "prompt_tokens_per_sec": 488.36550003046244, "eval_duration_ns": 7636985665, "prompt_eval_duration_ns": 397243458, "code": "def add(x: int, y: int):\n    \"\"\"Add two numbers x and y\n    >>> add(2, 3)\n    5\n    >>> add(5, 7)\n    12\n    \"\"\"\n    return x + y", "response_raw": "def add(x: int, y: int):\n    \"\"\"Add two numbers x and y\n    >>> add(2, 3)\n    5\n    >>> add(5, 7)\n    12\n    \"\"\"\n    return x + y"}
{"task_id": "HumanEval/54", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 25.750452995300293, "exec_time_s": 0.031822919845581055, "stdout": "", "stderr": "", "error": null, "eval_count": 621, "prompt_eval_count": 282, "eval_tokens_per_sec": 25.852600544236758, "prompt_tokens_per_sec": 410.55980730919947, "eval_duration_ns": 24020794308, "prompt_eval_duration_ns": 686867041, "code": "def same_chars(s0: str, s1: str) -> bool:\n    \"\"\"\n    Check if two words have the same characters.\n    >>> same_chars('eabcdzzzz', 'dddzzzzzzzddeddabc')\n    True\n    >>> same_chars('abcd', 'dddddddabc')\n    True\n    >>> same_chars('dddddddabc', 'abcd')\n    True\n    >>> same_chars('eabcd', 'dddddddabc')\n    False\n    >>> same_chars('abcd', 'dddddddabce')\n    False\n    >>> same_chars('eabcdzzzz', 'dddzzzzzzzddddabc')\n    False\n    \"\"\"\n    return set(s0) == set(s1)", "response_raw": "def same_chars(s0: str, s1: str) -> bool:\n    \"\"\"\n    Check if two words have the same characters.\n    >>> same_chars('eabcdzzzz', 'dddzzzzzzzddeddabc')\n    True\n    >>> same_chars('abcd', 'dddddddabc')\n    True\n    >>> same_chars('dddddddabc', 'abcd')\n    True\n    >>> same_chars('eabcd', 'dddddddabc')\n    False\n    >>> same_chars('abcd', 'dddddddabce')\n    False\n    >>> same_chars('eabcdzzzz', 'dddzzzzzzzddddabc')\n    False\n    \"\"\"\n    return set(s0) == set(s1)"}
{"task_id": "HumanEval/55", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.114984035491943, "exec_time_s": 0.028104305267333984, "stdout": "", "stderr": "", "error": null, "eval_count": 431, "prompt_eval_count": 193, "eval_tokens_per_sec": 30.291890499167756, "prompt_tokens_per_sec": 479.46761664786294, "eval_duration_ns": 14228230490, "prompt_eval_duration_ns": 402529792, "code": "def fib(n: int) -> int:\n    \"\"\"Return n-th Fibonacci number.\n    >>> fib(10)\n    55\n    >>> fib(1)\n    1\n    >>> fib(8)\n    21\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    a, b = 0, 1\n    for _ in range(n):\n        a, b = b, a + b\n    return a", "response_raw": "def fib(n: int) -> int:\n    \"\"\"Return n-th Fibonacci number.\n    >>> fib(10)\n    55\n    >>> fib(1)\n    1\n    >>> fib(8)\n    21\n    \"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    a, b = 0, 1\n    for _ in range(n):\n        a, b = b, a + b\n    return a"}
{"task_id": "HumanEval/56", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.690591096878052, "exec_time_s": 0.0354771614074707, "stdout": "", "stderr": "", "error": null, "eval_count": 341, "prompt_eval_count": 234, "eval_tokens_per_sec": 28.96559087097986, "prompt_tokens_per_sec": 503.1410926399463, "eval_duration_ns": 11772589122, "prompt_eval_duration_ns": 465078292, "code": "def correct_bracketing(brackets: str) -> bool:\n    \"\"\" brackets is a string of \"<\" and \">\".\n    return True if every opening bracket has a corresponding closing bracket.\n\n    >>> correct_bracketing(\"<\")\n    False\n    >>> correct_bracketing(\"<>\")\n    True\n    >>> correct_bracketing(\"<<><>>\")\n    True\n    >>> correct_bracketing(\"><<>\")\n    False\n    \"\"\"\n    balance = 0\n    for ch in brackets:\n        if ch == \"<\":\n            balance += 1\n        elif ch == \">\":\n            balance -= 1\n        else:\n            # Invalid character, treat as unbalanced\n            return False\n        if balance < 0:\n            return False\n    return balance == 0", "response_raw": "def correct_bracketing(brackets: str) -> bool:\n    \"\"\" brackets is a string of \"<\" and \">\".\n    return True if every opening bracket has a corresponding closing bracket.\n\n    >>> correct_bracketing(\"<\")\n    False\n    >>> correct_bracketing(\"<>\")\n    True\n    >>> correct_bracketing(\"<<><>>\")\n    True\n    >>> correct_bracketing(\"><<>\")\n    False\n    \"\"\"\n    balance = 0\n    for ch in brackets:\n        if ch == \"<\":\n            balance += 1\n        elif ch == \">\":\n            balance -= 1\n        else:\n            # Invalid character, treat as unbalanced\n            return False\n        if balance < 0:\n            return False\n    return balance == 0"}
{"task_id": "HumanEval/57", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.204380989074707, "exec_time_s": 0.044734954833984375, "stdout": "", "stderr": "", "error": null, "eval_count": 339, "prompt_eval_count": 227, "eval_tokens_per_sec": 30.41084924927471, "prompt_tokens_per_sec": 374.2742258052727, "eval_duration_ns": 11147337492, "prompt_eval_duration_ns": 606507166, "code": "def monotonic(l: list) -> bool:\n    \"\"\"Return True if list elements are monotonically increasing or decreasing.\n    >>> monotonic([1, 2, 4, 20])\n    True\n    >>> monotonic([1, 20, 4, 10])\n    False\n    >>> monotonic([4, 1, 0, -10])\n    True\n    \"\"\"\n    if len(l) <= 1:\n        return True\n    increasing = all(l[i] <= l[i + 1] for i in range(len(l) - 1))\n    decreasing = all(l[i] >= l[i + 1] for i in range(len(l) - 1))\n    return increasing or decreasing", "response_raw": "def monotonic(l: list) -> bool:\n    \"\"\"Return True if list elements are monotonically increasing or decreasing.\n    >>> monotonic([1, 2, 4, 20])\n    True\n    >>> monotonic([1, 20, 4, 10])\n    False\n    >>> monotonic([4, 1, 0, -10])\n    True\n    \"\"\"\n    if len(l) <= 1:\n        return True\n    increasing = all(l[i] <= l[i + 1] for i in range(len(l) - 1))\n    decreasing = all(l[i] >= l[i + 1] for i in range(len(l) - 1))\n    return increasing or decreasing"}
{"task_id": "HumanEval/58", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.071468114852905, "exec_time_s": 0.020631074905395508, "stdout": "", "stderr": "", "error": null, "eval_count": 301, "prompt_eval_count": 255, "eval_tokens_per_sec": 33.19094765606261, "prompt_tokens_per_sec": 423.5619190427833, "eval_duration_ns": 9068737751, "prompt_eval_duration_ns": 602037125, "code": "def common(l1: list, l2: list):\n    \"\"\"Return sorted unique common elements for two lists.\n    >>> common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\n    [1, 5, 653]\n    >>> common([5, 3, 2, 8], [3, 2])\n    [2, 3]\n    \"\"\"\n    return sorted(set(l1) & set(l2))", "response_raw": "def common(l1: list, l2: list):\n    \"\"\"Return sorted unique common elements for two lists.\n    >>> common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\n    [1, 5, 653]\n    >>> common([5, 3, 2, 8], [3, 2])\n    [2, 3]\n    \"\"\"\n    return sorted(set(l1) & set(l2))"}
{"task_id": "HumanEval/59", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.369647741317749, "exec_time_s": 0.02674698829650879, "stdout": "", "stderr": "", "error": null, "eval_count": 290, "prompt_eval_count": 204, "eval_tokens_per_sec": 37.89039376182717, "prompt_tokens_per_sec": 417.641889481515, "eval_duration_ns": 7653654956, "prompt_eval_duration_ns": 488456750, "code": "def largest_prime_factor(n: int) -> int:\n    \"\"\"Return the largest prime factor of n. Assume n > 1 and is not a prime.\n    >>> largest_prime_factor(13195)\n    29\n    >>> largest_prime_factor(2048)\n    2\n    \"\"\"\n    original = n\n    max_factor = 1\n\n    # Remove factors of 2 first\n    while n % 2 == 0:\n        max_factor = 2\n        n //= 2\n\n    # Check odd factors up to sqrt(n)\n    factor = 3\n    while factor * factor <= n:\n        while n % factor == 0:\n            max_factor = factor\n            n //= factor\n        factor += 2\n\n    # If remainder is a prime larger than any found factor\n    if n > 1:\n        max_factor = n\n\n    return max_factor", "response_raw": "def largest_prime_factor(n: int) -> int:\n    \"\"\"Return the largest prime factor of n. Assume n > 1 and is not a prime.\n    >>> largest_prime_factor(13195)\n    29\n    >>> largest_prime_factor(2048)\n    2\n    \"\"\"\n    original = n\n    max_factor = 1\n\n    # Remove factors of 2 first\n    while n % 2 == 0:\n        max_factor = 2\n        n //= 2\n\n    # Check odd factors up to sqrt(n)\n    factor = 3\n    while factor * factor <= n:\n        while n % factor == 0:\n            max_factor = factor\n            n //= factor\n        factor += 2\n\n    # If remainder is a prime larger than any found factor\n    if n > 1:\n        max_factor = n\n\n    return max_factor"}
{"task_id": "HumanEval/60", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.753542900085449, "exec_time_s": 0.025123119354248047, "stdout": "", "stderr": "", "error": null, "eval_count": 192, "prompt_eval_count": 235, "eval_tokens_per_sec": 37.665233805449894, "prompt_tokens_per_sec": 510.4333843555304, "eval_duration_ns": 5097539046, "prompt_eval_duration_ns": 460393084, "code": "def sum_to_n(n: int) -> int:\n    \"\"\"sum_to_n is a function that sums numbers from 1 to n.\n    >>> sum_to_n(30)\n    465\n    >>> sum_to_n(100)\n    5050\n    >>> sum_to_n(5)\n    15\n    >>> sum_to_n(10)\n    55\n    >>> sum_to_n(1)\n    1\n    \"\"\"\n    return n * (n + 1) // 2", "response_raw": "def sum_to_n(n: int) -> int:\n    \"\"\"sum_to_n is a function that sums numbers from 1 to n.\n    >>> sum_to_n(30)\n    465\n    >>> sum_to_n(100)\n    5050\n    >>> sum_to_n(5)\n    15\n    >>> sum_to_n(10)\n    55\n    >>> sum_to_n(1)\n    1\n    \"\"\"\n    return n * (n + 1) // 2"}
{"task_id": "HumanEval/61", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.039561986923218, "exec_time_s": 0.0384068489074707, "stdout": "", "stderr": "", "error": null, "eval_count": 325, "prompt_eval_count": 232, "eval_tokens_per_sec": 29.228350095768732, "prompt_tokens_per_sec": 411.2930374463802, "eval_duration_ns": 11119341288, "prompt_eval_duration_ns": 564074708, "code": "def correct_bracketing(brackets: str) -> bool:\n    \"\"\" brackets is a string of \"(\" and \")\".\n    return True if every opening bracket has a corresponding closing bracket.\n\n    >>> correct_bracketing(\"(\")\n    False\n    >>> correct_bracketing(\"()\")\n    True\n    >>> correct_bracketing(\"(()())\")\n    True\n    >>> correct_bracketing(\")(()\")\n    False\n    \"\"\"\n    balance = 0\n    for ch in brackets:\n        if ch == '(':\n            balance += 1\n        elif ch == ')':\n            balance -= 1\n            if balance < 0:\n                return False\n        else:\n            # ignore any other characters\n            continue\n    return balance == 0", "response_raw": "def correct_bracketing(brackets: str) -> bool:\n    \"\"\" brackets is a string of \"(\" and \")\".\n    return True if every opening bracket has a corresponding closing bracket.\n\n    >>> correct_bracketing(\"(\")\n    False\n    >>> correct_bracketing(\"()\")\n    True\n    >>> correct_bracketing(\"(()())\")\n    True\n    >>> correct_bracketing(\")(()\")\n    False\n    \"\"\"\n    balance = 0\n    for ch in brackets:\n        if ch == '(':\n            balance += 1\n        elif ch == ')':\n            balance -= 1\n            if balance < 0:\n                return False\n        else:\n            # ignore any other characters\n            continue\n    return balance == 0"}
{"task_id": "HumanEval/62", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.377425909042358, "exec_time_s": 0.03881025314331055, "stdout": "", "stderr": "", "error": null, "eval_count": 339, "prompt_eval_count": 248, "eval_tokens_per_sec": 30.079792428463346, "prompt_tokens_per_sec": 378.47771747768024, "eval_duration_ns": 11270024579, "prompt_eval_duration_ns": 655256541, "code": "def derivative(xs: list):\n    \"\"\" xs represent coefficients of a polynomial.\n    xs[0] + xs[1] * x + xs[2] * x^2 + ....\n     Return derivative of this polynomial in the same form.\n    >>> derivative([3, 1, 2, 4, 5])\n    [1, 4, 12, 20]\n    >>> derivative([1, 2, 3])\n    [2, 6]\n    \"\"\"\n    return [coeff * i for i, coeff in enumerate(xs) if i > 0]", "response_raw": "def derivative(xs: list):\n    \"\"\" xs represent coefficients of a polynomial.\n    xs[0] + xs[1] * x + xs[2] * x^2 + ....\n     Return derivative of this polynomial in the same form.\n    >>> derivative([3, 1, 2, 4, 5])\n    [1, 4, 12, 20]\n    >>> derivative([1, 2, 3])\n    [2, 6]\n    \"\"\"\n    return [coeff * i for i, coeff in enumerate(xs) if i > 0]"}
{"task_id": "HumanEval/63", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 33.5769419670105, "exec_time_s": 0.03585481643676758, "stdout": "", "stderr": "", "error": null, "eval_count": 967, "prompt_eval_count": 288, "eval_tokens_per_sec": 30.293046847871278, "prompt_tokens_per_sec": 354.6456993167667, "eval_duration_ns": 31921516672, "prompt_eval_duration_ns": 812078084, "code": "def fibfib(n: int) -> int:\n    \"\"\"Compute the n-th FibFib number.\n    fibfib(0) == 0\n    fibfib(1) == 0\n    fibfib(2) == 1\n    fibfib(n) == fibfib(n-1) + fibfib(n-2) + fibfib(n-3) for n >= 3\n    \"\"\"\n    if n == 0 or n == 1:\n        return 0\n    if n == 2:\n        return 1\n\n    def mat_mul(a, b):\n        return [\n            [a[0][0]*b[0][0] + a[0][1]*b[1][0] + a[0][2]*b[2][0],\n             a[0][0]*b[0][1] + a[0][1]*b[1][1] + a[0][2]*b[2][1],\n             a[0][0]*b[0][2] + a[0][1]*b[1][2] + a[0][2]*b[2][2]],\n            [a[1][0]*b[0][0] + a[1][1]*b[1][0] + a[1][2]*b[2][0],\n             a[1][0]*b[0][1] + a[1][1]*b[1][1] + a[1][2]*b[2][1],\n             a[1][0]*b[0][2] + a[1][1]*b[1][2] + a[1][2]*b[2][2]],\n            [a[2][0]*b[0][0] + a[2][1]*b[1][0] + a[2][2]*b[2][0],\n             a[2][0]*b[0][1] + a[2][1]*b[1][1] + a[2][2]*b[2][1],\n             a[2][0]*b[0][2] + a[2][1]*b[1][2] + a[2][2]*b[2][2]],\n        ]\n\n    def mat_pow(mat, power):\n        # identity matrix\n        result = [[1,0,0],[0,1,0],[0,0,1]]\n        while power:\n            if power & 1:\n                result = mat_mul(result, mat)\n            mat = mat_mul(mat, mat)\n            power >>= 1\n        return result\n\n    # Transition matrix\n    M = [[1,1,1],\n         [1,0,0],\n         [0,1,0]]\n\n    # Compute M^(n-2)\n    P = mat_pow(M, n-2)\n\n    # Base vector [T2, T1, T0] = [1,0,0]\n    # Resulting Tn = first row dot base vector = P[0][0]*1 + P[0][1]*0 + P[0][2]*0\n    return P[0][0]", "response_raw": "def fibfib(n: int) -> int:\n    \"\"\"Compute the n-th FibFib number.\n    fibfib(0) == 0\n    fibfib(1) == 0\n    fibfib(2) == 1\n    fibfib(n) == fibfib(n-1) + fibfib(n-2) + fibfib(n-3) for n >= 3\n    \"\"\"\n    if n == 0 or n == 1:\n        return 0\n    if n == 2:\n        return 1\n\n    def mat_mul(a, b):\n        return [\n            [a[0][0]*b[0][0] + a[0][1]*b[1][0] + a[0][2]*b[2][0],\n             a[0][0]*b[0][1] + a[0][1]*b[1][1] + a[0][2]*b[2][1],\n             a[0][0]*b[0][2] + a[0][1]*b[1][2] + a[0][2]*b[2][2]],\n            [a[1][0]*b[0][0] + a[1][1]*b[1][0] + a[1][2]*b[2][0],\n             a[1][0]*b[0][1] + a[1][1]*b[1][1] + a[1][2]*b[2][1],\n             a[1][0]*b[0][2] + a[1][1]*b[1][2] + a[1][2]*b[2][2]],\n            [a[2][0]*b[0][0] + a[2][1]*b[1][0] + a[2][2]*b[2][0],\n             a[2][0]*b[0][1] + a[2][1]*b[1][1] + a[2][2]*b[2][1],\n             a[2][0]*b[0][2] + a[2][1]*b[1][2] + a[2][2]*b[2][2]],\n        ]\n\n    def mat_pow(mat, power):\n        # identity matrix\n        result = [[1,0,0],[0,1,0],[0,0,1]]\n        while power:\n            if power & 1:\n                result = mat_mul(result, mat)\n            mat = mat_mul(mat, mat)\n            power >>= 1\n        return result\n\n    # Transition matrix\n    M = [[1,1,1],\n         [1,0,0],\n         [0,1,0]]\n\n    # Compute M^(n-2)\n    P = mat_pow(M, n-2)\n\n    # Base vector [T2, T1, T0] = [1,0,0]\n    # Resulting Tn = first row dot base vector = P[0][0]*1 + P[0][1]*0 + P[0][2]*0\n    return P[0][0]"}
{"task_id": "HumanEval/64", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.45637583732605, "exec_time_s": 0.03067922592163086, "stdout": "", "stderr": "", "error": null, "eval_count": 432, "prompt_eval_count": 265, "eval_tokens_per_sec": 30.397689920574273, "prompt_tokens_per_sec": 347.3972600067578, "eval_duration_ns": 14211606248, "prompt_eval_duration_ns": 762815458, "code": "def vowels_count(s):\n    \"\"\"Return the number of vowels in the string s.\n    Vowels are a, e, i, o, u (case‑insensitive). The letter y counts as a vowel\n    only when it appears as the last character of the word.\n    \"\"\"\n    if not s:\n        return 0\n    count = 0\n    vowels = {'a', 'e', 'i', 'o', 'u'}\n    for ch in s[:-1]:\n        if ch.lower() in vowels:\n            count += 1\n    # handle last character\n    last = s[-1].lower()\n    if last in vowels or last == 'y':\n        count += 1\n    return count", "response_raw": "def vowels_count(s):\n    \"\"\"Return the number of vowels in the string s.\n    Vowels are a, e, i, o, u (case‑insensitive). The letter y counts as a vowel\n    only when it appears as the last character of the word.\n    \"\"\"\n    if not s:\n        return 0\n    count = 0\n    vowels = {'a', 'e', 'i', 'o', 'u'}\n    for ch in s[:-1]:\n        if ch.lower() in vowels:\n            count += 1\n    # handle last character\n    last = s[-1].lower()\n    if last in vowels or last == 'y':\n        count += 1\n    return count"}
{"task_id": "HumanEval/65", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 14.769248008728027, "exec_time_s": 0.02525496482849121, "stdout": "", "stderr": "", "error": null, "eval_count": 527, "prompt_eval_count": 222, "eval_tokens_per_sec": 37.77222042003337, "prompt_tokens_per_sec": 453.1067284265289, "eval_duration_ns": 13952052438, "prompt_eval_duration_ns": 489950791, "code": "def circular_shift(x, shift):\n    \"\"\"Circular shift the digits of the integer x, shift the digits right by shift\n    and return the result as a string.\n    If shift > number of digits, return digits reversed.\n    >>> circular_shift(12, 1)\n    \"21\"\n    >>> circular_shift(12, 2)\n    \"12\"\n    \"\"\"\n    s = str(abs(int(x)))  # ensure integer and handle possible negative sign\n    n = len(s)\n    if shift > n:\n        return s[::-1]\n    shift_mod = shift % n\n    if shift_mod == 0:\n        return s\n    return s[-shift_mod:] + s[:-shift_mod]", "response_raw": "def circular_shift(x, shift):\n    \"\"\"Circular shift the digits of the integer x, shift the digits right by shift\n    and return the result as a string.\n    If shift > number of digits, return digits reversed.\n    >>> circular_shift(12, 1)\n    \"21\"\n    >>> circular_shift(12, 2)\n    \"12\"\n    \"\"\"\n    s = str(abs(int(x)))  # ensure integer and handle possible negative sign\n    n = len(s)\n    if shift > n:\n        return s[::-1]\n    shift_mod = shift % n\n    if shift_mod == 0:\n        return s\n    return s[-shift_mod:] + s[:-shift_mod]"}
{"task_id": "HumanEval/66", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.639834880828857, "exec_time_s": 0.03309011459350586, "stdout": "", "stderr": "", "error": null, "eval_count": 158, "prompt_eval_count": 251, "eval_tokens_per_sec": 27.969584113213628, "prompt_tokens_per_sec": 368.72176838995375, "eval_duration_ns": 5648993541, "prompt_eval_duration_ns": 680730083, "code": "def digitSum(s: str) -> int:\n    \"\"\"Return the sum of ASCII codes of uppercase characters in the string.\"\"\"\n    return sum(ord(c) for c in s if c.isupper())", "response_raw": "def digitSum(s: str) -> int:\n    \"\"\"Return the sum of ASCII codes of uppercase characters in the string.\"\"\"\n    return sum(ord(c) for c in s if c.isupper())"}
{"task_id": "HumanEval/67", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.746605157852173, "exec_time_s": 0.05723404884338379, "stdout": "", "stderr": "", "error": null, "eval_count": 254, "prompt_eval_count": 350, "eval_tokens_per_sec": 29.955421134788583, "prompt_tokens_per_sec": 407.2149374611283, "eval_duration_ns": 8479266536, "prompt_eval_duration_ns": 859496958, "code": "import re\n\ndef fruit_distribution(s, n):\n    \"\"\"\n    Calculates the number of mango fruits in a basket.\n\n    Parameters:\n    s (str): A string describing the number of apples and oranges, e.g., \"5 apples and 6 oranges\".\n    n (int): Total number of fruits in the basket.\n\n    Returns:\n    int: Number of mango fruits.\n    \"\"\"\n    numbers = list(map(int, re.findall(r'\\d+', s)))\n    if len(numbers) < 2:\n        raise ValueError(\"Input string must contain numbers for apples and oranges.\")\n    apples, oranges = numbers[0], numbers[1]\n    return n - apples - oranges", "response_raw": "import re\n\ndef fruit_distribution(s, n):\n    \"\"\"\n    Calculates the number of mango fruits in a basket.\n\n    Parameters:\n    s (str): A string describing the number of apples and oranges, e.g., \"5 apples and 6 oranges\".\n    n (int): Total number of fruits in the basket.\n\n    Returns:\n    int: Number of mango fruits.\n    \"\"\"\n    numbers = list(map(int, re.findall(r'\\d+', s)))\n    if len(numbers) < 2:\n        raise ValueError(\"Input string must contain numbers for apples and oranges.\")\n    apples, oranges = numbers[0], numbers[1]\n    return n - apples - oranges"}
{"task_id": "HumanEval/68", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.613595008850098, "exec_time_s": 0.025223970413208008, "stdout": "", "stderr": "", "error": null, "eval_count": 313, "prompt_eval_count": 452, "eval_tokens_per_sec": 30.76949203087782, "prompt_tokens_per_sec": 436.9704912792818, "eval_duration_ns": 10172413626, "prompt_eval_duration_ns": 1034394791, "code": "def pluck(arr):\n    \"\"\"\n    Given an array representing a branch of a tree that has non-negative integer nodes,\n    return the node with the smallest even value and its index.\n    The result is a list [smallest_even_value, index].\n    If there are no even values or the array is empty, return [].\n    \"\"\"\n    min_even = None\n    min_idx = -1\n    for idx, val in enumerate(arr):\n        if val % 2 == 0:\n            if min_even is None or val < min_even:\n                min_even = val\n                min_idx = idx\n    if min_even is None:\n        return []\n    return [min_even, min_idx]", "response_raw": "def pluck(arr):\n    \"\"\"\n    Given an array representing a branch of a tree that has non-negative integer nodes,\n    return the node with the smallest even value and its index.\n    The result is a list [smallest_even_value, index].\n    If there are no even values or the array is empty, return [].\n    \"\"\"\n    min_even = None\n    min_idx = -1\n    for idx, val in enumerate(arr):\n        if val % 2 == 0:\n            if min_even is None or val < min_even:\n                min_even = val\n                min_idx = idx\n    if min_even is None:\n        return []\n    return [min_even, min_idx]"}
{"task_id": "HumanEval/69", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.60349988937378, "exec_time_s": 0.03087592124938965, "stdout": "", "stderr": "", "error": null, "eval_count": 320, "prompt_eval_count": 305, "eval_tokens_per_sec": 30.188939724568606, "prompt_tokens_per_sec": 463.66450608178775, "eval_duration_ns": 10599908540, "prompt_eval_duration_ns": 657803209, "code": "def search(lst):\n    from collections import Counter\n    freq = Counter(lst)\n    result = -1\n    for val, count in freq.items():\n        if count >= val and val > 0:\n            if val > result:\n                result = val\n    return result", "response_raw": "def search(lst):\n    from collections import Counter\n    freq = Counter(lst)\n    result = -1\n    for val, count in freq.items():\n        if count >= val and val > 0:\n            if val > result:\n                result = val\n    return result"}
{"task_id": "HumanEval/70", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 14.45218300819397, "exec_time_s": 0.04042983055114746, "stdout": "", "stderr": "", "error": null, "eval_count": 399, "prompt_eval_count": 264, "eval_tokens_per_sec": 29.9263248892776, "prompt_tokens_per_sec": 401.31018655223244, "eval_duration_ns": 13332743044, "prompt_eval_duration_ns": 657845250, "code": "def strange_sort_list(lst):\n    \"\"\"\n    Given list of integers, return list in strange order.\n    Strange sorting, is when you start with the minimum value,\n    then maximum of the remaining integers, then minimum and so on.\n\n    Examples:\n    strange_sort_list([1, 2, 3, 4]) == [1, 4, 2, 3]\n    strange_sort_list([5, 5, 5, 5]) == [5, 5, 5, 5]\n    strange_sort_list([]) == []\n    \"\"\"\n    sorted_lst = sorted(lst)\n    result = []\n    i, j = 0, len(sorted_lst) - 1\n    pick_min = True\n    while i <= j:\n        if pick_min:\n            result.append(sorted_lst[i])\n            i += 1\n        else:\n            result.append(sorted_lst[j])\n            j -= 1\n        pick_min = not pick_min\n    return result", "response_raw": "def strange_sort_list(lst):\n    \"\"\"\n    Given list of integers, return list in strange order.\n    Strange sorting, is when you start with the minimum value,\n    then maximum of the remaining integers, then minimum and so on.\n\n    Examples:\n    strange_sort_list([1, 2, 3, 4]) == [1, 4, 2, 3]\n    strange_sort_list([5, 5, 5, 5]) == [5, 5, 5, 5]\n    strange_sort_list([]) == []\n    \"\"\"\n    sorted_lst = sorted(lst)\n    result = []\n    i, j = 0, len(sorted_lst) - 1\n    pick_min = True\n    while i <= j:\n        if pick_min:\n            result.append(sorted_lst[i])\n            i += 1\n        else:\n            result.append(sorted_lst[j])\n            j -= 1\n        pick_min = not pick_min\n    return result"}
{"task_id": "HumanEval/71", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.733156204223633, "exec_time_s": 0.03268098831176758, "stdout": "", "stderr": "", "error": null, "eval_count": 333, "prompt_eval_count": 261, "eval_tokens_per_sec": 31.45936114799838, "prompt_tokens_per_sec": 374.4426399784229, "eval_duration_ns": 10585084625, "prompt_eval_duration_ns": 697036000, "code": "import math\n\ndef triangle_area(a, b, c):\n    \"\"\"\n    Given the lengths of the three sides of a triangle. Return the area of\n    the triangle rounded to 2 decimal points if the three sides form a valid triangle. \n    Otherwise return -1.\n    \"\"\"\n    # Validate sides are positive numbers\n    if a <= 0 or b <= 0 or c <= 0:\n        return -1\n    # Triangle inequality check\n    if (a + b <= c) or (a + c <= b) or (b + c <= a):\n        return -1\n    # Heron's formula\n    s = (a + b + c) / 2.0\n    area = math.sqrt(s * (s - a) * (s - b) * (s - c))\n    return round(area, 2)", "response_raw": "import math\n\ndef triangle_area(a, b, c):\n    \"\"\"\n    Given the lengths of the three sides of a triangle. Return the area of\n    the triangle rounded to 2 decimal points if the three sides form a valid triangle. \n    Otherwise return -1.\n    \"\"\"\n    # Validate sides are positive numbers\n    if a <= 0 or b <= 0 or c <= 0:\n        return -1\n    # Triangle inequality check\n    if (a + b <= c) or (a + c <= b) or (b + c <= a):\n        return -1\n    # Heron's formula\n    s = (a + b + c) / 2.0\n    area = math.sqrt(s * (s - a) * (s - b) * (s - c))\n    return round(area, 2)"}
{"task_id": "HumanEval/72", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.142309188842773, "exec_time_s": 0.0280609130859375, "stdout": "", "stderr": "", "error": null, "eval_count": 148, "prompt_eval_count": 365, "eval_tokens_per_sec": 30.122173645529283, "prompt_tokens_per_sec": 389.77032677776094, "eval_duration_ns": 4913324043, "prompt_eval_duration_ns": 936448916, "code": "def will_it_fly(q, w):\n    \"\"\"\n    Returns True if the list q is a palindrome and the sum of its elements\n    does not exceed the maximum allowed weight w, otherwise returns False.\n    \"\"\"\n    if not isinstance(q, list):\n        return False\n    if q != q[::-1]:\n        return False\n    return sum(q) <= w", "response_raw": "def will_it_fly(q, w):\n    \"\"\"\n    Returns True if the list q is a palindrome and the sum of its elements\n    does not exceed the maximum allowed weight w, otherwise returns False.\n    \"\"\"\n    if not isinstance(q, list):\n        return False\n    if q != q[::-1]:\n        return False\n    return sum(q) <= w"}
{"task_id": "HumanEval/73", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.30019211769104, "exec_time_s": 0.03048086166381836, "stdout": "", "stderr": "", "error": null, "eval_count": 327, "prompt_eval_count": 297, "eval_tokens_per_sec": 31.78032389256085, "prompt_tokens_per_sec": 442.6788081768285, "eval_duration_ns": 10289385379, "prompt_eval_duration_ns": 670915333, "code": "def smallest_change(arr):\n    n = len(arr)\n    changes = 0\n    for i in range(n // 2):\n        if arr[i] != arr[n - 1 - i]:\n            changes += 1\n    return changes", "response_raw": "def smallest_change(arr):\n    n = len(arr)\n    changes = 0\n    for i in range(n // 2):\n        if arr[i] != arr[n - 1 - i]:\n            changes += 1\n    return changes"}
{"task_id": "HumanEval/74", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.595666885375977, "exec_time_s": 0.023160934448242188, "stdout": "", "stderr": "", "error": null, "eval_count": 239, "prompt_eval_count": 333, "eval_tokens_per_sec": 31.97425271988653, "prompt_tokens_per_sec": 437.5988524144872, "eval_duration_ns": 7474764214, "prompt_eval_duration_ns": 760970917, "code": "def total_match(lst1, lst2):\n    \"\"\"\n    Returns the list with a smaller total number of characters across all its strings.\n    If both lists have the same total character count, returns the first list.\n    \"\"\"\n    total1 = sum(len(s) for s in lst1)\n    total2 = sum(len(s) for s in lst2)\n    if total1 <= total2:\n        return lst1\n    else:\n        return lst2", "response_raw": "def total_match(lst1, lst2):\n    \"\"\"\n    Returns the list with a smaller total number of characters across all its strings.\n    If both lists have the same total character count, returns the first list.\n    \"\"\"\n    total1 = sum(len(s) for s in lst1)\n    total2 = sum(len(s) for s in lst2)\n    if total1 <= total2:\n        return lst1\n    else:\n        return lst2"}
{"task_id": "HumanEval/75", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.99719500541687, "exec_time_s": 0.022701025009155273, "stdout": "", "stderr": "", "error": null, "eval_count": 364, "prompt_eval_count": 221, "eval_tokens_per_sec": 32.991761349924985, "prompt_tokens_per_sec": 342.57938082385624, "eval_duration_ns": 11033057500, "prompt_eval_duration_ns": 645105959, "code": "def is_multiply_prime(a: int) -> bool:\n    \"\"\"Return True if a is the product of exactly three prime numbers (counting multiplicities).\"\"\"\n    if a <= 1:\n        return False\n\n    count = 0\n    n = a\n    p = 2\n    while p * p <= n and count <= 3:\n        while n % p == 0:\n            count += 1\n            n //= p\n            if count > 3:\n                break\n        p += 1 if p == 2 else 2  # skip even numbers after 2\n    if n > 1:\n        count += 1  # remaining prime factor\n\n    return count == 3", "response_raw": "def is_multiply_prime(a: int) -> bool:\n    \"\"\"Return True if a is the product of exactly three prime numbers (counting multiplicities).\"\"\"\n    if a <= 1:\n        return False\n\n    count = 0\n    n = a\n    p = 2\n    while p * p <= n and count <= 3:\n        while n % p == 0:\n            count += 1\n            n //= p\n            if count > 3:\n                break\n        p += 1 if p == 2 else 2  # skip even numbers after 2\n    if n > 1:\n        count += 1  # remaining prime factor\n\n    return count == 3"}
{"task_id": "HumanEval/76", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 14.67768907546997, "exec_time_s": 0.020250797271728516, "stdout": "", "stderr": "", "error": null, "eval_count": 500, "prompt_eval_count": 282, "eval_tokens_per_sec": 36.444320766090435, "prompt_tokens_per_sec": 439.32609875313193, "eval_duration_ns": 13719558754, "prompt_eval_duration_ns": 641892209, "code": "def is_simple_power(x, n):\n    \"\"\"Return True if x is a simple power of n (i.e., n**k == x for some integer k >= 0).\"\"\"\n    # Edge cases\n    if n == 1:\n        return x == 1\n    if n == 0:\n        # 0**k is 0 for k>0, undefined for k=0; treat only x==0 as true for k>0\n        return x == 0\n    if x == 1:\n        # n**0 == 1 for any n != 0\n        return True\n    if x < 1 or n < 1:\n        return False\n\n    # Repeatedly divide x by n\n    while x % n == 0:\n        x //= n\n        if x == 1:\n            return True\n    return False", "response_raw": "def is_simple_power(x, n):\n    \"\"\"Return True if x is a simple power of n (i.e., n**k == x for some integer k >= 0).\"\"\"\n    # Edge cases\n    if n == 1:\n        return x == 1\n    if n == 0:\n        # 0**k is 0 for k>0, undefined for k=0; treat only x==0 as true for k>0\n        return x == 0\n    if x == 1:\n        # n**0 == 1 for any n != 0\n        return True\n    if x < 1 or n < 1:\n        return False\n\n    # Repeatedly divide x by n\n    while x % n == 0:\n        x //= n\n        if x == 1:\n            return True\n    return False"}
{"task_id": "HumanEval/77", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 13.192911863327026, "exec_time_s": 0.02227497100830078, "stdout": "", "stderr": "", "error": null, "eval_count": 447, "prompt_eval_count": 250, "eval_tokens_per_sec": 36.17314991863532, "prompt_tokens_per_sec": 459.1731543746739, "eval_duration_ns": 12357231842, "prompt_eval_duration_ns": 544456917, "code": "def iscube(a):\n    \"\"\"\n    Return True if integer a is a perfect cube of some integer, else False.\n    \"\"\"\n    # Handle zero directly\n    if a == 0:\n        return True\n\n    # Determine search bounds based on sign\n    if a > 0:\n        low, high = 0, int(a ** (1/3)) + 2\n    else:\n        low, high = -int((-a) ** (1/3)) - 2, 0\n\n    while low <= high:\n        mid = (low + high) // 2\n        cube = mid * mid * mid\n        if cube == a:\n            return True\n        if cube < a:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return False", "response_raw": "def iscube(a):\n    \"\"\"\n    Return True if integer a is a perfect cube of some integer, else False.\n    \"\"\"\n    # Handle zero directly\n    if a == 0:\n        return True\n\n    # Determine search bounds based on sign\n    if a > 0:\n        low, high = 0, int(a ** (1/3)) + 2\n    else:\n        low, high = -int((-a) ** (1/3)) - 2, 0\n\n    while low <= high:\n        mid = (low + high) // 2\n        cube = mid * mid * mid\n        if cube == a:\n            return True\n        if cube < a:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return False"}
{"task_id": "HumanEval/78", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 3.970154047012329, "exec_time_s": 0.020821809768676758, "stdout": "", "stderr": "", "error": null, "eval_count": 108, "prompt_eval_count": 439, "eval_tokens_per_sec": 37.91474752746557, "prompt_tokens_per_sec": 478.4061990109851, "eval_duration_ns": 2848495824, "prompt_eval_duration_ns": 917630250, "code": "def hex_key(num):\n    prime_digits = {'2', '3', '5', '7', 'B', 'D'}\n    return sum(1 for ch in num if ch in prime_digits)", "response_raw": "def hex_key(num):\n    prime_digits = {'2', '3', '5', '7', 'B', 'D'}\n    return sum(1 for ch in num if ch in prime_digits)"}
{"task_id": "HumanEval/79", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 9.577913284301758, "exec_time_s": 8.005817174911499, "stdout": "", "stderr": "", "error": "timeout", "eval_count": 309, "prompt_eval_count": 279, "eval_tokens_per_sec": 35.75236657977311, "prompt_tokens_per_sec": 412.59425477288556, "eval_duration_ns": 8642784508, "prompt_eval_duration_ns": 676209125, "code": "def decimal_to_binary(decimal):\n    \"\"\"Convert a decimal integer to a binary string wrapped with 'db' markers.\"\"\"\n    if not isinstance(decimal, int):\n        raise TypeError(\"Input must be an integer\")\n    if decimal < 0:\n        raise ValueError(\"Negative numbers are not supported\")\n    binary = bin(decimal)[2:]  # strip the '0b' prefix\n    return f\"db{binary}db\"\n\n\nif __name__ == \"__main__\":\n    import sys\n    data = sys.stdin.read().strip()\n    if data:\n        try:\n            num = int(data)\n            print(decimal_to_binary(num))\n        except ValueError:\n            pass", "response_raw": "def decimal_to_binary(decimal):\n    \"\"\"Convert a decimal integer to a binary string wrapped with 'db' markers.\"\"\"\n    if not isinstance(decimal, int):\n        raise TypeError(\"Input must be an integer\")\n    if decimal < 0:\n        raise ValueError(\"Negative numbers are not supported\")\n    binary = bin(decimal)[2:]  # strip the '0b' prefix\n    return f\"db{binary}db\"\n\n\nif __name__ == \"__main__\":\n    import sys\n    data = sys.stdin.read().strip()\n    if data:\n        try:\n            num = int(data)\n            print(decimal_to_binary(num))\n        except ValueError:\n            pass"}
{"task_id": "HumanEval/80", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.154798030853271, "exec_time_s": 0.023447275161743164, "stdout": "", "stderr": "", "error": null, "eval_count": 317, "prompt_eval_count": 262, "eval_tokens_per_sec": 38.962837725959616, "prompt_tokens_per_sec": 149.05684562545525, "eval_duration_ns": 8135957710, "prompt_eval_duration_ns": 1757718667, "code": "def is_happy(s):\n    if len(s) < 3:\n        return False\n    for i in range(len(s) - 2):\n        a, b, c = s[i], s[i + 1], s[i + 2]\n        if a == b or a == c or b == c:\n            return False\n    return True", "response_raw": "def is_happy(s):\n    if len(s) < 3:\n        return False\n    for i in range(len(s) - 2):\n        a, b, c = s[i], s[i + 1], s[i + 2]\n        if a == b or a == c or b == c:\n            return False\n    return True"}
{"task_id": "HumanEval/81", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.416039228439331, "exec_time_s": 0.020457983016967773, "stdout": "", "stderr": "", "error": null, "eval_count": 573, "prompt_eval_count": 410, "eval_tokens_per_sec": 39.83711469234071, "prompt_tokens_per_sec": 596.8859658461123, "eval_duration_ns": 14383571813, "prompt_eval_duration_ns": 686898375, "code": "def numerical_letter_grade(grades):\n    result = []\n    for g in grades:\n        if g == 4.0:\n            result.append('A+')\n        elif g > 3.7:\n            result.append('A')\n        elif g > 3.3:\n            result.append('A-')\n        elif g > 3.0:\n            result.append('B+')\n        elif g > 2.7:\n            result.append('B')\n        elif g > 2.3:\n            result.append('B-')\n        elif g > 2.0:\n            result.append('C+')\n        elif g > 1.7:\n            result.append('C')\n        elif g > 1.3:\n            result.append('C-')\n        elif g > 1.0:\n            result.append('D+')\n        elif g > 0.7:\n            result.append('D')\n        elif g > 0.0:\n            result.append('D-')\n        else:  # g == 0.0 or any non‑positive value\n            result.append('E')\n    return result", "response_raw": "def numerical_letter_grade(grades):\n    result = []\n    for g in grades:\n        if g == 4.0:\n            result.append('A+')\n        elif g > 3.7:\n            result.append('A')\n        elif g > 3.3:\n            result.append('A-')\n        elif g > 3.0:\n            result.append('B+')\n        elif g > 2.7:\n            result.append('B')\n        elif g > 2.3:\n            result.append('B-')\n        elif g > 2.0:\n            result.append('C+')\n        elif g > 1.7:\n            result.append('C')\n        elif g > 1.3:\n            result.append('C-')\n        elif g > 1.0:\n            result.append('D+')\n        elif g > 0.7:\n            result.append('D')\n        elif g > 0.0:\n            result.append('D-')\n        else:  # g == 0.0 or any non‑positive value\n            result.append('E')\n    return result"}
{"task_id": "HumanEval/82", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.371915102005005, "exec_time_s": 0.024016857147216797, "stdout": "", "stderr": "", "error": null, "eval_count": 190, "prompt_eval_count": 221, "eval_tokens_per_sec": 39.822193895871315, "prompt_tokens_per_sec": 541.4648343225532, "eval_duration_ns": 4771208751, "prompt_eval_duration_ns": 408152083, "code": "def prime_length(string: str) -> bool:\n    \"\"\"Return True if the length of the given string is a prime number, else False.\"\"\"\n    n = len(string)\n    if n < 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    i = 3\n    while i * i <= n:\n        if n % i == 0:\n            return False\n        i += 2\n    return True", "response_raw": "def prime_length(string: str) -> bool:\n    \"\"\"Return True if the length of the given string is a prime number, else False.\"\"\"\n    n = len(string)\n    if n < 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    i = 3\n    while i * i <= n:\n        if n % i == 0:\n            return False\n        i += 2\n    return True"}
{"task_id": "HumanEval/83", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 13.869073867797852, "exec_time_s": 0.020465373992919922, "stdout": "", "stderr": "", "error": null, "eval_count": 526, "prompt_eval_count": 185, "eval_tokens_per_sec": 39.75741024771968, "prompt_tokens_per_sec": 572.5621259463237, "eval_duration_ns": 13230238004, "prompt_eval_duration_ns": 323109042, "code": "def starts_one_ends(n):\n    \"\"\"\n    Given a positive integer n, return the count of the numbers of n-digit\n    positive integers that start or end with 1.\n    \"\"\"\n    if n == 1:\n        return 1\n    return 10 ** (n - 1) + 8 * 10 ** (n - 2)", "response_raw": "def starts_one_ends(n):\n    \"\"\"\n    Given a positive integer n, return the count of the numbers of n-digit\n    positive integers that start or end with 1.\n    \"\"\"\n    if n == 1:\n        return 1\n    return 10 ** (n - 1) + 8 * 10 ** (n - 2)"}
{"task_id": "HumanEval/84", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.415602207183838, "exec_time_s": 0.024959087371826172, "stdout": "", "stderr": "", "error": null, "eval_count": 259, "prompt_eval_count": 273, "eval_tokens_per_sec": 39.05135264814803, "prompt_tokens_per_sec": 498.09474199878304, "eval_duration_ns": 6632292672, "prompt_eval_duration_ns": 548088500, "code": "def solve(N):\n    \"\"\"\n    Given a positive integer N, return the total sum of its digits in binary.\n    \n    Example:\n        N = 1000 -> sum = 1 -> \"1\"\n        N = 150  -> sum = 6 -> \"110\"\n        N = 147  -> sum = 12 -> \"1100\"\n    \"\"\"\n    digit_sum = sum(int(d) for d in str(N))\n    return bin(digit_sum)[2:]", "response_raw": "def solve(N):\n    \"\"\"\n    Given a positive integer N, return the total sum of its digits in binary.\n    \n    Example:\n        N = 1000 -> sum = 1 -> \"1\"\n        N = 150  -> sum = 6 -> \"110\"\n        N = 147  -> sum = 12 -> \"1100\"\n    \"\"\"\n    digit_sum = sum(int(d) for d in str(N))\n    return bin(digit_sum)[2:]"}
{"task_id": "HumanEval/85", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.267246007919312, "exec_time_s": 0.024775028228759766, "stdout": "", "stderr": "", "error": null, "eval_count": 312, "prompt_eval_count": 195, "eval_tokens_per_sec": 40.67503569075658, "prompt_tokens_per_sec": 548.4440765300327, "eval_duration_ns": 7670552581, "prompt_eval_duration_ns": 355551292, "code": "def add(lst):\n    \"\"\"Given a non-empty list of integers lst. Add the even elements that are at odd indices.\n\n    Examples:\n        add([4, 2, 6, 7]) ==> 2 \n    \"\"\"\n    total = 0\n    for i in range(1, len(lst), 2):\n        if lst[i] % 2 == 0:\n            total += lst[i]\n    return total", "response_raw": "def add(lst):\n    \"\"\"Given a non-empty list of integers lst. Add the even elements that are at odd indices.\n\n    Examples:\n        add([4, 2, 6, 7]) ==> 2 \n    \"\"\"\n    total = 0\n    for i in range(1, len(lst), 2):\n        if lst[i] % 2 == 0:\n            total += lst[i]\n    return total"}
{"task_id": "HumanEval/86", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 14.389615058898926, "exec_time_s": 0.01655721664428711, "stdout": "", "stderr": "", "error": null, "eval_count": 552, "prompt_eval_count": 268, "eval_tokens_per_sec": 40.7255522708977, "prompt_tokens_per_sec": 548.2697282484726, "eval_duration_ns": 13554144001, "prompt_eval_duration_ns": 488810500, "code": "def anti_shuffle(s):\n    parts = s.split(' ')\n    return ' '.join(''.join(sorted(part)) for part in parts)", "response_raw": "def anti_shuffle(s):\n    parts = s.split(' ')\n    return ' '.join(''.join(sorted(part)) for part in parts)"}
{"task_id": "HumanEval/87", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.05576491355896, "exec_time_s": 0.025706052780151367, "stdout": "", "stderr": "", "error": null, "eval_count": 253, "prompt_eval_count": 399, "eval_tokens_per_sec": 41.08701350262727, "prompt_tokens_per_sec": 598.702922273015, "eval_duration_ns": 6157663418, "prompt_eval_duration_ns": 666440709, "code": "def get_row(lst, x):\n    result = []\n    for i, row in enumerate(lst):\n        for j, val in enumerate(row):\n            if val == x:\n                result.append((i, j))\n    result.sort(key=lambda t: (t[0], -t[1]))\n    return result", "response_raw": "def get_row(lst, x):\n    result = []\n    for i, row in enumerate(lst):\n        for j, val in enumerate(row):\n            if val == x:\n                result.append((i, j))\n    result.sort(key=lambda t: (t[0], -t[1]))\n    return result"}
{"task_id": "HumanEval/88", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.130486726760864, "exec_time_s": 0.02688884735107422, "stdout": "", "stderr": "", "error": null, "eval_count": 403, "prompt_eval_count": 342, "eval_tokens_per_sec": 39.32122699226304, "prompt_tokens_per_sec": 568.1798519427306, "eval_duration_ns": 10248917209, "prompt_eval_duration_ns": 601922083, "code": "def sort_array(array):\n    \"\"\"\n    Given an array of non-negative integers, return a copy of the given array after sorting,\n    you will sort the given array in ascending order if the sum( first index value, last index value) is odd,\n    or sort it in descending order if the sum( first index value, last index value) is even.\n\n    Note:\n    * don't change the given array.\n\n    Examples:\n    * sort_array([]) => []\n    * sort_array([5]) => [5]\n    * sort_array([2, 4, 3, 0, 1, 5]) => [0, 1, 2, 3, 4, 5]\n    * sort_array([2, 4, 3, 0, 1, 5, 6]) => [6, 5, 4, 3, 2, 1, 0]\n    \"\"\"\n    if not array:\n        return []\n    total = array[0] + array[-1]\n    if total % 2 == 1:\n        return sorted(array)\n    else:\n        return sorted(array, reverse=True)", "response_raw": "def sort_array(array):\n    \"\"\"\n    Given an array of non-negative integers, return a copy of the given array after sorting,\n    you will sort the given array in ascending order if the sum( first index value, last index value) is odd,\n    or sort it in descending order if the sum( first index value, last index value) is even.\n\n    Note:\n    * don't change the given array.\n\n    Examples:\n    * sort_array([]) => []\n    * sort_array([5]) => [5]\n    * sort_array([2, 4, 3, 0, 1, 5]) => [0, 1, 2, 3, 4, 5]\n    * sort_array([2, 4, 3, 0, 1, 5, 6]) => [6, 5, 4, 3, 2, 1, 0]\n    \"\"\"\n    if not array:\n        return []\n    total = array[0] + array[-1]\n    if total % 2 == 1:\n        return sorted(array)\n    else:\n        return sorted(array, reverse=True)"}
{"task_id": "HumanEval/89", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.573871850967407, "exec_time_s": 0.030204057693481445, "stdout": "", "stderr": "", "error": null, "eval_count": 378, "prompt_eval_count": 250, "eval_tokens_per_sec": 42.695114206506794, "prompt_tokens_per_sec": 530.8000722949698, "eval_duration_ns": 8853472043, "prompt_eval_duration_ns": 470987125, "code": "def encrypt(s):\n    result = []\n    for ch in s:\n        if 'a' <= ch <= 'z':\n            result.append(chr((ord(ch) - ord('a') + 4) % 26 + ord('a')))\n        elif 'A' <= ch <= 'Z':\n            result.append(chr((ord(ch) - ord('A') + 4) % 26 + ord('A')))\n        else:\n            result.append(ch)\n    return ''.join(result)", "response_raw": "def encrypt(s):\n    result = []\n    for ch in s:\n        if 'a' <= ch <= 'z':\n            result.append(chr((ord(ch) - ord('a') + 4) % 26 + ord('a')))\n        elif 'A' <= ch <= 'Z':\n            result.append(chr((ord(ch) - ord('A') + 4) % 26 + ord('A')))\n        else:\n            result.append(ch)\n    return ''.join(result)"}
{"task_id": "HumanEval/90", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.249346971511841, "exec_time_s": 0.031770944595336914, "stdout": "", "stderr": "", "error": null, "eval_count": 228, "prompt_eval_count": 264, "eval_tokens_per_sec": 40.93887414815595, "prompt_tokens_per_sec": 563.8698774143683, "eval_duration_ns": 5569278705, "prompt_eval_duration_ns": 468193125, "code": "def next_smallest(lst):\n    \"\"\"\n    Returns the second smallest distinct element in the list, or None if it doesn't exist.\n    \"\"\"\n    distinct = set(lst)\n    if len(distinct) < 2:\n        return None\n    # Find the smallest and second smallest without full sort for efficiency\n    smallest = second_smallest = None\n    for num in distinct:\n        if smallest is None or num < smallest:\n            second_smallest = smallest\n            smallest = num\n        elif second_smallest is None or num < second_smallest:\n            second_smallest = num\n    return second_smallest", "response_raw": "def next_smallest(lst):\n    \"\"\"\n    Returns the second smallest distinct element in the list, or None if it doesn't exist.\n    \"\"\"\n    distinct = set(lst)\n    if len(distinct) < 2:\n        return None\n    # Find the smallest and second smallest without full sort for efficiency\n    smallest = second_smallest = None\n    for num in distinct:\n        if smallest is None or num < smallest:\n            second_smallest = smallest\n            smallest = num\n        elif second_smallest is None or num < second_smallest:\n            second_smallest = num\n    return second_smallest"}
{"task_id": "HumanEval/91", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 10.440587759017944, "exec_time_s": 8.008491039276123, "stdout": "", "stderr": "", "error": "timeout", "eval_count": 397, "prompt_eval_count": 247, "eval_tokens_per_sec": 40.99724295699407, "prompt_tokens_per_sec": 505.97628978308484, "eval_duration_ns": 9683578001, "prompt_eval_duration_ns": 488165167, "code": "import sys, re\n\ndef is_bored(S):\n    \"\"\"\n    You'll be given a string of words, and your task is to count the number\n    of boredoms. A boredom is a sentence that starts with the word \"I\".\n    Sentences are delimited by '.', '?' or '!'.\n    \"\"\"\n    # Split the text into sentences using the delimiters\n    sentences = re.split(r'[.!?]', S)\n    count = 0\n    for sentence in sentences:\n        stripped = sentence.strip()\n        if stripped.startswith('I'):\n            count += 1\n    return count\n\nif __name__ == \"__main__\":\n    data = sys.stdin.read()\n    if data:\n        result = is_bored(data.rstrip('\\n'))\n        print(result)", "response_raw": "import sys, re\n\ndef is_bored(S):\n    \"\"\"\n    You'll be given a string of words, and your task is to count the number\n    of boredoms. A boredom is a sentence that starts with the word \"I\".\n    Sentences are delimited by '.', '?' or '!'.\n    \"\"\"\n    # Split the text into sentences using the delimiters\n    sentences = re.split(r'[.!?]', S)\n    count = 0\n    for sentence in sentences:\n        stripped = sentence.strip()\n        if stripped.startswith('I'):\n            count += 1\n    return count\n\nif __name__ == \"__main__\":\n    data = sys.stdin.read()\n    if data:\n        result = is_bored(data.rstrip('\\n'))\n        print(result)"}
{"task_id": "HumanEval/92", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.427398920059204, "exec_time_s": 0.023207902908325195, "stdout": "", "stderr": "", "error": null, "eval_count": 264, "prompt_eval_count": 275, "eval_tokens_per_sec": 41.941248340917014, "prompt_tokens_per_sec": 147.18585988120228, "eval_duration_ns": 6294519368, "prompt_eval_duration_ns": 1868386000, "code": "def any_int(x, y, z):\n    \"\"\"\n    Returns True if all inputs are integers and one of them equals the sum of the other two.\n    Otherwise returns False.\n    \"\"\"\n    if not all(isinstance(v, int) for v in (x, y, z)):\n        return False\n    return x == y + z or y == x + z or z == x + y", "response_raw": "def any_int(x, y, z):\n    \"\"\"\n    Returns True if all inputs are integers and one of them equals the sum of the other two.\n    Otherwise returns False.\n    \"\"\"\n    if not all(isinstance(v, int) for v in (x, y, z)):\n        return False\n    return x == y + z or y == x + z or z == x + y"}
{"task_id": "HumanEval/93", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 33.20681095123291, "exec_time_s": 0.03538823127746582, "stdout": "", "stderr": "", "error": null, "eval_count": 1250, "prompt_eval_count": 249, "eval_tokens_per_sec": 38.893793152470984, "prompt_tokens_per_sec": 544.6957693328657, "eval_duration_ns": 32138804130, "prompt_eval_duration_ns": 457135917, "code": "def encode(message):\n    result = []\n    vowels = set('aeiou')\n    for ch in message:\n        if ch.isalpha():\n            swapped = ch.swapcase()\n            if swapped.lower() in vowels:\n                if swapped.isupper():\n                    base = ord('A')\n                else:\n                    base = ord('a')\n                new_char = chr(base + (ord(swapped) - base) + 2)\n                result.append(new_char)\n            else:\n                result.append(swapped)\n        else:\n            result.append(ch)\n    return ''.join(result)", "response_raw": "def encode(message):\n    result = []\n    vowels = set('aeiou')\n    for ch in message:\n        if ch.isalpha():\n            swapped = ch.swapcase()\n            if swapped.lower() in vowels:\n                if swapped.isupper():\n                    base = ord('A')\n                else:\n                    base = ord('a')\n                new_char = chr(base + (ord(swapped) - base) + 2)\n                result.append(new_char)\n            else:\n                result.append(swapped)\n        else:\n            result.append(ch)\n    return ''.join(result)"}
{"task_id": "HumanEval/94", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.0329248905181885, "exec_time_s": 0.028622150421142578, "stdout": "", "stderr": "", "error": null, "eval_count": 269, "prompt_eval_count": 426, "eval_tokens_per_sec": 43.34327429805303, "prompt_tokens_per_sec": 700.6225086907946, "eval_duration_ns": 6206268547, "prompt_eval_duration_ns": 608030708, "code": "def skjkasdkd(lst):\n    def is_prime(n):\n        if n < 2:\n            return False\n        if n % 2 == 0:\n            return n == 2\n        i = 3\n        while i * i <= n:\n            if n % i == 0:\n                return False\n            i += 2\n        return True\n\n    max_prime = None\n    for num in lst:\n        if is_prime(num):\n            if max_prime is None or num > max_prime:\n                max_prime = num\n\n    if max_prime is None:\n        return 0\n    return sum(int(d) for d in str(max_prime))", "response_raw": "def skjkasdkd(lst):\n    def is_prime(n):\n        if n < 2:\n            return False\n        if n % 2 == 0:\n            return n == 2\n        i = 3\n        while i * i <= n:\n            if n % i == 0:\n                return False\n            i += 2\n        return True\n\n    max_prime = None\n    for num in lst:\n        if is_prime(num):\n            if max_prime is None or num > max_prime:\n                max_prime = num\n\n    if max_prime is None:\n        return 0\n    return sum(int(d) for d in str(max_prime))"}
{"task_id": "HumanEval/95", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.388994693756104, "exec_time_s": 0.02352309226989746, "stdout": "", "stderr": "", "error": null, "eval_count": 374, "prompt_eval_count": 309, "eval_tokens_per_sec": 43.407105517015154, "prompt_tokens_per_sec": 592.998017582679, "eval_duration_ns": 8616100879, "prompt_eval_duration_ns": 521081000, "code": "def check_dict_case(d):\n    \"\"\"\n    Given a dictionary, return True if all keys are strings in lower \n    case or all keys are strings in upper case, else return False.\n    The function should return False if the given dictionary is empty.\n    \"\"\"\n    if not d:\n        return False\n\n    case_set = set()\n    for key in d.keys():\n        if not isinstance(key, str):\n            return False\n        if key.islower():\n            case_set.add('lower')\n        elif key.isupper():\n            case_set.add('upper')\n        else:\n            return False\n        if len(case_set) > 1:\n            return False\n    return len(case_set) == 1", "response_raw": "def check_dict_case(d):\n    \"\"\"\n    Given a dictionary, return True if all keys are strings in lower \n    case or all keys are strings in upper case, else return False.\n    The function should return False if the given dictionary is empty.\n    \"\"\"\n    if not d:\n        return False\n\n    case_set = set()\n    for key in d.keys():\n        if not isinstance(key, str):\n            return False\n        if key.islower():\n            case_set.add('lower')\n        elif key.isupper():\n            case_set.add('upper')\n        else:\n            return False\n        if len(case_set) > 1:\n            return False\n    return len(case_set) == 1"}
{"task_id": "HumanEval/96", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.3280189037323, "exec_time_s": 0.027274131774902344, "stdout": "", "stderr": "", "error": null, "eval_count": 324, "prompt_eval_count": 285, "eval_tokens_per_sec": 42.775692433359694, "prompt_tokens_per_sec": 570.9397199620005, "eval_duration_ns": 7574395213, "prompt_eval_duration_ns": 499177041, "code": "def count_up_to(n):\n    \"\"\"Return a list of all prime numbers less than the non‑negative integer n.\"\"\"\n    if n <= 2:\n        return []\n    sieve = bytearray(b'\\x01') * n\n    sieve[0:2] = b'\\x00\\x00'  # 0 and 1 are not prime\n    limit = int(n ** 0.5) + 1\n    for p in range(2, limit):\n        if sieve[p]:\n            step = p\n            start = p * p\n            sieve[start:n:step] = b'\\x00' * ((n - start - 1) // step + 1)\n    return [i for i, is_prime in enumerate(sieve) if is_prime]", "response_raw": "def count_up_to(n):\n    \"\"\"Return a list of all prime numbers less than the non‑negative integer n.\"\"\"\n    if n <= 2:\n        return []\n    sieve = bytearray(b'\\x01') * n\n    sieve[0:2] = b'\\x00\\x00'  # 0 and 1 are not prime\n    limit = int(n ** 0.5) + 1\n    for p in range(2, limit):\n        if sieve[p]:\n            step = p\n            start = p * p\n            sieve[start:n:step] = b'\\x00' * ((n - start - 1) // step + 1)\n    return [i for i, is_prime in enumerate(sieve) if is_prime]"}
{"task_id": "HumanEval/97", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.019491195678711, "exec_time_s": 0.02012324333190918, "stdout": "", "stderr": "", "error": null, "eval_count": 351, "prompt_eval_count": 238, "eval_tokens_per_sec": 42.12656964864708, "prompt_tokens_per_sec": 539.871117520828, "eval_duration_ns": 8332033748, "prompt_eval_duration_ns": 440845958, "code": "def multiply(a, b):\n    \"\"\"Return the product of the unit digits of two integers.\"\"\"\n    return (a % 10) * (b % 10)", "response_raw": "def multiply(a, b):\n    \"\"\"Return the product of the unit digits of two integers.\"\"\"\n    return (a % 10) * (b % 10)"}
{"task_id": "HumanEval/98", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.171303033828735, "exec_time_s": 0.022263050079345703, "stdout": "", "stderr": "", "error": null, "eval_count": 240, "prompt_eval_count": 212, "eval_tokens_per_sec": 43.031618457762384, "prompt_tokens_per_sec": 553.5752720307403, "eval_duration_ns": 5577294292, "prompt_eval_duration_ns": 382965083, "code": "def count_upper(s):\n    vowels = {'A', 'E', 'I', 'O', 'U'}\n    return sum(1 for i, ch in enumerate(s) if i % 2 == 0 and ch in vowels)", "response_raw": "def count_upper(s):\n    vowels = {'A', 'E', 'I', 'O', 'U'}\n    return sum(1 for i, ch in enumerate(s) if i % 2 == 0 and ch in vowels)"}
{"task_id": "HumanEval/99", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.755978107452393, "exec_time_s": 0.02363896369934082, "stdout": "", "stderr": "", "error": null, "eval_count": 501, "prompt_eval_count": 296, "eval_tokens_per_sec": 41.94219281461214, "prompt_tokens_per_sec": 586.4913797160174, "eval_duration_ns": 11945012084, "prompt_eval_duration_ns": 504696250, "code": "from decimal import Decimal, getcontext\n\ndef closest_integer(value):\n    \"\"\"\n    Returns the closest integer to the numeric value represented by the input string.\n    Ties (fractional part exactly 0.5) are rounded away from zero.\n    \"\"\"\n    # Increase precision to handle very long fractional parts\n    getcontext().prec = max(28, len(value) + 5)\n    d = Decimal(value.strip())\n    sign = 1 if d >= 0 else -1\n    abs_d = d.copy_abs()\n    integer_part = int(abs_d)  # floor for positive numbers\n    fraction = abs_d - Decimal(integer_part)\n\n    half = Decimal('0.5')\n    if fraction > half:\n        rounded = integer_part + 1\n    elif fraction < half:\n        rounded = integer_part\n    else:  # exactly half, round away from zero\n        rounded = integer_part + 1\n\n    return sign * rounded", "response_raw": "from decimal import Decimal, getcontext\n\ndef closest_integer(value):\n    \"\"\"\n    Returns the closest integer to the numeric value represented by the input string.\n    Ties (fractional part exactly 0.5) are rounded away from zero.\n    \"\"\"\n    # Increase precision to handle very long fractional parts\n    getcontext().prec = max(28, len(value) + 5)\n    d = Decimal(value.strip())\n    sign = 1 if d >= 0 else -1\n    abs_d = d.copy_abs()\n    integer_part = int(abs_d)  # floor for positive numbers\n    fraction = abs_d - Decimal(integer_part)\n\n    half = Decimal('0.5')\n    if fraction > half:\n        rounded = integer_part + 1\n    elif fraction < half:\n        rounded = integer_part\n    else:  # exactly half, round away from zero\n        rounded = integer_part + 1\n\n    return sign * rounded"}
{"task_id": "HumanEval/100", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.742167949676514, "exec_time_s": 0.022515058517456055, "stdout": "", "stderr": "", "error": null, "eval_count": 370, "prompt_eval_count": 272, "eval_tokens_per_sec": 41.2076774663609, "prompt_tokens_per_sec": 534.2040776001497, "eval_duration_ns": 8978909338, "prompt_eval_duration_ns": 509168708, "code": "def make_a_pile(n):\n    \"\"\"\n    Given a positive integer n, generate a list of n levels where the first level\n    has n stones and each subsequent level has the next odd or even number,\n    depending on whether n is odd or even.\n\n    Parameters:\n    n (int): Positive integer representing the number of levels and the stones in the first level.\n\n    Returns:\n    List[int]: List containing the number of stones in each level.\n    \"\"\"\n    return [n + 2 * i for i in range(n)]", "response_raw": "def make_a_pile(n):\n    \"\"\"\n    Given a positive integer n, generate a list of n levels where the first level\n    has n stones and each subsequent level has the next odd or even number,\n    depending on whether n is odd or even.\n\n    Parameters:\n    n (int): Positive integer representing the number of levels and the stones in the first level.\n\n    Returns:\n    List[int]: List containing the number of stones in each level.\n    \"\"\"\n    return [n + 2 * i for i in range(n)]"}
{"task_id": "HumanEval/101", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 4.431403875350952, "exec_time_s": 0.02188587188720703, "stdout": "", "stderr": "", "error": null, "eval_count": 157, "prompt_eval_count": 256, "eval_tokens_per_sec": 42.08203887206008, "prompt_tokens_per_sec": 495.26806956919137, "eval_duration_ns": 3730807827, "prompt_eval_duration_ns": 516891792, "code": "def words_string(s):\n    return [word for word in s.replace(',', ' ').split() if word]", "response_raw": "def words_string(s):\n    return [word for word in s.replace(',', ' ').split() if word]"}
{"task_id": "HumanEval/102", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.348896026611328, "exec_time_s": 0.015386104583740234, "stdout": "", "stderr": "", "error": null, "eval_count": 458, "prompt_eval_count": 233, "eval_tokens_per_sec": 39.36129384493184, "prompt_tokens_per_sec": 564.9267761673046, "eval_duration_ns": 11635796369, "prompt_eval_duration_ns": 412442833, "code": "def choose_num(x, y):\n    \"\"\"Return the biggest even integer in the inclusive range [x, y].\n    If no such integer exists or x > y, return -1.\"\"\"\n    if x > y:\n        return -1\n    # Find the largest integer <= y\n    candidate = int(y) if y == int(y) else int(y)\n    # Adjust candidate down to the nearest even number\n    if candidate % 2 != 0:\n        candidate -= 1\n    # Ensure candidate is within the range\n    if candidate >= x:\n        return candidate\n    return -1", "response_raw": "def choose_num(x, y):\n    \"\"\"Return the biggest even integer in the inclusive range [x, y].\n    If no such integer exists or x > y, return -1.\"\"\"\n    if x > y:\n        return -1\n    # Find the largest integer <= y\n    candidate = int(y) if y == int(y) else int(y)\n    # Adjust candidate down to the nearest even number\n    if candidate % 2 != 0:\n        candidate -= 1\n    # Ensure candidate is within the range\n    if candidate >= x:\n        return candidate\n    return -1"}
{"task_id": "HumanEval/103", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.395791053771973, "exec_time_s": 0.03251194953918457, "stdout": "", "stderr": "", "error": null, "eval_count": 572, "prompt_eval_count": 280, "eval_tokens_per_sec": 39.312227321224746, "prompt_tokens_per_sec": 559.8653064848353, "eval_duration_ns": 14550180414, "prompt_eval_duration_ns": 500120291, "code": "def rounded_avg(n, m):\n    \"\"\"You are given two positive integers n and m, and your task is to compute the\n    average of the integers from n through m (including n and m). \n    Round the answer to the nearest integer and convert that to binary.\n    If n is greater than m, return -1.\n    Example:\n    rounded_avg(1, 5) => \"0b11\"\n    rounded_avg(7, 5) => -1\n    rounded_avg(10, 20) => \"0b1111\"\n    rounded_avg(20, 33) => \"0b11010\"\n    \"\"\"\n    if n > m:\n        return -1\n    count = m - n + 1\n    total = (n + m) * count // 2\n    avg = round(total / count)\n    return bin(avg)", "response_raw": "def rounded_avg(n, m):\n    \"\"\"You are given two positive integers n and m, and your task is to compute the\n    average of the integers from n through m (including n and m). \n    Round the answer to the nearest integer and convert that to binary.\n    If n is greater than m, return -1.\n    Example:\n    rounded_avg(1, 5) => \"0b11\"\n    rounded_avg(7, 5) => -1\n    rounded_avg(10, 20) => \"0b1111\"\n    rounded_avg(20, 33) => \"0b11010\"\n    \"\"\"\n    if n > m:\n        return -1\n    count = m - n + 1\n    total = (n + m) * count // 2\n    avg = round(total / count)\n    return bin(avg)"}
{"task_id": "HumanEval/104", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.115051031112671, "exec_time_s": 0.023107051849365234, "stdout": "", "stderr": "", "error": null, "eval_count": 253, "prompt_eval_count": 241, "eval_tokens_per_sec": 39.38476557064133, "prompt_tokens_per_sec": 546.6221741317693, "eval_duration_ns": 6423803629, "prompt_eval_duration_ns": 440889542, "code": "def unique_digits(x):\n    \"\"\"Given a list of positive integers x, return a sorted list of all \n    elements that do not contain any even digit.\n\n    Note: Returned list is sorted in increasing order.\n    \"\"\"\n    def has_only_odd_digits(n):\n        while n:\n            d = n % 10\n            if d % 2 == 0:\n                return False\n            n //= 10\n        return True\n\n    result = [num for num in x if has_only_odd_digits(num)]\n    return sorted(result)", "response_raw": "def unique_digits(x):\n    \"\"\"Given a list of positive integers x, return a sorted list of all \n    elements that do not contain any even digit.\n\n    Note: Returned list is sorted in increasing order.\n    \"\"\"\n    def has_only_odd_digits(n):\n        while n:\n            d = n % 10\n            if d % 2 == 0:\n                return False\n            n //= 10\n        return True\n\n    result = [num for num in x if has_only_odd_digits(num)]\n    return sorted(result)"}
{"task_id": "HumanEval/105", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.77930498123169, "exec_time_s": 0.023212909698486328, "stdout": "", "stderr": "", "error": null, "eval_count": 347, "prompt_eval_count": 416, "eval_tokens_per_sec": 39.644119763800454, "prompt_tokens_per_sec": 534.8013513869637, "eval_duration_ns": 8752874375, "prompt_eval_duration_ns": 777858917, "code": "def by_length(arr):\n    \"\"\"\n    Given an array of integers, sort the integers that are between 1 and 9 inclusive,\n    reverse the resulting array, and then replace each digit by its corresponding name from\n    \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\".\n    \"\"\"\n    names = {\n        1: \"One\",\n        2: \"Two\",\n        3: \"Three\",\n        4: \"Four\",\n        5: \"Five\",\n        6: \"Six\",\n        7: \"Seven\",\n        8: \"Eight\",\n        9: \"Nine\",\n    }\n    # Filter valid digits\n    filtered = [x for x in arr if 1 <= x <= 9]\n    # Sort ascending then reverse for descending order\n    filtered.sort()\n    filtered.reverse()\n    # Map to names\n    return [names[d] for d in filtered]", "response_raw": "def by_length(arr):\n    \"\"\"\n    Given an array of integers, sort the integers that are between 1 and 9 inclusive,\n    reverse the resulting array, and then replace each digit by its corresponding name from\n    \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\".\n    \"\"\"\n    names = {\n        1: \"One\",\n        2: \"Two\",\n        3: \"Three\",\n        4: \"Four\",\n        5: \"Five\",\n        6: \"Six\",\n        7: \"Seven\",\n        8: \"Eight\",\n        9: \"Nine\",\n    }\n    # Filter valid digits\n    filtered = [x for x in arr if 1 <= x <= 9]\n    # Sort ascending then reverse for descending order\n    filtered.sort()\n    filtered.reverse()\n    # Map to names\n    return [names[d] for d in filtered]"}
{"task_id": "HumanEval/106", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.549132823944092, "exec_time_s": 0.022823095321655273, "stdout": "", "stderr": "", "error": null, "eval_count": 235, "prompt_eval_count": 264, "eval_tokens_per_sec": 40.53222454939053, "prompt_tokens_per_sec": 485.7867134113705, "eval_duration_ns": 5797855968, "prompt_eval_duration_ns": 543448375, "code": "def f(n):\n    result = []\n    fact = 1\n    for i in range(1, n + 1):\n        if i % 2 == 0:\n            fact *= i\n            result.append(fact)\n        else:\n            result.append(i * (i + 1) // 2)\n    return result", "response_raw": "def f(n):\n    result = []\n    fact = 1\n    for i in range(1, n + 1):\n        if i % 2 == 0:\n            fact *= i\n            result.append(fact)\n        else:\n            result.append(i * (i + 1) // 2)\n    return result"}
{"task_id": "HumanEval/107", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 4.821913957595825, "exec_time_s": 0.028172016143798828, "stdout": "", "stderr": "", "error": null, "eval_count": 170, "prompt_eval_count": 350, "eval_tokens_per_sec": 41.97579269023358, "prompt_tokens_per_sec": 600.7966133953184, "eval_duration_ns": 4049953297, "prompt_eval_duration_ns": 582559875, "code": "def even_odd_palindrome(n):\n    even = odd = 0\n    for i in range(1, n + 1):\n        s = str(i)\n        if s == s[::-1]:\n            if i % 2 == 0:\n                even += 1\n            else:\n                odd += 1\n    return (even, odd)", "response_raw": "def even_odd_palindrome(n):\n    even = odd = 0\n    for i in range(1, n + 1):\n        s = str(i)\n        if s == s[::-1]:\n            if i % 2 == 0:\n                even += 1\n            else:\n                odd += 1\n    return (even, odd)"}
{"task_id": "HumanEval/108", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.503146171569824, "exec_time_s": 0.028309106826782227, "stdout": "", "stderr": "", "error": null, "eval_count": 414, "prompt_eval_count": 264, "eval_tokens_per_sec": 42.43412004004583, "prompt_tokens_per_sec": 551.3741277088996, "eval_duration_ns": 9756299874, "prompt_eval_duration_ns": 478803750, "code": "def count_nums(arr):\n    count = 0\n    for n in arr:\n        sign = -1 if n < 0 else 1\n        digits = str(abs(n))\n        total = 0\n        for i, d in enumerate(digits):\n            val = int(d)\n            if i == 0:\n                val *= sign\n            total += val\n        if total > 0:\n            count += 1\n    return count", "response_raw": "def count_nums(arr):\n    count = 0\n    for n in arr:\n        sign = -1 if n < 0 else 1\n        digits = str(abs(n))\n        total = 0\n        for i, d in enumerate(digits):\n            val = int(d)\n            if i == 0:\n                val *= sign\n            total += val\n        if total > 0:\n            count += 1\n    return count"}
{"task_id": "HumanEval/109", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.205466270446777, "exec_time_s": 0.026810169219970703, "stdout": "", "stderr": "", "error": null, "eval_count": 489, "prompt_eval_count": 441, "eval_tokens_per_sec": 43.57654059097398, "prompt_tokens_per_sec": 631.4365551471008, "eval_duration_ns": 11221634241, "prompt_eval_duration_ns": 698407459, "code": "def move_one_ball(arr):\n    \"\"\"\n    Returns True if the array can be sorted in non-decreasing order by any number\n    of right shift (rotation) operations, otherwise False.\n    An empty array is considered sortable.\n    \"\"\"\n    n = len(arr)\n    if n <= 1:\n        return True\n\n    # Find the index of the smallest element (the would-be start of sorted order)\n    min_val = min(arr)\n    start = arr.index(min_val)\n\n    # Verify that traversing from start wraps around in strictly increasing order\n    for i in range(n - 1):\n        cur = arr[(start + i) % n]\n        nxt = arr[(start + i + 1) % n]\n        if nxt <= cur:  # not strictly increasing\n            return False\n    return True", "response_raw": "def move_one_ball(arr):\n    \"\"\"\n    Returns True if the array can be sorted in non-decreasing order by any number\n    of right shift (rotation) operations, otherwise False.\n    An empty array is considered sortable.\n    \"\"\"\n    n = len(arr)\n    if n <= 1:\n        return True\n\n    # Find the index of the smallest element (the would-be start of sorted order)\n    min_val = min(arr)\n    start = arr.index(min_val)\n\n    # Verify that traversing from start wraps around in strictly increasing order\n    for i in range(n - 1):\n        cur = arr[(start + i) % n]\n        nxt = arr[(start + i + 1) % n]\n        if nxt <= cur:  # not strictly increasing\n            return False\n    return True"}
{"task_id": "HumanEval/110", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 15.298071146011353, "exec_time_s": 0.02904820442199707, "stdout": "", "stderr": "  File \"/var/folders/15/tzdxphxd5tb0cxb8mbs0hn900000gn/T/tmpimka4qim/main.py\", line 3\n    return \"YES\" if total_even >= len(lst1) else \"NO\")\n                                                     ^\nSyntaxError: unmatched ')'\n", "error": null, "eval_count": 595, "prompt_eval_count": 337, "eval_tokens_per_sec": 41.24795349717203, "prompt_tokens_per_sec": 626.0200016028341, "eval_duration_ns": 14424958078, "prompt_eval_duration_ns": 538321458, "code": "def exchange(lst1, lst2):\n    total_even = sum(1 for x in lst1 if x % 2 == 0) + sum(1 for x in lst2 if x % 2 == 0)\n    return \"YES\" if total_even >= len(lst1) else \"NO\")", "response_raw": "def exchange(lst1, lst2):\n    total_even = sum(1 for x in lst1 if x % 2 == 0) + sum(1 for x in lst2 if x % 2 == 0)\n    return \"YES\" if total_even >= len(lst1) else \"NO\")"}
{"task_id": "HumanEval/111", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.42914605140686, "exec_time_s": 0.02581501007080078, "stdout": "", "stderr": "", "error": null, "eval_count": 337, "prompt_eval_count": 291, "eval_tokens_per_sec": 43.65574832428447, "prompt_tokens_per_sec": 616.666307156567, "eval_duration_ns": 7719487420, "prompt_eval_duration_ns": 471892167, "code": "def histogram(test):\n    \"\"\"Given a string representing a space separated lowercase letters, return a dictionary\n    of the letter with the most repetition and containing the corresponding count.\n    If several letters have the same occurrence, return all of them.\n    \n    Example:\n    histogram('a b c') == {'a': 1, 'b': 1, 'c': 1}\n    histogram('a b b a') == {'a': 2, 'b': 2}\n    histogram('a b c a b') == {'a': 2, 'b': 2}\n    histogram('b b b b a') == {'b': 4}\n    histogram('') == {}\n    \"\"\"\n    if not test or not test.strip():\n        return {}\n    counts = {}\n    for ch in test.split():\n        counts[ch] = counts.get(ch, 0) + 1\n    if not counts:\n        return {}\n    max_count = max(counts.values())\n    return {ch: cnt for ch, cnt in counts.items() if cnt == max_count}", "response_raw": "def histogram(test):\n    \"\"\"Given a string representing a space separated lowercase letters, return a dictionary\n    of the letter with the most repetition and containing the corresponding count.\n    If several letters have the same occurrence, return all of them.\n    \n    Example:\n    histogram('a b c') == {'a': 1, 'b': 1, 'c': 1}\n    histogram('a b b a') == {'a': 2, 'b': 2}\n    histogram('a b c a b') == {'a': 2, 'b': 2}\n    histogram('b b b b a') == {'b': 4}\n    histogram('') == {}\n    \"\"\"\n    if not test or not test.strip():\n        return {}\n    counts = {}\n    for ch in test.split():\n        counts[ch] = counts.get(ch, 0) + 1\n    if not counts:\n        return {}\n    max_count = max(counts.values())\n    return {ch: cnt for ch, cnt in counts.items() if cnt == max_count}"}
{"task_id": "HumanEval/112", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.5271008014678955, "exec_time_s": 0.029405832290649414, "stdout": "", "stderr": "", "error": null, "eval_count": 249, "prompt_eval_count": 304, "eval_tokens_per_sec": 42.9780293424635, "prompt_tokens_per_sec": 594.8384079004434, "eval_duration_ns": 5793657918, "prompt_eval_duration_ns": 511063166, "code": "def reverse_delete(s, c):\n    \"\"\"Remove all characters from s that appear in c and check if the resulting string is a palindrome.\n    \n    Args:\n        s (str): The original string.\n        c (str): String containing characters to delete from s.\n    \n    Returns:\n        tuple: (result_string, is_palindrome) where result_string is s after deletions,\n               and is_palindrome is True if result_string reads the same forward and backward.\n    \"\"\"\n    delete_set = set(c)\n    result = ''.join(ch for ch in s if ch not in delete_set)\n    is_palindrome = result == result[::-1]\n    return result, is_palindrome", "response_raw": "def reverse_delete(s, c):\n    \"\"\"Remove all characters from s that appear in c and check if the resulting string is a palindrome.\n    \n    Args:\n        s (str): The original string.\n        c (str): String containing characters to delete from s.\n    \n    Returns:\n        tuple: (result_string, is_palindrome) where result_string is s after deletions,\n               and is_palindrome is True if result_string reads the same forward and backward.\n    \"\"\"\n    delete_set = set(c)\n    result = ''.join(ch for ch in s if ch not in delete_set)\n    is_palindrome = result == result[::-1]\n    return result, is_palindrome"}
{"task_id": "HumanEval/113", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 19.749733924865723, "exec_time_s": 0.028313159942626953, "stdout": "", "stderr": "", "error": null, "eval_count": 790, "prompt_eval_count": 313, "eval_tokens_per_sec": 41.97982568014059, "prompt_tokens_per_sec": 594.4209416586766, "eval_duration_ns": 18818563136, "prompt_eval_duration_ns": 526562875, "code": "def odd_count(lst):\n    \"\"\"\n    Given a list of strings, where each string consists of only digits, return a list.\n    Each element i of the output should be \"the number of odd elements in the\n    string i of the input.\" where all the i's are replaced by the number\n    of odd digits in the i'th string of the input.\n    \"\"\"\n    template = \"the number of odd elements in the string i of the input.\"\n    result = []\n    for s in lst:\n        count = sum(1 for ch in s if int(ch) % 2 == 1)\n        result.append(template.replace('i', str(count)))\n    return result", "response_raw": "def odd_count(lst):\n    \"\"\"\n    Given a list of strings, where each string consists of only digits, return a list.\n    Each element i of the output should be \"the number of odd elements in the\n    string i of the input.\" where all the i's are replaced by the number\n    of odd digits in the i'th string of the input.\n    \"\"\"\n    template = \"the number of odd elements in the string i of the input.\"\n    result = []\n    for s in lst:\n        count = sum(1 for ch in s if int(ch) % 2 == 1)\n        result.append(template.replace('i', str(count)))\n    return result"}
{"task_id": "HumanEval/114", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.820118188858032, "exec_time_s": 0.021604061126708984, "stdout": "", "stderr": "", "error": null, "eval_count": 261, "prompt_eval_count": 228, "eval_tokens_per_sec": 41.96175325099045, "prompt_tokens_per_sec": 592.3448515750983, "eval_duration_ns": 6219949830, "prompt_eval_duration_ns": 384910917, "code": "def minSubArraySum(nums):\n    \"\"\"\n    Given an array of integers nums, find the minimum sum of any non-empty sub-array\n    of nums.\n    Example\n    minSubArraySum([2, 3, 4, 1, 2, 4]) == 1\n    minSubArraySum([-1, -2, -3]) == -6\n    \"\"\"\n    if not nums:\n        raise ValueError(\"Input list must be non-empty\")\n    current_min = global_min = nums[0]\n    for num in nums[1:]:\n        current_min = min(num, current_min + num)\n        global_min = min(global_min, current_min)\n    return global_min", "response_raw": "def minSubArraySum(nums):\n    \"\"\"\n    Given an array of integers nums, find the minimum sum of any non-empty sub-array\n    of nums.\n    Example\n    minSubArraySum([2, 3, 4, 1, 2, 4]) == 1\n    minSubArraySum([-1, -2, -3]) == -6\n    \"\"\"\n    if not nums:\n        raise ValueError(\"Input list must be non-empty\")\n    current_min = global_min = nums[0]\n    for num in nums[1:]:\n        current_min = min(num, current_min + num)\n        global_min = min(global_min, current_min)\n    return global_min"}
{"task_id": "HumanEval/115", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.96033000946045, "exec_time_s": 0.022305011749267578, "stdout": "", "stderr": "", "error": null, "eval_count": 368, "prompt_eval_count": 463, "eval_tokens_per_sec": 40.96942450324103, "prompt_tokens_per_sec": 640.0775281809512, "eval_duration_ns": 8982308257, "prompt_eval_duration_ns": 723349875, "code": "def max_fill(grid, capacity):\n    import math\n    total = 0\n    for row in grid:\n        water = sum(row)\n        if water:\n            total += math.ceil(water / capacity)\n    return total", "response_raw": "def max_fill(grid, capacity):\n    import math\n    total = 0\n    for row in grid:\n        water = sum(row)\n        if water:\n            total += math.ceil(water / capacity)\n    return total"}
{"task_id": "HumanEval/116", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 41.60754895210266, "exec_time_s": 0.03290534019470215, "stdout": "", "stderr": "", "error": null, "eval_count": 1615, "prompt_eval_count": 310, "eval_tokens_per_sec": 40.01360545040595, "prompt_tokens_per_sec": 586.8049342640006, "eval_duration_ns": 40361271668, "prompt_eval_duration_ns": 528284583, "code": "def sort_array(arr):\n    \"\"\"\n    Sort an array of integers according to the number of ones in their binary\n    representation (ascending). For equal counts, sort by the integer's value.\n    \"\"\"\n    return sorted(arr, key=lambda x: (bin(abs(x)).count('1'), x))", "response_raw": "def sort_array(arr):\n    \"\"\"\n    Sort an array of integers according to the number of ones in their binary\n    representation (ascending). For equal counts, sort by the integer's value.\n    \"\"\"\n    return sorted(arr, key=lambda x: (bin(abs(x)).count('1'), x))"}
{"task_id": "HumanEval/117", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.772929906845093, "exec_time_s": 0.017028093338012695, "stdout": "", "stderr": "", "error": null, "eval_count": 249, "prompt_eval_count": 321, "eval_tokens_per_sec": 36.467805666597904, "prompt_tokens_per_sec": 484.69471349455404, "eval_duration_ns": 6827940301, "prompt_eval_duration_ns": 662272542, "code": "def select_words(s, n):\n    vowels = set('aeiouAEIOU')\n    if not s:\n        return []\n    result = []\n    for word in s.split():\n        consonant_count = sum(1 for ch in word if ch.isalpha() and ch not in vowels)\n        if consonant_count == n:\n            result.append(word)\n    return result", "response_raw": "def select_words(s, n):\n    vowels = set('aeiouAEIOU')\n    if not s:\n        return []\n    result = []\n    for word in s.split():\n        consonant_count = sum(1 for ch in word if ch.isalpha() and ch not in vowels)\n        if consonant_count == n:\n            result.append(word)\n    return result"}
{"task_id": "HumanEval/118", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 15.915958166122437, "exec_time_s": 0.03268909454345703, "stdout": "", "stderr": "", "error": null, "eval_count": 623, "prompt_eval_count": 286, "eval_tokens_per_sec": 41.57575495256384, "prompt_tokens_per_sec": 505.6231794637433, "eval_duration_ns": 14984694823, "prompt_eval_duration_ns": 565638625, "code": "def get_closest_vowel(word):\n    \"\"\"You are given a word. Your task is to find the closest vowel that stands between \n    two consonants from the right side of the word (case sensitive).\n    \n    Vowels in the beginning and ending doesn't count. Return empty string if you didn't\n    find any vowel met the above condition. \n\n    You may assume that the given string contains English letter only.\n\n    Example:\n    get_closest_vowel(\"yogurt\") ==> \"u\"\n    get_closest_vowel(\"FULL\") ==> \"U\"\n    get_closest_vowel(\"quick\") ==> \"\"\n    get_closest_vowel(\"ab\") ==> \"\"\n    \"\"\"\n    vowels = set(\"aeiouAEIOU\")\n    n = len(word)\n    for i in range(n - 2, 0, -1):\n        if word[i] in vowels:\n            if word[i - 1] not in vowels and word[i + 1] not in vowels:\n                return word[i]\n    return \"\"", "response_raw": "def get_closest_vowel(word):\n    \"\"\"You are given a word. Your task is to find the closest vowel that stands between \n    two consonants from the right side of the word (case sensitive).\n    \n    Vowels in the beginning and ending doesn't count. Return empty string if you didn't\n    find any vowel met the above condition. \n\n    You may assume that the given string contains English letter only.\n\n    Example:\n    get_closest_vowel(\"yogurt\") ==> \"u\"\n    get_closest_vowel(\"FULL\") ==> \"U\"\n    get_closest_vowel(\"quick\") ==> \"\"\n    get_closest_vowel(\"ab\") ==> \"\"\n    \"\"\"\n    vowels = set(\"aeiouAEIOU\")\n    n = len(word)\n    for i in range(n - 2, 0, -1):\n        if word[i] in vowels:\n            if word[i - 1] not in vowels and word[i + 1] not in vowels:\n                return word[i]\n    return \"\""}
{"task_id": "HumanEval/119", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.454776763916016, "exec_time_s": 0.018413066864013672, "stdout": "", "stderr": "", "error": null, "eval_count": 332, "prompt_eval_count": 305, "eval_tokens_per_sec": 43.36129090265967, "prompt_tokens_per_sec": 548.8337990754947, "eval_duration_ns": 7656598618, "prompt_eval_duration_ns": 555723792, "code": "def match_parens(lst):\n    def is_balanced(s):\n        bal = 0\n        for ch in s:\n            if ch == '(':\n                bal += 1\n            else:  # ')'\n                bal -= 1\n            if bal < 0:\n                return False\n        return bal == 0\n\n    s1, s2 = lst[0], lst[1]\n    return 'Yes' if is_balanced(s1 + s2) or is_balanced(s2 + s1) else 'No'", "response_raw": "def match_parens(lst):\n    def is_balanced(s):\n        bal = 0\n        for ch in s:\n            if ch == '(':\n                bal += 1\n            else:  # ')'\n                bal -= 1\n            if bal < 0:\n                return False\n        return bal == 0\n\n    s1, s2 = lst[0], lst[1]\n    return 'Yes' if is_balanced(s1 + s2) or is_balanced(s2 + s1) else 'No'"}
{"task_id": "HumanEval/120", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.5331289768219, "exec_time_s": 0.020349740982055664, "stdout": "", "stderr": "", "error": null, "eval_count": 364, "prompt_eval_count": 357, "eval_tokens_per_sec": 41.7402059911457, "prompt_tokens_per_sec": 629.3920812955956, "eval_duration_ns": 8720608616, "prompt_eval_duration_ns": 567214000, "code": "def maximum(arr, k):\n    if k == 0:\n        return []\n    import heapq\n    largest = heapq.nlargest(k, arr)\n    return sorted(largest)", "response_raw": "def maximum(arr, k):\n    if k == 0:\n        return []\n    import heapq\n    largest = heapq.nlargest(k, arr)\n    return sorted(largest)"}
{"task_id": "HumanEval/121", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.919759750366211, "exec_time_s": 0.019805192947387695, "stdout": "", "stderr": "", "error": null, "eval_count": 265, "prompt_eval_count": 237, "eval_tokens_per_sec": 42.20070434459742, "prompt_tokens_per_sec": 558.3556778676467, "eval_duration_ns": 6279516044, "prompt_eval_duration_ns": 424460625, "code": "def solution(lst):\n    return sum(x for i, x in enumerate(lst) if i % 2 == 0 and x % 2 != 0)", "response_raw": "def solution(lst):\n    return sum(x for i, x in enumerate(lst) if i % 2 == 0 and x % 2 != 0)"}
{"task_id": "HumanEval/122", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 13.050407886505127, "exec_time_s": 0.02077317237854004, "stdout": "", "stderr": "", "error": null, "eval_count": 496, "prompt_eval_count": 268, "eval_tokens_per_sec": 40.368267226813444, "prompt_tokens_per_sec": 602.7642259099052, "eval_duration_ns": 12286878632, "prompt_eval_duration_ns": 444618291, "code": "def add_elements(arr, k):\n    \"\"\"\n    Given a non-empty array of integers arr and an integer k, return\n    the sum of the elements with at most two digits from the first k elements of arr.\n\n    Example:\n        Input: arr = [111,21,3,4000,5,6,7,8,9], k = 4\n        Output: 24 # sum of 21 + 3\n    \"\"\"\n    total = 0\n    for num in arr[:k]:\n        if -99 <= num <= 99:\n            total += num\n    return total", "response_raw": "def add_elements(arr, k):\n    \"\"\"\n    Given a non-empty array of integers arr and an integer k, return\n    the sum of the elements with at most two digits from the first k elements of arr.\n\n    Example:\n        Input: arr = [111,21,3,4000,5,6,7,8,9], k = 4\n        Output: 24 # sum of 21 + 3\n    \"\"\"\n    total = 0\n    for num in arr[:k]:\n        if -99 <= num <= 99:\n            total += num\n    return total"}
{"task_id": "HumanEval/123", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.775484085083008, "exec_time_s": 0.02280712127685547, "stdout": "", "stderr": "", "error": null, "eval_count": 463, "prompt_eval_count": 373, "eval_tokens_per_sec": 42.57628459142576, "prompt_tokens_per_sec": 605.5379936640172, "eval_duration_ns": 10874598487, "prompt_eval_duration_ns": 615981167, "code": "def get_odd_collatz(n):\n    \"\"\"\n    Given a positive integer n, return a sorted list that has the odd numbers in collatz sequence.\n\n    The Collatz conjecture is a conjecture in mathematics that concerns a sequence defined\n    as follows: start with any positive integer n. Then each term is obtained from the \n    previous term as follows: if the previous term is even, the next term is one half of \n    the previous term. If the previous term is odd, the next term is 3 times the previous\n    term plus 1. The conjecture is that no matter what value of n, the sequence will always reach 1.\n\n    Note: \n        1. Collatz(1) is [1].\n        2. returned list sorted in increasing order.\n\n    For example:\n    get_odd_collatz(5) returns [1, 5] # The collatz sequence for 5 is [5, 16, 8, 4, 2, 1], so the odd numbers are only 1, and 5.\n    \"\"\"\n    if n <= 0:\n        raise ValueError(\"Input must be a positive integer\")\n    odd_numbers = set()\n    current = n\n    while True:\n        if current % 2 == 1:\n            odd_numbers.add(current)\n        if current == 1:\n            break\n        if current % 2 == 0:\n            current //= 2\n        else:\n            current = 3 * current + 1\n    return sorted(odd_numbers)", "response_raw": "def get_odd_collatz(n):\n    \"\"\"\n    Given a positive integer n, return a sorted list that has the odd numbers in collatz sequence.\n\n    The Collatz conjecture is a conjecture in mathematics that concerns a sequence defined\n    as follows: start with any positive integer n. Then each term is obtained from the \n    previous term as follows: if the previous term is even, the next term is one half of \n    the previous term. If the previous term is odd, the next term is 3 times the previous\n    term plus 1. The conjecture is that no matter what value of n, the sequence will always reach 1.\n\n    Note: \n        1. Collatz(1) is [1].\n        2. returned list sorted in increasing order.\n\n    For example:\n    get_odd_collatz(5) returns [1, 5] # The collatz sequence for 5 is [5, 16, 8, 4, 2, 1], so the odd numbers are only 1, and 5.\n    \"\"\"\n    if n <= 0:\n        raise ValueError(\"Input must be a positive integer\")\n    odd_numbers = set()\n    current = n\n    while True:\n        if current % 2 == 1:\n            odd_numbers.add(current)\n        if current == 1:\n            break\n        if current % 2 == 0:\n            current //= 2\n        else:\n            current = 3 * current + 1\n    return sorted(odd_numbers)"}
{"task_id": "HumanEval/124", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 14.414299011230469, "exec_time_s": 0.028226137161254883, "stdout": "", "stderr": "", "error": null, "eval_count": 591, "prompt_eval_count": 403, "eval_tokens_per_sec": 43.833546891028945, "prompt_tokens_per_sec": 662.6165221019374, "eval_duration_ns": 13482824045, "prompt_eval_duration_ns": 608194916, "code": "def valid_date(date):\n    \"\"\"Validate a date string in mm-dd-yyyy format.\"\"\"\n    if not date:\n        return False\n    if date.count('-') != 2:\n        return False\n    parts = date.split('-')\n    if len(parts) != 3:\n        return False\n    month_str, day_str, year_str = parts\n    if not (month_str.isdigit() and day_str.isdigit() and year_str.isdigit()):\n        return False\n    month = int(month_str)\n    day = int(day_str)\n    if month < 1 or month > 12:\n        return False\n    if month == 2:\n        max_day = 29\n    elif month in {1, 3, 5, 7, 8, 10, 12}:\n        max_day = 31\n    else:\n        max_day = 30\n    if day < 1 or day > max_day:\n        return False\n    return True", "response_raw": "def valid_date(date):\n    \"\"\"Validate a date string in mm-dd-yyyy format.\"\"\"\n    if not date:\n        return False\n    if date.count('-') != 2:\n        return False\n    parts = date.split('-')\n    if len(parts) != 3:\n        return False\n    month_str, day_str, year_str = parts\n    if not (month_str.isdigit() and day_str.isdigit() and year_str.isdigit()):\n        return False\n    month = int(month_str)\n    day = int(day_str)\n    if month < 1 or month > 12:\n        return False\n    if month == 2:\n        max_day = 29\n    elif month in {1, 3, 5, 7, 8, 10, 12}:\n        max_day = 31\n    else:\n        max_day = 30\n    if day < 1 or day > max_day:\n        return False\n    return True"}
{"task_id": "HumanEval/125", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.85731816291809, "exec_time_s": 0.018473148345947266, "stdout": "", "stderr": "", "error": null, "eval_count": 536, "prompt_eval_count": 280, "eval_tokens_per_sec": 44.40417833419969, "prompt_tokens_per_sec": 588.7149137265206, "eval_duration_ns": 12070936117, "prompt_eval_duration_ns": 475612208, "code": "def split_words(txt):\n    \"\"\"\n    Given a string of words, return a list of words split on whitespace.\n    If no whitespace exists, split on commas.\n    If no commas either, return the count of lowercase letters whose\n    alphabetical index (a=0, b=1, ...) is odd.\n    \"\"\"\n    # Check for any whitespace characters\n    if any(ch.isspace() for ch in txt):\n        return txt.split()\n    # No whitespace; check for commas\n    if ',' in txt:\n        return txt.split(',')\n    # No whitespace and no commas; count lowercase letters with odd index\n    count = 0\n    for ch in txt:\n        if 'a' <= ch <= 'z':\n            if (ord(ch) - ord('a')) % 2 == 1:\n                count += 1\n    return count", "response_raw": "def split_words(txt):\n    \"\"\"\n    Given a string of words, return a list of words split on whitespace.\n    If no whitespace exists, split on commas.\n    If no commas either, return the count of lowercase letters whose\n    alphabetical index (a=0, b=1, ...) is odd.\n    \"\"\"\n    # Check for any whitespace characters\n    if any(ch.isspace() for ch in txt):\n        return txt.split()\n    # No whitespace; check for commas\n    if ',' in txt:\n        return txt.split(',')\n    # No whitespace and no commas; count lowercase letters with odd index\n    count = 0\n    for ch in txt:\n        if 'a' <= ch <= 'z':\n            if (ord(ch) - ord('a')) % 2 == 1:\n                count += 1\n    return count"}
{"task_id": "HumanEval/126", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.679905891418457, "exec_time_s": 0.026973962783813477, "stdout": "", "stderr": "", "error": null, "eval_count": 439, "prompt_eval_count": 389, "eval_tokens_per_sec": 44.64372142943247, "prompt_tokens_per_sec": 671.6358801181751, "eval_duration_ns": 9833409625, "prompt_eval_duration_ns": 579182875, "code": "def is_sorted(lst):\n    \"\"\"\n    Returns True if the list is in non‑decreasing order and no element appears\n    more than twice; otherwise returns False.\n    \"\"\"\n    if not lst:\n        return True\n\n    prev = lst[0]\n    counts = {prev: 1}\n\n    for x in lst[1:]:\n        # check order\n        if x < prev:\n            return False\n        # count occurrences\n        cnt = counts.get(x, 0) + 1\n        if cnt > 2:\n            return False\n        counts[x] = cnt\n        prev = x\n\n    return True", "response_raw": "def is_sorted(lst):\n    \"\"\"\n    Returns True if the list is in non‑decreasing order and no element appears\n    more than twice; otherwise returns False.\n    \"\"\"\n    if not lst:\n        return True\n\n    prev = lst[0]\n    counts = {prev: 1}\n\n    for x in lst[1:]:\n        # check order\n        if x < prev:\n            return False\n        # count occurrences\n        cnt = counts.get(x, 0) + 1\n        if cnt > 2:\n            return False\n        counts[x] = cnt\n        prev = x\n\n    return True"}
{"task_id": "HumanEval/127", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.691498041152954, "exec_time_s": 0.02810978889465332, "stdout": "", "stderr": "", "error": null, "eval_count": 432, "prompt_eval_count": 393, "eval_tokens_per_sec": 43.84194307764514, "prompt_tokens_per_sec": 686.0230592319938, "eval_duration_ns": 9853577868, "prompt_eval_duration_ns": 572867041, "code": "def intersection(interval1, interval2):\n    a, b = interval1\n    c, d = interval2\n    start = max(a, c)\n    end = min(b, d)\n    if start > end:\n        return \"NO\"\n    length = end - start\n    if length < 2:\n        return \"NO\"\n    if length == 2:\n        return \"YES\"\n    if length % 2 == 0:\n        return \"NO\"\n    i = 3\n    while i * i <= length:\n        if length % i == 0:\n            return \"NO\"\n        i += 2\n    return \"YES\"", "response_raw": "def intersection(interval1, interval2):\n    a, b = interval1\n    c, d = interval2\n    start = max(a, c)\n    end = min(b, d)\n    if start > end:\n        return \"NO\"\n    length = end - start\n    if length < 2:\n        return \"NO\"\n    if length == 2:\n        return \"YES\"\n    if length % 2 == 0:\n        return \"NO\"\n    i = 3\n    while i * i <= length:\n        if length % i == 0:\n            return \"NO\"\n        i += 2\n    return \"YES\"\n"}
{"task_id": "HumanEval/128", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.74772596359253, "exec_time_s": 0.0219571590423584, "stdout": "", "stderr": "", "error": null, "eval_count": 402, "prompt_eval_count": 262, "eval_tokens_per_sec": 44.487206599972524, "prompt_tokens_per_sec": 588.3973979971114, "eval_duration_ns": 9036305732, "prompt_eval_duration_ns": 445277292, "code": "def prod_signs(arr):\n    \"\"\"\n    You are given an array arr of integers and you need to return\n    sum of magnitudes of integers multiplied by product of all signs\n    of each number in the array, represented by 1, -1 or 0.\n    Note: return None for empty arr.\n\n    Example:\n    >>> prod_signs([1, 2, 2, -4]) == -9\n    >>> prod_signs([0, 1]) == 0\n    >>> prod_signs([]) == None\n    \"\"\"\n    if not arr:\n        return None\n\n    total_magnitude = sum(abs(x) for x in arr)\n\n    product_sign = 1\n    for x in arr:\n        if x == 0:\n            product_sign = 0\n            break\n        product_sign *= 1 if x > 0 else -1\n\n    return total_magnitude * product_sign", "response_raw": "def prod_signs(arr):\n    \"\"\"\n    You are given an array arr of integers and you need to return\n    sum of magnitudes of integers multiplied by product of all signs\n    of each number in the array, represented by 1, -1 or 0.\n    Note: return None for empty arr.\n\n    Example:\n    >>> prod_signs([1, 2, 2, -4]) == -9\n    >>> prod_signs([0, 1]) == 0\n    >>> prod_signs([]) == None\n    \"\"\"\n    if not arr:\n        return None\n\n    total_magnitude = sum(abs(x) for x in arr)\n\n    product_sign = 1\n    for x in arr:\n        if x == 0:\n            product_sign = 0\n            break\n        product_sign *= 1 if x > 0 else -1\n\n    return total_magnitude * product_sign"}
{"task_id": "HumanEval/129", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 27.1425461769104, "exec_time_s": 0.03862786293029785, "stdout": "", "stderr": "", "error": null, "eval_count": 1103, "prompt_eval_count": 536, "eval_tokens_per_sec": 42.74006139445834, "prompt_tokens_per_sec": 712.0965516515905, "eval_duration_ns": 25807169293, "prompt_eval_duration_ns": 752706917, "code": "def minPath(grid, k):\n    n = len(grid)\n    # Find position of value 1\n    start = None\n    for i in range(n):\n        for j in range(n):\n            if grid[i][j] == 1:\n                start = (i, j)\n                break\n        if start:\n            break\n    if k == 0:\n        return []\n    ans = [1]\n    current = {start}\n    dirs = [(1,0),(-1,0),(0,1),(0,-1)]\n    for _ in range(1, k):\n        min_val = float('inf')\n        next_pos = set()\n        for r, c in current:\n            for dr, dc in dirs:\n                nr, nc = r + dr, c + dc\n                if 0 <= nr < n and 0 <= nc < n:\n                    val = grid[nr][nc]\n                    if val < min_val:\n                        min_val = val\n                        next_pos = {(nr, nc)}\n                    elif val == min_val:\n                        next_pos.add((nr, nc))\n        ans.append(min_val)\n        current = next_pos\n    return ans", "response_raw": "def minPath(grid, k):\n    n = len(grid)\n    # Find position of value 1\n    start = None\n    for i in range(n):\n        for j in range(n):\n            if grid[i][j] == 1:\n                start = (i, j)\n                break\n        if start:\n            break\n    if k == 0:\n        return []\n    ans = [1]\n    current = {start}\n    dirs = [(1,0),(-1,0),(0,1),(0,-1)]\n    for _ in range(1, k):\n        min_val = float('inf')\n        next_pos = set()\n        for r, c in current:\n            for dr, dc in dirs:\n                nr, nc = r + dr, c + dc\n                if 0 <= nr < n and 0 <= nc < n:\n                    val = grid[nr][nc]\n                    if val < min_val:\n                        min_val = val\n                        next_pos = {(nr, nc)}\n                    elif val == min_val:\n                        next_pos.add((nr, nc))\n        ans.append(min_val)\n        current = next_pos\n    return ans"}
{"task_id": "HumanEval/130", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 29.14913511276245, "exec_time_s": 0.02477717399597168, "stdout": "", "stderr": "", "error": null, "eval_count": 1189, "prompt_eval_count": 374, "eval_tokens_per_sec": 42.46134684011982, "prompt_tokens_per_sec": 644.4080721077609, "eval_duration_ns": 28001937962, "prompt_eval_duration_ns": 580377584, "code": "def tri(n):\n    \"\"\"Return a list of the first n+1 numbers of the Tribonacci sequence as defined.\"\"\"\n    res = [0] * (n + 1)\n    for i in range(n + 1):\n        if i % 2 == 0:\n            # even index (including 0)\n            res[i] = 1 + i // 2\n        else:\n            if i == 1:\n                res[i] = 3\n            else:\n                # odd index >= 3\n                next_even = i + 1\n                val_next = 1 + next_even // 2  # tri(i+1) using even formula\n                res[i] = res[i - 1] + res[i - 2] + val_next\n    return res", "response_raw": "def tri(n):\n    \"\"\"Return a list of the first n+1 numbers of the Tribonacci sequence as defined.\"\"\"\n    res = [0] * (n + 1)\n    for i in range(n + 1):\n        if i % 2 == 0:\n            # even index (including 0)\n            res[i] = 1 + i // 2\n        else:\n            if i == 1:\n                res[i] = 3\n            else:\n                # odd index >= 3\n                next_even = i + 1\n                val_next = 1 + next_even // 2  # tri(i+1) using even formula\n                res[i] = res[i - 1] + res[i - 2] + val_next\n    return res"}
{"task_id": "HumanEval/131", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.954261064529419, "exec_time_s": 0.020481109619140625, "stdout": "", "stderr": "", "error": null, "eval_count": 233, "prompt_eval_count": 211, "eval_tokens_per_sec": 43.543201308875595, "prompt_tokens_per_sec": 525.4316056449035, "eval_duration_ns": 5351007574, "prompt_eval_duration_ns": 401574625, "code": "def digits(n):\n    \"\"\"Given a positive integer n, return the product of the odd digits.\n    Return 0 if all digits are even.\n    For example:\n    digits(1)  == 1\n    digits(4)  == 0\n    digits(235) == 15\n    \"\"\"\n    product = 1\n    has_odd = False\n    while n > 0:\n        d = n % 10\n        if d % 2 == 1:\n            product *= d\n            has_odd = True\n        n //= 10\n    return product if has_odd else 0", "response_raw": "def digits(n):\n    \"\"\"Given a positive integer n, return the product of the odd digits.\n    Return 0 if all digits are even.\n    For example:\n    digits(1)  == 1\n    digits(4)  == 0\n    digits(235) == 15\n    \"\"\"\n    product = 1\n    has_odd = False\n    while n > 0:\n        d = n % 10\n        if d % 2 == 1:\n            product *= d\n            has_odd = True\n        n //= 10\n    return product if has_odd else 0"}
{"task_id": "HumanEval/132", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 22.090271949768066, "exec_time_s": 0.022171735763549805, "stdout": "", "stderr": "", "error": null, "eval_count": 926, "prompt_eval_count": 273, "eval_tokens_per_sec": 43.69638541073931, "prompt_tokens_per_sec": 633.247463972064, "eval_duration_ns": 21191684193, "prompt_eval_duration_ns": 431111083, "code": "def is_nested(string):\n    n = len(string)\n    # Find first '['\n    i = 0\n    while i < n and string[i] != '[':\n        i += 1\n    if i == n:\n        return False\n    # Find second '[' after i\n    j = i + 1\n    while j < n and string[j] != '[':\n        j += 1\n    if j == n:\n        return False\n    # Find first ']' after j\n    k = j + 1\n    while k < n and string[k] != ']':\n        k += 1\n    if k == n:\n        return False\n    # Find second ']' after k\n    l = k + 1\n    while l < n and string[l] != ']':\n        l += 1\n    if l == n:\n        return False\n    return True", "response_raw": "def is_nested(string):\n    n = len(string)\n    # Find first '['\n    i = 0\n    while i < n and string[i] != '[':\n        i += 1\n    if i == n:\n        return False\n    # Find second '[' after i\n    j = i + 1\n    while j < n and string[j] != '[':\n        j += 1\n    if j == n:\n        return False\n    # Find first ']' after j\n    k = j + 1\n    while k < n and string[k] != ']':\n        k += 1\n    if k == n:\n        return False\n    # Find second ']' after k\n    l = k + 1\n    while l < n and string[l] != ']':\n        l += 1\n    if l == n:\n        return False\n    return True"}
{"task_id": "HumanEval/133", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.760831117630005, "exec_time_s": 0.019690990447998047, "stdout": "", "stderr": "", "error": null, "eval_count": 529, "prompt_eval_count": 298, "eval_tokens_per_sec": 44.141268917996406, "prompt_tokens_per_sec": 633.2373649357028, "eval_duration_ns": 11984249954, "prompt_eval_duration_ns": 470597625, "code": "import math\n\ndef sum_squares(lst):\n    \"\"\"You are given a list of numbers.\n    You need to return the sum of squared numbers in the given list,\n    round each element in the list to the upper int(Ceiling) first.\n    Examples:\n    For lst = [1,2,3] the output should be 14\n    For lst = [1,4,9] the output should be 98\n    For lst = [1,3,5,7] the output should be 84\n    For lst = [1.4,4.2,0] the output should be 29\n    For lst = [-2.4,1,1] the output should be 6\n    \"\"\"\n    total = 0\n    for x in lst:\n        c = math.ceil(x)\n        total += c * c\n    return total", "response_raw": "import math\n\ndef sum_squares(lst):\n    \"\"\"You are given a list of numbers.\n    You need to return the sum of squared numbers in the given list,\n    round each element in the list to the upper int(Ceiling) first.\n    Examples:\n    For lst = [1,2,3] the output should be 14\n    For lst = [1,4,9] the output should be 98\n    For lst = [1,3,5,7] the output should be 84\n    For lst = [1.4,4.2,0] the output should be 29\n    For lst = [-2.4,1,1] the output should be 6\n    \"\"\"\n    total = 0\n    for x in lst:\n        c = math.ceil(x)\n        total += c * c\n    return total"}
{"task_id": "HumanEval/134", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.081236124038696, "exec_time_s": 0.024547100067138672, "stdout": "", "stderr": "", "error": null, "eval_count": 409, "prompt_eval_count": 277, "eval_tokens_per_sec": 43.813701699660626, "prompt_tokens_per_sec": 574.3668580983714, "eval_duration_ns": 9334979336, "prompt_eval_duration_ns": 482270166, "code": "def check_if_last_char_is_a_letter(txt: str) -> bool:\n    if not txt:\n        return False\n    last_char = txt[-1]\n    if not last_char.isalpha():\n        return False\n    if len(txt) == 1:\n        return True\n    return txt[-2] == ' '", "response_raw": "def check_if_last_char_is_a_letter(txt: str) -> bool:\n    if not txt:\n        return False\n    last_char = txt[-1]\n    if not last_char.isalpha():\n        return False\n    if len(txt) == 1:\n        return True\n    return txt[-2] == ' '"}
{"task_id": "HumanEval/135", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.283020734786987, "exec_time_s": 0.017637968063354492, "stdout": "", "stderr": "", "error": null, "eval_count": 198, "prompt_eval_count": 243, "eval_tokens_per_sec": 42.400791726085274, "prompt_tokens_per_sec": 584.7024514191667, "eval_duration_ns": 4669724124, "prompt_eval_duration_ns": 415596000, "code": "def can_arrange(arr):\n    \"\"\"\n    Returns the largest index i such that arr[i] < arr[i-1].\n    If no such index exists, returns -1.\n    \"\"\"\n    result = -1\n    for i in range(1, len(arr)):\n        if arr[i] < arr[i - 1]:\n            result = i\n    return result", "response_raw": "def can_arrange(arr):\n    \"\"\"\n    Returns the largest index i such that arr[i] < arr[i-1].\n    If no such index exists, returns -1.\n    \"\"\"\n    result = -1\n    for i in range(1, len(arr)):\n        if arr[i] < arr[i - 1]:\n            result = i\n    return result"}
{"task_id": "HumanEval/136", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.1703550815582275, "exec_time_s": 0.02005481719970703, "stdout": "", "stderr": "", "error": null, "eval_count": 284, "prompt_eval_count": 282, "eval_tokens_per_sec": 43.74415461706369, "prompt_tokens_per_sec": 617.0960216180554, "eval_duration_ns": 6492295999, "prompt_eval_duration_ns": 456979125, "code": "def largest_smallest_integers(lst):\n    max_negative = None\n    min_positive = None\n    for x in lst:\n        if isinstance(x, int):\n            if x < 0:\n                if max_negative is None or x > max_negative:\n                    max_negative = x\n            elif x > 0:\n                if min_positive is None or x < min_positive:\n                    min_positive = x\n    return (max_negative, min_positive)", "response_raw": "def largest_smallest_integers(lst):\n    max_negative = None\n    min_positive = None\n    for x in lst:\n        if isinstance(x, int):\n            if x < 0:\n                if max_negative is None or x > max_negative:\n                    max_negative = x\n            elif x > 0:\n                if min_positive is None or x < min_positive:\n                    min_positive = x\n    return (max_negative, min_positive)"}
{"task_id": "HumanEval/137", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.72431993484497, "exec_time_s": 0.02903294563293457, "stdout": "", "stderr": "", "error": null, "eval_count": 399, "prompt_eval_count": 281, "eval_tokens_per_sec": 44.280439959118304, "prompt_tokens_per_sec": 615.151946832553, "eval_duration_ns": 9010750579, "prompt_eval_duration_ns": 456797709, "code": "def compare_one(a, b):\n    def to_number(x):\n        if isinstance(x, (int, float)):\n            return float(x)\n        if isinstance(x, str):\n            try:\n                return float(x.replace(',', '.'))\n            except ValueError:\n                raise ValueError(f\"Invalid numeric string: {x}\")\n        raise TypeError(f\"Unsupported type: {type(x)}\")\n    num_a = to_number(a)\n    num_b = to_number(b)\n    if num_a == num_b:\n        return None\n    return a if num_a > num_b else b", "response_raw": "def compare_one(a, b):\n    def to_number(x):\n        if isinstance(x, (int, float)):\n            return float(x)\n        if isinstance(x, str):\n            try:\n                return float(x.replace(',', '.'))\n            except ValueError:\n                raise ValueError(f\"Invalid numeric string: {x}\")\n        raise TypeError(f\"Unsupported type: {type(x)}\")\n    num_a = to_number(a)\n    num_b = to_number(b)\n    if num_a == num_b:\n        return None\n    return a if num_a > num_b else b"}
{"task_id": "HumanEval/138", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.24753212928772, "exec_time_s": 0.028132200241088867, "stdout": "", "stderr": "", "error": null, "eval_count": 335, "prompt_eval_count": 217, "eval_tokens_per_sec": 43.80046434462143, "prompt_tokens_per_sec": 605.3587500318197, "eval_duration_ns": 7648320743, "prompt_eval_duration_ns": 358465125, "code": "def is_equal_to_sum_even(n):\n    \"\"\"Evaluate whether the given number n can be written as the sum of exactly 4 positive even numbers\n    Example\n    is_equal_to_sum_even(4) == False\n    is_equal_to_sum_even(6) == False\n    is_equal_to_sum_even(8) == True\n    \"\"\"\n    return n >= 8 and n % 2 == 0", "response_raw": "def is_equal_to_sum_even(n):\n    \"\"\"Evaluate whether the given number n can be written as the sum of exactly 4 positive even numbers\n    Example\n    is_equal_to_sum_even(4) == False\n    is_equal_to_sum_even(6) == False\n    is_equal_to_sum_even(8) == True\n    \"\"\"\n    return n >= 8 and n % 2 == 0"}
{"task_id": "HumanEval/139", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 8.487695932388306, "exec_time_s": 0.0222170352935791, "stdout": "", "stderr": "Traceback (most recent call last):\n  File \"/var/folders/15/tzdxphxd5tb0cxb8mbs0hn900000gn/T/tmp57eih5v8/main.py\", line 12, in <module>\n    solve()\n  File \"/var/folders/15/tzdxphxd5tb0cxb8mbs0hn900000gn/T/tmp57eih5v8/main.py\", line 2, in solve\n    data = sys.stdin.read().strip().split()\nNameError: name 'sys' is not defined\n", "error": null, "eval_count": 349, "prompt_eval_count": 235, "eval_tokens_per_sec": 44.550931957090484, "prompt_tokens_per_sec": 577.3014886003849, "eval_duration_ns": 7833730624, "prompt_eval_duration_ns": 407066333, "code": "def solve() -> None:\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    try:\n        n = int(data[0])\n    except ValueError:\n        return\n    print(special_factorial(n))\n\nif __name__ == \"__main__\":\n    solve()", "response_raw": "import sys\n\ndef special_factorial(n: int) -> int:\n    prod = 1\n    fact = 1\n    for i in range(1, n + 1):\n        fact *= i\n        prod *= fact\n    return prod\n\ndef solve() -> None:\n    data = sys.stdin.read().strip().split()\n    if not data:\n        return\n    try:\n        n = int(data[0])\n    except ValueError:\n        return\n    print(special_factorial(n))\n\nif __name__ == \"__main__\":\n    solve()\n"}
{"task_id": "HumanEval/140", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.06091022491455, "exec_time_s": 0.026292800903320312, "stdout": "", "stderr": "", "error": null, "eval_count": 489, "prompt_eval_count": 246, "eval_tokens_per_sec": 43.04831753777264, "prompt_tokens_per_sec": 608.4141074166237, "eval_duration_ns": 11359328958, "prompt_eval_duration_ns": 404329875, "code": "import re\n\ndef fix_spaces(text):\n    \"\"\"\n    Given a string text, replace all spaces in it with underscores, \n    and if a string has more than 2 consecutive spaces, \n    then replace all consecutive spaces with - \n    \n    fix_spaces(\"Example\") == \"Example\"\n    fix_spaces(\"Example 1\") == \"Example_1\"\n    fix_spaces(\" Example 2\") == \"_Example_2\"\n    fix_spaces(\" Example   3\") == \"_Example-3\"\n    \"\"\"\n    # Replace runs of three or more spaces with a single dash\n    text = re.sub(r' {3,}', '-', text)\n    # Replace any remaining single spaces with underscores\n    return text.replace(' ', '_')", "response_raw": "import re\n\ndef fix_spaces(text):\n    \"\"\"\n    Given a string text, replace all spaces in it with underscores, \n    and if a string has more than 2 consecutive spaces, \n    then replace all consecutive spaces with - \n    \n    fix_spaces(\"Example\") == \"Example\"\n    fix_spaces(\"Example 1\") == \"Example_1\"\n    fix_spaces(\" Example 2\") == \"_Example_2\"\n    fix_spaces(\" Example   3\") == \"_Example-3\"\n    \"\"\"\n    # Replace runs of three or more spaces with a single dash\n    text = re.sub(r' {3,}', '-', text)\n    # Replace any remaining single spaces with underscores\n    return text.replace(' ', '_')"}
{"task_id": "HumanEval/141", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 8.591239929199219, "exec_time_s": 0.028050899505615234, "stdout": "", "stderr": "", "error": null, "eval_count": 344, "prompt_eval_count": 354, "eval_tokens_per_sec": 44.30918194782982, "prompt_tokens_per_sec": 606.4548899922522, "eval_duration_ns": 7763627873, "prompt_eval_duration_ns": 583720250, "code": "def file_name_check(file_name: str) -> str:\n    # Condition: exactly one dot\n    if file_name.count('.') != 1:\n        return 'No'\n    name, ext = file_name.split('.')\n    # Condition: non‑empty name and starts with a latin letter\n    if not name or not name[0].isalpha() or not ('a' <= name[0].lower() <= 'z'):\n        return 'No'\n    # Condition: allowed extensions\n    if ext not in {'txt', 'exe', 'dll'}:\n        return 'No'\n    # Condition: at most three digits in the whole string\n    digit_count = sum(ch.isdigit() for ch in file_name)\n    if digit_count > 3:\n        return 'No'\n    return 'Yes'", "response_raw": "def file_name_check(file_name: str) -> str:\n    # Condition: exactly one dot\n    if file_name.count('.') != 1:\n        return 'No'\n    name, ext = file_name.split('.')\n    # Condition: non‑empty name and starts with a latin letter\n    if not name or not name[0].isalpha() or not ('a' <= name[0].lower() <= 'z'):\n        return 'No'\n    # Condition: allowed extensions\n    if ext not in {'txt', 'exe', 'dll'}:\n        return 'No'\n    # Condition: at most three digits in the whole string\n    digit_count = sum(ch.isdigit() for ch in file_name)\n    if digit_count > 3:\n        return 'No'\n    return 'Yes'"}
{"task_id": "HumanEval/142", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.735054731369019, "exec_time_s": 0.022434234619140625, "stdout": "", "stderr": "", "error": null, "eval_count": 436, "prompt_eval_count": 310, "eval_tokens_per_sec": 43.66710462829623, "prompt_tokens_per_sec": 643.3114626043658, "eval_duration_ns": 9984632682, "prompt_eval_duration_ns": 481881667, "code": "def sum_squares(lst):\n    total = 0\n    for i, val in enumerate(lst):\n        if i % 3 == 0:\n            total += val * val\n        elif i % 4 == 0:\n            total += val * val * val\n        else:\n            total += val\n    return total", "response_raw": "def sum_squares(lst):\n    total = 0\n    for i, val in enumerate(lst):\n        if i % 3 == 0:\n            total += val * val\n        elif i % 4 == 0:\n            total += val * val * val\n        else:\n            total += val\n    return total"}
{"task_id": "HumanEval/143", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.215517282485962, "exec_time_s": 0.023067951202392578, "stdout": "", "stderr": "", "error": null, "eval_count": 239, "prompt_eval_count": 287, "eval_tokens_per_sec": 43.14626539613485, "prompt_tokens_per_sec": 610.9431741147728, "eval_duration_ns": 5539297499, "prompt_eval_duration_ns": 469765458, "code": "def words_in_sentence(sentence):\n    \"\"\"\n    Returns a string containing the words from the original sentence\n    whose lengths are prime numbers, preserving the original order.\n    \"\"\"\n    def is_prime(n):\n        if n < 2:\n            return False\n        if n == 2:\n            return True\n        if n % 2 == 0:\n            return False\n        i = 3\n        while i * i <= n:\n            if n % i == 0:\n                return False\n            i += 2\n        return True\n\n    words = sentence.split()\n    prime_words = [w for w in words if is_prime(len(w))]\n    return \" \".join(prime_words)", "response_raw": "def words_in_sentence(sentence):\n    \"\"\"\n    Returns a string containing the words from the original sentence\n    whose lengths are prime numbers, preserving the original order.\n    \"\"\"\n    def is_prime(n):\n        if n < 2:\n            return False\n        if n == 2:\n            return True\n        if n % 2 == 0:\n            return False\n        i = 3\n        while i * i <= n:\n            if n % i == 0:\n                return False\n            i += 2\n        return True\n\n    words = sentence.split()\n    prime_words = [w for w in words if is_prime(len(w))]\n    return \" \".join(prime_words)"}
{"task_id": "HumanEval/144", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.202836990356445, "exec_time_s": 0.018253087997436523, "stdout": "", "stderr": "", "error": null, "eval_count": 202, "prompt_eval_count": 295, "eval_tokens_per_sec": 44.46257268153409, "prompt_tokens_per_sec": 633.2217648100085, "eval_duration_ns": 4543146917, "prompt_eval_duration_ns": 465871542, "code": "def simplify(x, n):\n    num1, den1 = map(int, x.split('/'))\n    num2, den2 = map(int, n.split('/'))\n    numerator = num1 * num2\n    denominator = den1 * den2\n    return numerator % denominator == 0", "response_raw": "def simplify(x, n):\n    num1, den1 = map(int, x.split('/'))\n    num2, den2 = map(int, n.split('/'))\n    numerator = num1 * num2\n    denominator = den1 * den2\n    return numerator % denominator == 0"}
{"task_id": "HumanEval/145", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 29.920448064804077, "exec_time_s": 0.02369523048400879, "stdout": "", "stderr": "", "error": null, "eval_count": 1241, "prompt_eval_count": 255, "eval_tokens_per_sec": 42.90974499774571, "prompt_tokens_per_sec": 582.4877896796581, "eval_duration_ns": 28921169307, "prompt_eval_duration_ns": 437777417, "code": "def order_by_points(nums):\n    \"\"\"\n    Sorts the list of integers in ascending order based on the sum of their digits.\n    If multiple numbers have the same digit sum, negative numbers come before\n    non‑negative numbers, preserving the original relative order otherwise.\n    \"\"\"\n    def digit_sum(n):\n        return sum(int(d) for d in str(abs(n)))\n    return sorted(nums, key=lambda x: (digit_sum(x), 0 if x < 0 else 1))", "response_raw": "def order_by_points(nums):\n    \"\"\"\n    Sorts the list of integers in ascending order based on the sum of their digits.\n    If multiple numbers have the same digit sum, negative numbers come before\n    non‑negative numbers, preserving the original relative order otherwise.\n    \"\"\"\n    def digit_sum(n):\n        return sum(int(d) for d in str(abs(n)))\n    return sorted(nums, key=lambda x: (digit_sum(x), 0 if x < 0 else 1))"}
{"task_id": "HumanEval/146", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.115091323852539, "exec_time_s": 0.02595686912536621, "stdout": "", "stderr": "", "error": null, "eval_count": 369, "prompt_eval_count": 259, "eval_tokens_per_sec": 43.678789879964434, "prompt_tokens_per_sec": 623.2624903668044, "eval_duration_ns": 8448036244, "prompt_eval_duration_ns": 415555250, "code": "def specialFilter(nums):\n    count = 0\n    for n in nums:\n        if n > 10:\n            s = str(abs(n))\n            if int(s[0]) % 2 == 1 and int(s[-1]) % 2 == 1:\n                count += 1\n    return count", "response_raw": "def specialFilter(nums):\n    count = 0\n    for n in nums:\n        if n > 10:\n            s = str(abs(n))\n            if int(s[0]) % 2 == 1 and int(s[-1]) % 2 == 1:\n                count += 1\n    return count"}
{"task_id": "HumanEval/147", "model": "gpt-oss:120b", "ok": false, "sample_index": 0, "gen_time_s": 12.810695171356201, "exec_time_s": 8.004964828491211, "stdout": "", "stderr": "", "error": "timeout", "eval_count": 527, "prompt_eval_count": 305, "eval_tokens_per_sec": 44.015658164312015, "prompt_tokens_per_sec": 573.0882457252079, "eval_duration_ns": 11973011923, "prompt_eval_duration_ns": 532204250, "code": "def get_max_triples(n):\n    if n < 3:\n        return 0\n    cnt = [0, 0, 0]  # counts for residues 0,1,2\n    for i in range(1, n + 1):\n        val_mod = (i * (i - 1) + 1) % 3\n        cnt[val_mod] += 1\n    def comb3(x):\n        return x * (x - 1) * (x - 2) // 6 if x >= 3 else 0\n    total = comb3(cnt[0]) + comb3(cnt[1]) + comb3(cnt[2]) + cnt[0] * cnt[1] * cnt[2]\n    return total\n\nif __name__ == \"__main__\":\n    import sys\n    data = sys.stdin.read().strip().split()\n    if data:\n        n = int(data[0])\n        print(get_max_triples(n))", "response_raw": "def get_max_triples(n):\n    if n < 3:\n        return 0\n    cnt = [0, 0, 0]  # counts for residues 0,1,2\n    for i in range(1, n + 1):\n        val_mod = (i * (i - 1) + 1) % 3\n        cnt[val_mod] += 1\n    def comb3(x):\n        return x * (x - 1) * (x - 2) // 6 if x >= 3 else 0\n    total = comb3(cnt[0]) + comb3(cnt[1]) + comb3(cnt[2]) + cnt[0] * cnt[1] * cnt[2]\n    return total\n\nif __name__ == \"__main__\":\n    import sys\n    data = sys.stdin.read().strip().split()\n    if data:\n        n = int(data[0])\n        print(get_max_triples(n))"}
{"task_id": "HumanEval/148", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.82579779624939, "exec_time_s": 0.023790836334228516, "stdout": "", "stderr": "", "error": null, "eval_count": 343, "prompt_eval_count": 351, "eval_tokens_per_sec": 43.979762671945146, "prompt_tokens_per_sec": 199.9679396131005, "eval_duration_ns": 7799041631, "prompt_eval_duration_ns": 1755281375, "code": "def bf(planet1, planet2):\n    planets = [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"]\n    if planet1 not in planets or planet2 not in planets:\n        return ()\n    idx1, idx2 = planets.index(planet1), planets.index(planet2)\n    start, end = sorted((idx1, idx2))\n    between = planets[start + 1:end]\n    return tuple(between)", "response_raw": "def bf(planet1, planet2):\n    planets = [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"]\n    if planet1 not in planets or planet2 not in planets:\n        return ()\n    idx1, idx2 = planets.index(planet1), planets.index(planet2)\n    start, end = sorted((idx1, idx2))\n    between = planets[start + 1:end]\n    return tuple(between)"}
{"task_id": "HumanEval/149", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.595205068588257, "exec_time_s": 0.0221099853515625, "stdout": "", "stderr": "", "error": null, "eval_count": 302, "prompt_eval_count": 327, "eval_tokens_per_sec": 43.89880583626571, "prompt_tokens_per_sec": 671.2643608696183, "eval_duration_ns": 6879458205, "prompt_eval_duration_ns": 487140416, "code": "def sorted_list_sum(lst):\n    \"\"\"\n    Accepts a list of strings, removes strings with odd lengths,\n    and returns the remaining strings sorted by length (ascending) and\n    alphabetically for equal lengths.\n    \"\"\"\n    # Filter out strings with odd length\n    even_strings = [s for s in lst if len(s) % 2 == 0]\n    # Sort by length then alphabetically\n    even_strings.sort(key=lambda x: (len(x), x))\n    return even_strings", "response_raw": "def sorted_list_sum(lst):\n    \"\"\"\n    Accepts a list of strings, removes strings with odd lengths,\n    and returns the remaining strings sorted by length (ascending) and\n    alphabetically for equal lengths.\n    \"\"\"\n    # Filter out strings with odd length\n    even_strings = [s for s in lst if len(s) % 2 == 0]\n    # Sort by length then alphabetically\n    even_strings.sort(key=lambda x: (len(x), x))\n    return even_strings"}
{"task_id": "HumanEval/150", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 4.986891031265259, "exec_time_s": 0.021342039108276367, "stdout": "", "stderr": "", "error": null, "eval_count": 199, "prompt_eval_count": 226, "eval_tokens_per_sec": 45.03209825054136, "prompt_tokens_per_sec": 605.9055014015747, "eval_duration_ns": 4419070124, "prompt_eval_duration_ns": 372995458, "code": "def x_or_y(n, x, y):\n    \"\"\"Return x if n is prime, otherwise return y.\"\"\"\n    if n <= 1:\n        return y\n    if n <= 3:\n        return x\n    if n % 2 == 0 or n % 3 == 0:\n        return y\n    i = 5\n    w = 2\n    while i * i <= n:\n        if n % i == 0:\n            return y\n        i += w\n        w = 6 - w\n    return x", "response_raw": "def x_or_y(n, x, y):\n    \"\"\"Return x if n is prime, otherwise return y.\"\"\"\n    if n <= 1:\n        return y\n    if n <= 3:\n        return x\n    if n % 2 == 0 or n % 3 == 0:\n        return y\n    i = 5\n    w = 2\n    while i * i <= n:\n        if n % i == 0:\n            return y\n        i += w\n        w = 6 - w\n    return x"}
{"task_id": "HumanEval/151", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 11.419857025146484, "exec_time_s": 0.01873326301574707, "stdout": "", "stderr": "", "error": null, "eval_count": 478, "prompt_eval_count": 277, "eval_tokens_per_sec": 44.634751482492966, "prompt_tokens_per_sec": 652.0643992830709, "eval_duration_ns": 10709144425, "prompt_eval_duration_ns": 424804667, "code": "def double_the_difference(lst):\n    total = 0\n    for x in lst:\n        if isinstance(x, int) and x >= 0 and (x % 2 == 1 or x == 0):\n            total += x * x\n    return total", "response_raw": "def double_the_difference(lst):\n    total = 0\n    for x in lst:\n        if isinstance(x, int) and x >= 0 and (x % 2 == 1 or x == 0):\n            total += x * x\n    return total"}
{"task_id": "HumanEval/152", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.070358991622925, "exec_time_s": 0.02670574188232422, "stdout": "", "stderr": "", "error": null, "eval_count": 193, "prompt_eval_count": 370, "eval_tokens_per_sec": 44.6834081212423, "prompt_tokens_per_sec": 663.8362923868958, "eval_duration_ns": 4319276620, "prompt_eval_duration_ns": 557366333, "code": "def compare(game, guess):\n    \"\"\"\n    Determines how far off each guess was from the actual scores.\n\n    Parameters:\n    - game: list of integers representing actual scores.\n    - guess: list of integers representing guessed scores.\n\n    Returns:\n    - List of integers where each element is 0 if the guess matches the score,\n      otherwise the absolute difference between the score and the guess.\n    \"\"\"\n    return [abs(s - g) if s != g else 0 for s, g in zip(game, guess)]", "response_raw": "def compare(game, guess):\n    \"\"\"\n    Determines how far off each guess was from the actual scores.\n\n    Parameters:\n    - game: list of integers representing actual scores.\n    - guess: list of integers representing guessed scores.\n\n    Returns:\n    - List of integers where each element is 0 if the guess matches the score,\n      otherwise the absolute difference between the score and the guess.\n    \"\"\"\n    return [abs(s - g) if s != g else 0 for s, g in zip(game, guess)]"}
{"task_id": "HumanEval/153", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.311143159866333, "exec_time_s": 0.01629805564880371, "stdout": "", "stderr": "", "error": null, "eval_count": 292, "prompt_eval_count": 412, "eval_tokens_per_sec": 45.005022712349586, "prompt_tokens_per_sec": 689.1287710086028, "eval_duration_ns": 6488164707, "prompt_eval_duration_ns": 597856333, "code": "def Strongest_Extension(class_name, extensions):\n    \"\"\"\n    Returns the class name concatenated with the strongest extension.\n    Strength of an extension is defined as (number of uppercase letters) - (number of lowercase letters).\n    In case of ties, the earliest extension in the list is chosen.\n    \"\"\"\n    if not extensions:\n        return class_name + \".\"\n    \n    best_ext = extensions[0]\n    best_strength = sum(1 for c in best_ext if c.isupper()) - sum(1 for c in best_ext if c.islower())\n    \n    for ext in extensions[1:]:\n        strength = sum(1 for c in ext if c.isupper()) - sum(1 for c in ext if c.islower())\n        if strength > best_strength:\n            best_strength = strength\n            best_ext = ext\n    return f\"{class_name}.{best_ext}\"", "response_raw": "def Strongest_Extension(class_name, extensions):\n    \"\"\"\n    Returns the class name concatenated with the strongest extension.\n    Strength of an extension is defined as (number of uppercase letters) - (number of lowercase letters).\n    In case of ties, the earliest extension in the list is chosen.\n    \"\"\"\n    if not extensions:\n        return class_name + \".\"\n    \n    best_ext = extensions[0]\n    best_strength = sum(1 for c in best_ext if c.isupper()) - sum(1 for c in best_ext if c.islower())\n    \n    for ext in extensions[1:]:\n        strength = sum(1 for c in ext if c.isupper()) - sum(1 for c in ext if c.islower())\n        if strength > best_strength:\n            best_strength = strength\n            best_ext = ext\n    return f\"{class_name}.{best_ext}\""}
{"task_id": "HumanEval/154", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.632928133010864, "exec_time_s": 0.026229143142700195, "stdout": "", "stderr": "", "error": null, "eval_count": 317, "prompt_eval_count": 267, "eval_tokens_per_sec": 45.364552226356615, "prompt_tokens_per_sec": 629.9915504683825, "eval_duration_ns": 6987834872, "prompt_eval_duration_ns": 423815208, "code": "def cycpattern_check(a, b):\n    \"\"\"Return True if b or any of its rotations is a substring of a.\"\"\"\n    n = len(b)\n    if n == 0:\n        return True\n    # Generate all rotations of b\n    double_b = b + b\n    rotations = {double_b[i:i + n] for i in range(n)}\n    # Check if any rotation appears in a\n    for rot in rotations:\n        if rot in a:\n            return True\n    return False", "response_raw": "def cycpattern_check(a, b):\n    \"\"\"Return True if b or any of its rotations is a substring of a.\"\"\"\n    n = len(b)\n    if n == 0:\n        return True\n    # Generate all rotations of b\n    double_b = b + b\n    rotations = {double_b[i:i + n] for i in range(n)}\n    # Check if any rotation appears in a\n    for rot in rotations:\n        if rot in a:\n            return True\n    return False"}
{"task_id": "HumanEval/155", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 5.562604904174805, "exec_time_s": 0.017168283462524414, "stdout": "", "stderr": "", "error": null, "eval_count": 230, "prompt_eval_count": 208, "eval_tokens_per_sec": 45.641618506212914, "prompt_tokens_per_sec": 630.6701242711526, "eval_duration_ns": 5039260384, "prompt_eval_duration_ns": 329807917, "code": "def even_odd_count(num):\n    \"\"\"Given an integer. return a tuple that has the number of even and odd digits respectively.\n\n     Example:\n        even_odd_count(-12) ==> (1, 1)\n        even_odd_count(123) ==> (1, 2)\n    \"\"\"\n    n = abs(num)\n    even = 0\n    odd = 0\n    if n == 0:\n        even = 1\n    while n > 0:\n        digit = n % 10\n        if digit % 2 == 0:\n            even += 1\n        else:\n            odd += 1\n        n //= 10\n    return (even, odd)", "response_raw": "def even_odd_count(num):\n    \"\"\"Given an integer. return a tuple that has the number of even and odd digits respectively.\n\n     Example:\n        even_odd_count(-12) ==> (1, 1)\n        even_odd_count(123) ==> (1, 2)\n    \"\"\"\n    n = abs(num)\n    even = 0\n    odd = 0\n    if n == 0:\n        even = 1\n    while n > 0:\n        digit = n % 10\n        if digit % 2 == 0:\n            even += 1\n        else:\n            odd += 1\n        n //= 10\n    return (even, odd)"}
{"task_id": "HumanEval/156", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.289170265197754, "exec_time_s": 0.028571128845214844, "stdout": "", "stderr": "", "error": null, "eval_count": 393, "prompt_eval_count": 245, "eval_tokens_per_sec": 45.42044471869589, "prompt_tokens_per_sec": 622.9725580588175, "eval_duration_ns": 8652491239, "prompt_eval_duration_ns": 393275750, "code": "def int_to_mini_roman(number: int) -> str:\n    \"\"\"\n    Convert a positive integer (1 <= number <= 1000) to its Roman numeral representation in lowercase.\n    \"\"\"\n    if not (1 <= number <= 1000):\n        raise ValueError(\"Number out of range (must be 1..1000)\")\n\n    roman_map = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\"),\n    ]\n\n    result = []\n    for value, symbol in roman_map:\n        while number >= value:\n            result.append(symbol)\n            number -= value\n    return \"\".join(result).lower()", "response_raw": "def int_to_mini_roman(number: int) -> str:\n    \"\"\"\n    Convert a positive integer (1 <= number <= 1000) to its Roman numeral representation in lowercase.\n    \"\"\"\n    if not (1 <= number <= 1000):\n        raise ValueError(\"Number out of range (must be 1..1000)\")\n\n    roman_map = [\n        (1000, \"M\"),\n        (900, \"CM\"),\n        (500, \"D\"),\n        (400, \"CD\"),\n        (100, \"C\"),\n        (90, \"XC\"),\n        (50, \"L\"),\n        (40, \"XL\"),\n        (10, \"X\"),\n        (9, \"IX\"),\n        (5, \"V\"),\n        (4, \"IV\"),\n        (1, \"I\"),\n    ]\n\n    result = []\n    for value, symbol in roman_map:\n        while number >= value:\n            result.append(symbol)\n            number -= value\n    return \"\".join(result).lower()"}
{"task_id": "HumanEval/157", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.805699825286865, "exec_time_s": 0.027705669403076172, "stdout": "", "stderr": "", "error": null, "eval_count": 281, "prompt_eval_count": 248, "eval_tokens_per_sec": 45.4156675200283, "prompt_tokens_per_sec": 614.4163638025489, "eval_duration_ns": 6187292081, "prompt_eval_duration_ns": 403635083, "code": "def right_angle_triangle(a, b, c):\n    \"\"\"\n    Given the lengths of the three sides of a triangle, return True if they form\n    a right-angled triangle, otherwise False.\n    \"\"\"\n    # Ensure the sides are positive numbers\n    if a <= 0 or b <= 0 or c <= 0:\n        return False\n\n    # Sort sides so that x <= y <= z\n    x, y, z = sorted((a, b, c))\n\n    # Check triangle inequality\n    if x + y <= z:\n        return False\n\n    # Use Pythagorean theorem with a tolerance for floating point errors\n    return abs(x * x + y * y - z * z) < 1e-9", "response_raw": "def right_angle_triangle(a, b, c):\n    \"\"\"\n    Given the lengths of the three sides of a triangle, return True if they form\n    a right-angled triangle, otherwise False.\n    \"\"\"\n    # Ensure the sides are positive numbers\n    if a <= 0 or b <= 0 or c <= 0:\n        return False\n\n    # Sort sides so that x <= y <= z\n    x, y, z = sorted((a, b, c))\n\n    # Check triangle inequality\n    if x + y <= z:\n        return False\n\n    # Use Pythagorean theorem with a tolerance for floating point errors\n    return abs(x * x + y * y - z * z) < 1e-9"}
{"task_id": "HumanEval/158", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 7.543900966644287, "exec_time_s": 0.02963995933532715, "stdout": "", "stderr": "", "error": null, "eval_count": 314, "prompt_eval_count": 260, "eval_tokens_per_sec": 45.388622790153605, "prompt_tokens_per_sec": 649.4493205557377, "eval_duration_ns": 6918033214, "prompt_eval_duration_ns": 400339167, "code": "def find_max(words):\n    \"\"\"\n    Returns the word with the maximum number of unique characters.\n    If there is a tie, returns the lexicographically smallest word among them.\n    If the input list is empty, returns an empty string.\n    \"\"\"\n    best_word = \"\"\n    best_count = -1\n    for word in words:\n        uniq = len(set(word))\n        if uniq > best_count or (uniq == best_count and word < best_word):\n            best_word = word\n            best_count = uniq\n    return best_word", "response_raw": "def find_max(words):\n    \"\"\"\n    Returns the word with the maximum number of unique characters.\n    If there is a tie, returns the lexicographically smallest word among them.\n    If the input list is empty, returns an empty string.\n    \"\"\"\n    best_word = \"\"\n    best_count = -1\n    for word in words:\n        uniq = len(set(word))\n        if uniq > best_count or (uniq == best_count and word < best_word):\n            best_word = word\n            best_count = uniq\n    return best_word"}
{"task_id": "HumanEval/159", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 10.550053119659424, "exec_time_s": 0.02017998695373535, "stdout": "", "stderr": "", "error": null, "eval_count": 441, "prompt_eval_count": 415, "eval_tokens_per_sec": 45.390464509528094, "prompt_tokens_per_sec": 725.8444117522955, "eval_duration_ns": 9715697003, "prompt_eval_duration_ns": 571747875, "code": "def eat(number, need, remaining):\n    \"\"\"\n    You're a hungry rabbit, and you already have eaten a certain number of carrots,\n    but now you need to eat more carrots to complete the day's meals.\n    you should return an array of [ total number of eaten carrots after your meals,\n                                    the number of carrots left after your meals ]\n    if there are not enough remaining carrots, you will eat all remaining carrots, but will still be hungry.\n    \n    Example:\n    * eat(5, 6, 10) -> [11, 4]\n    * eat(4, 8, 9) -> [12, 1]\n    * eat(1, 10, 10) -> [11, 0]\n    * eat(2, 11, 5) -> [7, 0]\n    \n    Variables:\n    @number : integer\n        the number of carrots that you have eaten.\n    @need : integer\n        the number of carrots that you need to eat.\n    @remaining : integer\n        the number of remaining carrots thet exist in stock\n    \n    Constrain:\n    * 0 <= number <= 1000\n    * 0 <= need <= 1000\n    * 0 <= remaining <= 1000\n\n    Have fun :)\n    \"\"\"\n    eaten = min(need, remaining)\n    total = number + eaten\n    left = remaining - eaten\n    return [total, left]", "response_raw": "def eat(number, need, remaining):\n    \"\"\"\n    You're a hungry rabbit, and you already have eaten a certain number of carrots,\n    but now you need to eat more carrots to complete the day's meals.\n    you should return an array of [ total number of eaten carrots after your meals,\n                                    the number of carrots left after your meals ]\n    if there are not enough remaining carrots, you will eat all remaining carrots, but will still be hungry.\n    \n    Example:\n    * eat(5, 6, 10) -> [11, 4]\n    * eat(4, 8, 9) -> [12, 1]\n    * eat(1, 10, 10) -> [11, 0]\n    * eat(2, 11, 5) -> [7, 0]\n    \n    Variables:\n    @number : integer\n        the number of carrots that you have eaten.\n    @need : integer\n        the number of carrots that you need to eat.\n    @remaining : integer\n        the number of remaining carrots thet exist in stock\n    \n    Constrain:\n    * 0 <= number <= 1000\n    * 0 <= need <= 1000\n    * 0 <= remaining <= 1000\n\n    Have fun :)\n    \"\"\"\n    eaten = min(need, remaining)\n    total = number + eaten\n    left = remaining - eaten\n    return [total, left]"}
{"task_id": "HumanEval/160", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 9.279584169387817, "exec_time_s": 0.026641845703125, "stdout": "", "stderr": "", "error": null, "eval_count": 388, "prompt_eval_count": 348, "eval_tokens_per_sec": 45.492492316716984, "prompt_tokens_per_sec": 693.3126618842729, "eval_duration_ns": 8528879827, "prompt_eval_duration_ns": 501938042, "code": "def do_algebra(operator, operand):\n    \"\"\"\n    Evaluate an algebraic expression built from a list of operators and a list of operands.\n\n    Parameters:\n    - operator: list of strings, each being one of '+', '-', '*', '//', '**'\n    - operand: list of non‑negative integers\n\n    Returns:\n    - The integer result of the expression.\n    \"\"\"\n    # Build the expression string respecting the given order.\n    expr = str(operand[0])\n    for op, val in zip(operator, operand[1:]):\n        expr += f' {op} {val}'\n    # Evaluate using Python's arithmetic rules (which match the required precedence).\n    return eval(expr)", "response_raw": "def do_algebra(operator, operand):\n    \"\"\"\n    Evaluate an algebraic expression built from a list of operators and a list of operands.\n\n    Parameters:\n    - operator: list of strings, each being one of '+', '-', '*', '//', '**'\n    - operand: list of non‑negative integers\n\n    Returns:\n    - The integer result of the expression.\n    \"\"\"\n    # Build the expression string respecting the given order.\n    expr = str(operand[0])\n    for op, val in zip(operator, operand[1:]):\n        expr += f' {op} {val}'\n    # Evaluate using Python's arithmetic rules (which match the required precedence).\n    return eval(expr)"}
{"task_id": "HumanEval/161", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 6.092717885971069, "exec_time_s": 0.025153160095214844, "stdout": "", "stderr": "", "error": null, "eval_count": 250, "prompt_eval_count": 247, "eval_tokens_per_sec": 45.5870421120172, "prompt_tokens_per_sec": 614.3650105446302, "eval_duration_ns": 5484014501, "prompt_eval_duration_ns": 402041125, "code": "def solve(s):\n    if any(c.isalpha() for c in s):\n        return ''.join(c.swapcase() if c.isalpha() else c for c in s)\n    else:\n        return s[::-1]", "response_raw": "def solve(s):\n    if any(c.isalpha() for c in s):\n        return ''.join(c.swapcase() if c.isalpha() else c for c in s)\n    else:\n        return s[::-1]"}
{"task_id": "HumanEval/162", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 3.973191022872925, "exec_time_s": 0.032926082611083984, "stdout": "", "stderr": "", "error": null, "eval_count": 158, "prompt_eval_count": 216, "eval_tokens_per_sec": 45.62808250709109, "prompt_tokens_per_sec": 634.5708151680827, "eval_duration_ns": 3462779747, "prompt_eval_duration_ns": 340387542, "code": "import hashlib\n\ndef string_to_md5(text):\n    \"\"\"\n    Given a string 'text', return its md5 hash equivalent string.\n    If 'text' is an empty string, return None.\n\n    >>> string_to_md5('Hello world') == '3e25960a79dbc69b674cd4ec67a72c62'\n    \"\"\"\n    if text == \"\":\n        return None\n    return hashlib.md5(text.encode('utf-8')).hexdigest()", "response_raw": "import hashlib\n\ndef string_to_md5(text):\n    \"\"\"\n    Given a string 'text', return its md5 hash equivalent string.\n    If 'text' is an empty string, return None.\n\n    >>> string_to_md5('Hello world') == '3e25960a79dbc69b674cd4ec67a72c62'\n    \"\"\"\n    if text == \"\":\n        return None\n    return hashlib.md5(text.encode('utf-8')).hexdigest()"}
{"task_id": "HumanEval/163", "model": "gpt-oss:120b", "ok": true, "sample_index": 0, "gen_time_s": 12.797714233398438, "exec_time_s": 0.023636817932128906, "stdout": "", "stderr": "", "error": null, "eval_count": 534, "prompt_eval_count": 248, "eval_tokens_per_sec": 44.14656475106909, "prompt_tokens_per_sec": 644.88881137857, "eval_duration_ns": 12096071416, "prompt_eval_duration_ns": 384562417, "code": "def generate_integers(a, b):\n    \"\"\"\n    Given two positive integers a and b, return the even digits between a\n    and b, in ascending order.\n\n    For example:\n    generate_integers(2, 8) => [2, 4, 6, 8]\n    generate_integers(8, 2) => [2, 4, 6, 8]\n    generate_integers(10, 14) => []\n    \"\"\"\n    low, high = (a, b) if a <= b else (b, a)\n    even_digits = [0, 2, 4, 6, 8]\n    return [d for d in even_digits if low <= d <= high]", "response_raw": "def generate_integers(a, b):\n    \"\"\"\n    Given two positive integers a and b, return the even digits between a\n    and b, in ascending order.\n\n    For example:\n    generate_integers(2, 8) => [2, 4, 6, 8]\n    generate_integers(8, 2) => [2, 4, 6, 8]\n    generate_integers(10, 14) => []\n    \"\"\"\n    low, high = (a, b) if a <= b else (b, a)\n    even_digits = [0, 2, 4, 6, 8]\n    return [d for d in even_digits if low <= d <= high]"}
