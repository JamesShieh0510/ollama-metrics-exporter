{
  "nodes": [
    {
      "name": "node1",
      "type": "local",
      "hosts": [
        "192.168.50.158",
        "node1",
        "m3max",
        "m3max.local",
        "m3max-128gb.local"
      ],
      "port": 11434,
      "memory_gb": 128,
      "description": "m3max-128gb",
      "supported_model_ranges": [
        {
          "min_params_b": 8,
          "max_params_b": null,
          "description": "70B+ 大模型"
        }
      ]
    },
    {
      "name": "node2",
      "type": "local",
      "hosts": [
        "192.168.50.31",
        "node2",
        "m1max",
        "m1max.local",
        "m1max-64gb.local",
        "m1max-32gb.local"
      ],
      "port": 11434,
      "memory_gb": 32,
      "description": "m1max-32gb",
      "supported_model_ranges": [
        {
          "min_params_b": 8,
          "max_params_b": 70,
          "description": "8B~70B 中型模型"
        }
      ]
    },
    {
      "name": "node3",
      "type": "local",
      "hosts": [
        "192.168.50.94",
        "node3",
        "m1",
        "m1.local",
        "m1-16gb.local"
      ],
      "port": 11434,
      "memory_gb": 16,
      "description": "m1-16gb",
      "supported_model_ranges": [
        {
          "min_params_b": 1,
          "max_params_b": 8,
          "description": "1B~8B 小模型"
        }
      ]
    },
    {
      "name": "node4",
      "type": "local",
      "hosts": [
        "192.168.50.155",
        "node4",
        "i7",
        "i74080.local",
        "i7g13-4080-32gb.local"
      ],
      "port": 11434,
      "memory_gb": 32,
      "description": "i7-4080-32gb",
      "supported_model_ranges": [
        {
          "min_params_b": 8,
          "max_params_b": 34,
          "description": "8B~30B 小模型（GPU加速）"
        }
      ]
    },
    {
      "name": "ollama-cloud",
      "type": "external",
      "description": "Ollama Cloud API",
      "api_url": "https://ollama.com",
      "api_key": "${OLLAMA_API_KEY}",
      "supported_model_ranges": [
        {
          "min_params_b": 1,
          "max_params_b": null,
          "description": "所有模型（云端）"
        }
      ],
      "timeout_seconds": 300,
      "headers": {
        "Authorization": "Bearer ${OLLAMA_API_KEY}"
      }
    }
  ],
  "model_name_patterns": {
    "120b": 120,
    "120B": 120,
    "70b": 70,
    "70B": 70,
    "65b": 65,
    "65B": 65,
    "34b": 34,
    "34B": 34,
    "32b": 32,
    "32B": 32,
    "30b": 30,
    "30B": 30,
    "13b": 13,
    "13B": 13,
    "8b": 8,
    "8B": 8,
    "7b": 7,
    "7B": 7,
    "3b": 3,
    "3B": 3,
    "1b": 1,
    "1B": 1
  },
  "model_name_mapping": {
    "qwen3-coder": 30,
    "qwen3-coder:30b": 30,
    "qwen3-coder:30B": 30
  },
  "default_model_size_b": 7
}